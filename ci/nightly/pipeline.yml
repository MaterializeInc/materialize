# Copyright Materialize, Inc. and contributors. All rights reserved.
#
# Use of this software is governed by the Business Source License
# included in the LICENSE file at the root of this repository.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0.

steps:
  - block: Nightly test selection
    prompt: |
      What tests would you like to run? As a convenience, leaving all tests
      unchecked will run all tests.
    blocked_state: running
    fields:
      - select: Tests
        key: tests
        options:
          - { value: coverage }
          - { value: kafka-matrix }
          - { value: kafka-multi-broker }
          - { value: redpanda-testdrive }
#         - { value: redpanda-testdrive-aarch64 }
          - { value: limits }
          - { value: cluster-limits }
          - { value: limits-instance-size }
          - { value: testdrive-partitions-5 }
          - { value: testdrive-replicas-4}
          - { value: testdrive-size-1}
          - { value: testdrive-size-8}
          - { value: testdrive-in-cloudtest}
          - { value: feature-benchmark }
          - { value: zippy-kafka-sources }
          - { value: zippy-kafka-parallel-insert }
          - { value: zippy-user-tables }
          - { value: zippy-debezium-postgres }
          - { value: zippy-postgres-cdc }
          - { value: zippy-cluster-replicas }
          - { value: zippy-crdb-minio-restart }
          - { value: zippy-crdb-latest-restart }
          - { value: secrets }
          - { value: checks-oneatatime-drop-create-default-replica }
          - { value: checks-oneatatime-restart-clusterd-compute }
          - { value: checks-oneatatime-restart-entire-mz }
          - { value: checks-oneatatime-restart-environmentd-clusterd-storage }
          - { value: checks-oneatatime-kill-clusterd-storage }
          - { value: checks-oneatatime-restart-cockroach }
          - { value: checks-oneatatime-restart-redpanda }
          - { value: checks-parallel-drop-create-default-replica }
          - { value: checks-parallel-restart-clusterd-compute }
          - { value: checks-parallel-restart-entire-mz }
          - { value: checks-parallel-restart-environmentd-clusterd-storage }
          - { value: checks-parallel-kill-clusterd-storage }
          - { value: checks-parallel-restart-cockroach }
          - { value: checks-parallel-restart-redpanda }
          - { value: checks-upgrade-entire-mz }
          - { value: checks-upgrade-entire-mz-previous-version }
          - { value: checks-upgrade-clusterd-compute-first }
          - { value: checks-upgrade-clusterd-compute-last }
          - { value: cloudtest-upgrade }
          - { value: persist-maelstrom-single-node }
          - { value: persist-maelstrom-multi-node }
          - { value: unused-deps }
          - { value: launchdarkly }
          - { value: bounded-memory }
        multiple: true
        required: false
    if: build.source == "ui"

  - id: build-x86_64
    label: Build x86_64
    command: bin/ci-builder run stable bin/pyactivate -m ci.test.build x86_64
    timeout_in_minutes: 60
    agents:
      queue: builder-linux-x86_64

  - wait: ~

  - command: bin/ci-builder run stable bin/pyactivate -m materialize.ci_util.trim_pipeline nightly
    if: build.source == "ui"
    agents:
      queue: linux

  - wait: ~

  - id: feature-benchmark
    label: "Feature benchmark against 'latest'"
    timeout_in_minutes: 360
    agents:
      queue: linux-x86_64-large
    plugins:
      - ./ci/plugins/mzcompose:
          composition: feature-benchmark
          args:
             - --other-tag
             - latest

  - id: coverage
    label: Code coverage
    timeout_in_minutes: 240
    command: bin/ci-builder run nightly bin/pyactivate -m ci.nightly.coverage
    agents:
      queue: linux-x86_64
    skip: Disabled due to persistent OOMs when linking

  - id: kafka-matrix
    label: Kafka smoke test against previous Kafka versions
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: kafka-matrix

  - id: kafka-multi-broker
    label: Kafka multi-broker test
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: kafka-multi-broker

  - id: redpanda-testdrive
    label: ":panda_face: :racing_car: testdrive"
    timeout_in_minutes: 600
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/scratch-aws-access: ~
      - ./ci/plugins/mzcompose:
          composition: testdrive
          args: [--redpanda, --aws-region=us-east-2]

# Disabled due to taking too long for the value provided
#  - id: redpanda-testdrive-aarch64
#    label: ":panda_face: :racing_car: testdrive aarch64"
#    timeout_in_minutes: 600
#    agents:
#      queue: linux-aarch64
#    plugins:
#      - ./ci/plugins/scratch-aws-access: ~
#      - ./ci/plugins/mzcompose:
#          composition: testdrive
#          args: [--redpanda, --aws-region=us-east-2]

  - id: limits
    label: "Product limits"
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: limits
    timeout_in_minutes: 50

  - id: cluster-limits
    label: "Cluster Product limits"
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: limits
          run: cluster
    timeout_in_minutes: 50

  - id: limits-instance-size
    label: "Instance size limits"
    agents:
      # A larger instance is needed due to the
      # many containers that are being created
      queue: builder-linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: limits
          run: instance-size
    timeout_in_minutes: 50

  - id: testdrive-partitions-5
    label: ":racing_car: testdrive with --kafka-default-partitions 5"
    timeout_in_minutes: 600
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/scratch-aws-access: ~
      - ./ci/plugins/mzcompose:
          composition: testdrive
          args: [--aws-region=us-east-2, --kafka-default-partitions=5]

  - id: testdrive-replicas-4
    label: ":racing_car: testdrive 4 replicas"
    timeout_in_minutes: 600
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/scratch-aws-access: ~
      - ./ci/plugins/mzcompose:
          composition: testdrive
          args: [--aws-region=us-east-2, --replicas=4]

  - id: testdrive-size-1
    label: ":racing_car: testdrive with SIZE 1"
    timeout_in_minutes: 600
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/scratch-aws-access: ~
      - ./ci/plugins/mzcompose:
          composition: testdrive
          args: [--aws-region=us-east-2, --default-size=1]

  - id: testdrive-size-8
    label: ":racing_car: testdrive with SIZE 8"
    timeout_in_minutes: 600
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/scratch-aws-access: ~
      - ./ci/plugins/mzcompose:
          composition: testdrive
          args: [--aws-region=us-east-2, --default-size=8]

  - id: testdrive-in-cloudtest
    label: Full Testdrive in Cloudtest (K8s)
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/scratch-aws-access: ~
      - ./ci/plugins/cloudtest:
          args: [-m=long, --aws-region=us-east-2, test/cloudtest/test_full_testdrive.py]

  - id: persistence-testdrive
    label: ":racing_car: testdrive with --persistent-user-tables"
    timeout_in_minutes: 30
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/scratch-aws-access: ~
      - ./ci/plugins/mzcompose:
          composition: testdrive
          args: [--aws-region=us-east-2, --persistent-user-tables]
    skip: Persistence tests disabled

  - id: zippy-kafka-sources
    label: "Zippy Kafka Sources"
    timeout_in_minutes: 120
    agents:
      # Workload takes slightly more than 8Gb, so it OOMs
      # on the instances from the linux-x86_64 queue
      queue: builder-linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: zippy
          args: [--scenario=KafkaSources, --actions=1000]

  - id: zippy-kafka-parallel-insert
    label: "Zippy Kafka Parallel Insert"
    timeout_in_minutes: 120
    agents:
      queue: builder-linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: zippy
          args: [--scenario=KafkaParallelInsert, --transaction-isolation=serializable, --actions=2000]

  - id: zippy-user-tables
    label: "Zippy User Tables"
    timeout_in_minutes: 180
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: zippy
          args: [--scenario=UserTables, --actions=1000]

  - id: zippy-postgres-cdc
    label: "Zippy Postgres CDC"
    timeout_in_minutes: 120
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: zippy
          args: [--scenario=PostgresCdc, --actions=3000]

  - id: zippy-debezium-postgres
    label: "Zippy Debezium Postgres"
    timeout_in_minutes: 120
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: zippy
          args: [--scenario=DebeziumPostgres, --actions=1000]

  - id: zippy-cluster-replicas
    label: "Zippy Cluster Replicas"
    timeout_in_minutes: 120
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: zippy
          args: [--scenario=ClusterReplicas, --actions=1000]

  - id: zippy-crdb-minio-restart
    label: "Zippy CRDB/Minio restarts"
    timeout_in_minutes: 120
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: zippy
          args: [--scenario=CrdbMinioRestart, --actions=1000]

  - id: zippy-crdb-latest-restart
    label: "Zippy CRDB restarts w/ latest CRDB"
    timeout_in_minutes: 120
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: zippy
          args: [--scenario=CrdbRestart, --actions=1000, --cockroach-tag=latest]

  - id: secrets
    label: "Secrets"
    timeout_in_minutes: 30
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: secrets

  - id: checks-oneatatime-drop-create-default-replica
    label: "Checks oneatatime + DROP/CREATE replica"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=DropCreateDefaultReplica, --execution-mode=oneatatime]

  - id: checks-oneatatime-restart-clusterd-compute
    label: "Checks oneatatime + restart compute clusterd"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartClusterdCompute, --execution-mode=oneatatime]

  - id: checks-oneatatime-restart-entire-mz
    label: "Checks oneatatime + restart of the entire Mz"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartEntireMz, --execution-mode=oneatatime]

  - id: checks-oneatatime-restart-environmentd-clusterd-storage
    label: "Checks oneatatime + restart of environmentd & storage clusterd"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartEnvironmentdClusterdStorage, --execution-mode=oneatatime]

  - id: checks-oneatatime-kill-clusterd-storage
    label: "Checks oneatatime + kill storage clusterd"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=KillClusterdStorage, --execution-mode=oneatatime]

  - id: checks-oneatatime-restart-cockroach
    label: "Checks oneatatime + restart Cockroach"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartCockroach, --execution-mode=oneatatime]

  - id: checks-oneatatime-restart-redpanda-debezium
    label: "Checks oneatatime + restart Redpanda & Debezium"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartRedpandaDebezium, --execution-mode=oneatatime]

  - id: checks-parallel-drop-create-default-replica
    label: "Checks parallel + DROP/CREATE replica"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=DropCreateDefaultReplica, --execution-mode=parallel]

  - id: checks-parallel-restart-clusterd-compute
    label: "Checks parallel + restart compute clusterd"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartClusterdCompute, --execution-mode=parallel]

  - id: checks-parallel-restart-entire-mz
    label: "Checks parallel + restart of the entire Mz"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartEntireMz, --execution-mode=parallel]

  - id: checks-parallel-restart-environmentd-clusterd-storage
    label: "Checks parallel + restart of environmentd & storage clusterd"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartEnvironmentdClusterdStorage, --execution-mode=parallel]

  - id: checks-parallel-kill-clusterd-storage
    label: "Checks parallel + kill storage clusterd"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=KillClusterdStorage, --execution-mode=parallel]

  - id: checks-parallel-restart-cockroach
    label: "Checks parallel + restart Cockroach"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartCockroach, --execution-mode=parallel]

  - id: checks-parallel-restart-redpanda
    label: "Checks parallel + restart Redpanda & Debezium"
    timeout_in_minutes: 300
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=RestartRedpandaDebezium, --execution-mode=parallel]

  - id: checks-upgrade-entire-mz
    label: "Checks upgrade, whole-Mz restart"
    timeout_in_minutes: 30
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=UpgradeEntireMz]

  - id: checks-upgrade-entire-mz-previous-version
    label: "Checks upgrade from previous version, whole-Mz restart"
    timeout_in_minutes: 30
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=UpgradeEntireMzPreviousVersion]

  - id: checks-upgrade-clusterd-compute-first
    label: "Platform checks upgrade, restarting compute clusterd first"
    timeout_in_minutes: 30
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=UpgradeClusterdComputeFirst]

  - id: checks-upgrade-clusterd-compute-last
    label: "Platform checks upgrade, restarting compute clusterd last"
    timeout_in_minutes: 30
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: platform-checks
          args: [--scenario=UpgradeClusterdComputeLast]

  - id: cloudtest-upgrade
    label: "Platform checks upgrade in Cloudtest/K8s"
    timeout_in_minutes: 30
    agents:
      queue: linux-x86_64
    artifact_paths: junit_cloudtest_*.xml
    plugins:
      - ./ci/plugins/scratch-aws-access: ~
      - ./ci/plugins/cloudtest:
          args: [-m=long,  --aws-region=us-east-2, test/cloudtest/test_upgrade.py]

  - id: persist-maelstrom-single-node
    label: Long single-node Maelstrom coverage of persist
    timeout_in_minutes: 20
    agents:
      queue: linux-x86_64
    artifact_paths: [test/persist/maelstrom/**/*.log, junit_mzcompose_*.xml]
    plugins:
      - ./ci/plugins/mzcompose:
          composition: persist
          args: [--node-count=1, --consensus=mem, --blob=mem, --time-limit=600, --concurrency=4, --rate=500, --max-txn-length=16, --unreliability=0.1]

  - id: persist-maelstrom-multi-node
    label: Long multi-node Maelstrom coverage of persist with postgres consensus
    timeout_in_minutes: 20
    agents:
      queue: linux-x86_64
    artifact_paths: [test/persist/maelstrom/**/*.log, junit_mzcompose_*.xml]
    plugins:
      - ./ci/plugins/mzcompose:
          composition: persist
          args: [--node-count=4, --consensus=cockroach, --blob=maelstrom, --time-limit=300, --concurrency=4, --rate=500, --max-txn-length=16, --unreliability=0.1]

  - id: persistence-failpoints
    label: Persistence failpoints
    timeout_in_minutes: 30
    artifact_paths: junit_mzcompose_*.xml
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: persistence
          run: failpoints
    skip: Persistence tests disabled

  - id: unused-deps
    label: Unused dependencies
    command: bin/ci-builder run nightly bin/unused-deps
    # inputs:
    #  - Cargo.lock
    #  - "**/Cargo.toml"
    #  - "**/*.rs"
    timeout_in_minutes: 30
    agents:
      queue: linux-x86_64

  - id: launchdarkly
    label: "LaunchDarkly"
    artifact_paths: junit_mzcompose_*.xml
    timeout_in_minutes: 30
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: launchdarkly

  - id: bounded-memory
    label: "Bounded Memory"
    artifact_paths: junit_mzcompose_*.xml
    timeout_in_minutes: 3600
    agents:
      queue: linux-x86_64
    plugins:
      - ./ci/plugins/mzcompose:
          composition: bounded-memory
