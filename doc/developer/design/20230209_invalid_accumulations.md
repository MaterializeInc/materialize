# Handling of Invalid Accumulations in Reductions

## Summary

Upon seeing invalid accumulations in aggregation queries / dataflows, Materialize may log errors or even crash. It is unclear whether errors logged will be reported as failures in the corresponding dataflow, making it difficult for users to take corrective actions themselves and/or notify us of erroneous sources.

Differential Dataflow (DD) operates on `(data, time, diff)` tuples representing changes to `data` at `time` for a given multiplicity `diff`. The multiplicity `diff` is an integer, signaling that changes can lead to either creation or removal of `data` over time. Tuples with negative multiplicities are thus a fact of life and Materialize should be able to process them correctly.

At some points during a computation, however, we should only observe multiplicities that are non-negative, since Materialize transforms inputs that are multisets into outputs that are also multisets. For example, every time output is produced out of a compute replica, we ensure that negative multiplicities result in a query-level error and, otherwise, that only tuples with positive multiplicities are emitted (see [relevant code](https://github.com/MaterializeInc/materialize/blob/9933639ea5393d1aaa40c1079d07ffc1cc622516/src/compute/src/compute_state.rs#L903-L929)).

It is, however, much harder to check whether inputs given to a dataflow computation are indeed multisets or whether they contain tuples with net negative multiplicities. Ultimately, input data processed by a compute replica originates either from introspection sources or from the STORAGE layer via `persist`. The data in the STORAGE layer is ingested from external sources or inserted as rows into tables. Since these data are not consolidated, but rather represented in terms of changes, checking for whether the data is a multiset is equivalent to performing full consolidation, which can be costly and unnecessary to do as part of a dataflow for a range of use cases. As a consequence, sources that incorrectly report too many or non-matching retractions for rows end up recording incorrect data in `persist`, which in turn may trigger errors at the COMPUTE layer. These errors are typically caught during reductions, wherein multiplicities at particular points in time can be asserted.

These errors lie at the root of at least two incidents; additionally, they have been [observed in Sentry](https://sentry.io/organizations/materializeinc/issues/3869058341/events/66dbb5ab35874580b814c1f9c17281f1/?project=6780145) after these incidents took place. At the time of writing, it is in principle possible, e.g., for a source to cause these errors by issuing invalid retractions to Materialize using `ENVELOPE DEBEZIUM`.

This design work is pursued as part of epic [#17178](https://github.com/MaterializeInc/materialize/issues/17178).

## Goals

Our goal is to design a consistent error reporting strategy for invalid accumulations in reductions, whenever such errors are detected. It is desirable that the errors produced be visible to the user of the system, i.e., reported as SQL-level errors. It is undesirable that these errors become visible as system crashes (e.g., due to panics), as the latter would unnecessarily reduce system availability. We also see as desirable that these errors be additionally logged to Sentry so that proactive remedial actions can be taken.

## Non-Goals

We do not aim to tackle here errors other than invalid accumulation errors in reductions. Other errors that can theoretically occur in reductions may lead to crashes, e.g., when incorrect data types are presented for some reduction operations (see [this example](https://github.com/MaterializeInc/materialize/blob/d28272444db09053e89eab1d568ba3a81f3da19a/src/compute/src/render/reduce.rs#L1138)). Additionally, it is not an aim of the present design to improve the general error reporting visibility in Materialize, e.g., ensuring that the user is alerted when materialized views contain errors. Finally, we only focus on invalid accumulation errors that can be detected during reductions. Note that even after this design is implemented, it will still be possible that reductions can be constructed over source data with incorrect multiplicities where we do not detect that the source data was, in fact, invalid.

## Description

### Error Categories

We identify a few important error categories to be considered:

1. When we implement introspection sources, tables, and regular sources, we ensure that only multisets are given as input to the COMPUTE layer, despite their representation being in terms of changes that may include retractions. However, sometimes this assumption can be violated when subtle bugs occur (see, e.g., issue [#15930](https://github.com/MaterializeInc/materialize/issues/15930)). Additionally, users may [directly introduce invalid retractions in source data](https://materializeinc.slack.com/archives/CM7ATT65S/p1675428135441319?thread_ts=1675355385.487949&cid=CM7ATT65S), e.g., exploiting `ENVELOPE DEBEZIUM`. Therefore, a number of sanity checks are performed during reductions rendered by the COMPUTE layer to ensure that we are operating on multisets. For example, when we compute a min/max aggregation, the closure given to a reduction operator cannot observe negative multiplicities if we are operating on a multiset. So checks and error reporting are introduced, e.g., in [intermediate stages](https://github.com/MaterializeInc/materialize/blob/9933639ea5393d1aaa40c1079d07ffc1cc622516/src/compute/src/render/reduce.rs#L634-L642) and [final reduction](https://github.com/MaterializeInc/materialize/blob/9933639ea5393d1aaa40c1079d07ffc1cc622516/src/compute/src/render/reduce.rs#L590-L596) of hierarchical aggregates. The strategy for error reporting is to employ a soft assertion: during development, an assertion failure will trigger a crash; in production, an error will be logged and captured in Sentry.
2. Another reason for error due to negative multiplicities is that a negative accumulated result cannot be coerced to an [unsigned type](https://github.com/MaterializeInc/materialize/blob/9933639ea5393d1aaa40c1079d07ffc1cc622516/src/compute/src/render/reduce.rs#L1344-L1346). This error is now treated as unrecoverable, leading to a `panic!` instead of the above strategy of employing a soft assertion.
3. Following a similar error reporting strategy as in category 1 above, we have a soft assertion regarding net-zero records with [non-zero accumulation in accumulable reductions](https://github.com/MaterializeInc/materialize/blob/9933639ea5393d1aaa40c1079d07ffc1cc622516/src/compute/src/render/reduce.rs#L1283-L1290). This category of error can emerge if we determine that an aggregate row has been removed, due to the corresponding tuple multiplicity accumulating to zero, but there is an inconsistency with the accumulation state, namely the aggregation function on the raw changes ends up with a non-zero result.
4. As observed in an incident, shutdown of a `persist_source` operator could trigger errors due to the sanity checks above in the COMPUTE layer. This behavior occurs because `persist_source` would not emit the entirety of a batch nor guarantee that a partially emitted batch would consolidate to a multiset. We ignore this problem in the remainder of this document, as a solution was introduced by PR [#17147](https://github.com/MaterializeInc/materialize/pull/17147).

The errors in categories 1 and 3 above are now reported in Sentry and require investigation. Importantly, these errors are concerning as they indicate that Materialize might silently compute incorrect aggregation results. The errors in category 2 cause Materialize to crash in production.

### Approach: Report SQL-level Errors, Log to Sentry, and Eschew Crashes

We discuss below a path for avoiding system crashes and some classes of silently erroneous computation by producing query-level errors whenever invalid accumulation errors are detected in reductions. Given that bugs in other Materialize components, and not only erroneous user-provided source data, could generate invalid accumulations in reductions, we still advocating keeping error reporting to Sentry in addition to producing query-level errors. Additionally, it is [important for our support team](https://materializeinc.slack.com/archives/CM7ATT65S/p1675358436801089) to have these errors in Sentry so that they can proactively notify users of invalid data in sources.

To discuss our solution approach, we first review the current handling of invalid accumulations by analyzing a few examples of category 1 and 3 errors. In general, our error reporting strategy based on soft asserts does not ensure that a query-level error will be generated when an invalid accumulation is seen. Consider, for example, a reduce collation. First, we check if [an error needs to be reported](https://github.com/MaterializeInc/materialize/blob/9933639ea5393d1aaa40c1079d07ffc1cc622516/src/compute/src/render/reduce.rs#L329-L335). However, subsequently, processing continues normally. Then, the row is [output with a hard-coded multiplicity of one record](https://github.com/MaterializeInc/materialize/blob/9933639ea5393d1aaa40c1079d07ffc1cc622516/src/compute/src/render/reduce.rs#L365). In the case of multiple basic aggregates, if [an error is detected](https://github.com/MaterializeInc/materialize/blob/9933639ea5393d1aaa40c1079d07ffc1cc622516/src/compute/src/render/reduce.rs#L507-L516), then no output is produced for aggregates in the query. No failure is reported at query level either. A similar handling is performed for bucketed hierarchical aggregates. For Category 3 errors, the accumulator logic, which is data-type dependent, is executed after a [soft assertion](https://github.com/MaterializeInc/materialize/blob/9933639ea5393d1aaa40c1079d07ffc1cc622516/src/compute/src/render/reduce.rs#L1292-L1448); the logic ends up with a row with the so computed aggregate being output with a hard-coded multiplicity of one record.

At a high level, our solution approach is to add a post-processing operator immediately after each reduction operator that evaluates if an error occurred during reduction and then produces an error in the appropriate error stream if so. This design avoids changing reduction operators to potentially create error streams, thus reducing the complexity of the change as well as avoiding compromises with raw reduction performance. Two important aspects need to be tackled for this solution approach to work: (1) We need to find a method to concretely implement the post-processing operator; (2) We need to devise a strategy to externalize the information that an error occurred in the output of the reduction operator.

Regarding point (1), the post-processing operator could be implemented as a special-purpose operator in rendering or as an MFP expression with the relevant error processing code encoded as an `MirScalarExpr`. The former option maintains all the implementation complexity within rendering. An argument can be made against this choice, since the error conditions are based on SQL-level semantics and it would be meaningful to encode them at a higher level of abstraction. The latter option embraces error handling as a SQL-level construct, but may suffer from lower evaluation performance than a special-purpose operator introduced during rendering.

Regarding point (2), we note that: (a) The error detection strategy for invalid accumulations is specific to the reduction type; and (b) the necessary information for error detection, e.g., row multiplicities, is available only at the input to a reduce closure. Because of (a), ideally each reduction operator should output, along with an aggregate, an additional field that indicates its validity, i.e., we represent whether an error was detected as an additional field per aggregate row. Due to (b), we need to represent this additional output also in arrangements, complicating the use of a traditional `Result` type. Thus, we propose to employ an extra `Row` column that contains either `Datum::True` or `Datum::False` indicating whether the aggregate is valid or invalid, respectively. The post-processing operator can then produce errors upon seeing `Datum::False` in this validity column or, otherwise, project out the column.

#### Details for Category 2 Errors

The panic calls triggered by this category of error were introduced in PR [#14699](https://github.com/MaterializeInc/materialize/pull/14699). The PR follows the standard of panic on data type mismatches encountered in the reduce module. However, in the case of unsigned types, the type mismatch additionally checks for the sign of the produced number, which can go negative if negative multiplicities are observed.

In our copy of the SQL standard, unsigned types are not listed among numbers. However, some DBMS support them to provide a more ergonomic experience to users. In Materialize, sum aggregations over unsigned integers lead to a wider type. Namely, sums of `uint2` and `uint4` have a `uint8` result, while a sum of `uint8` has a `numeric` result. Since the numeric type can accommodate negative values, PR [#16852](https://github.com/MaterializeInc/materialize/pull/16852) resolved the issue for sums of `uint8` values by eliminating the panic and returning the erroneous negative value. Sums of `uint2` and `uint4` still can trigger the panic if exposed to negative accumulations and crash Materialize.

Note that we would like to uniformly generate a SQL-level error in all cases above instead of outputting an erroneous negative value or crashing Materialize. The introduction of a post-processing step after aggregation that performs an appropriate [cast operation](https://github.com/MaterializeInc/materialize/blob/d28272444db09053e89eab1d568ba3a81f3da19a/src/expr/src/scalar/func.rs#L3868-L3870) would achieve this objective. Thus, implementation of the post-processing operator seems to be more natural as an MFP for category 2 errors.

## Alternatives

Some alternatives were discussed and ultimately discarded due to concerns regarding code maintainability or performance.

### Category 1 and 3 Errors

A **first alternative** is to report both the error to Sentry and also ensure that a record with a negative multiplicity is generated as part of processing. That way, upper processing layers will have a chance to observe the violation of a multiset output property and report a query-level error. However, it is not guaranteed that all query structures will result in a query-level error, since these negative multiplicities could be added up on another query path with positive multiplicities prior to output. The latter would lead to potential error reports to Sentry that are not visible to the user as SQL-level errors.

A **second alternative** is to introduce a `Datum::Dummy` variant in place of the aggregated data that flags that an error has occurred. It is, however, unclear whether this would result in a panic or a more gentle query-level error. From a preliminary analysis, the result appears to be a panic, which would lead us to consider either special handling of `Datum::Dummy` or introduction of another `Datum` variant. The advantage of this approach would be higher confidence in query-level detection, as opposed to the first suggestion, but the engineering effort is less clear and the representation cleanliness is questionable.

A **third alternative** is to work with `Result<_, DataflowError>` in reductions. There is, however, a [concern](https://materializeinc.slack.com/archives/C02PPB50ZHS/p1674077260746689?thread_ts=1674056919.112159&cid=C02PPB50ZHS) that using `Result` in reductions will make the arrangements constructed not usable by downstream operators, e.g., joins. Fixing this issue is not impossible, but the refactoring effort could be large. Orthogonally, initial performance concerns regarding the size of the `enum` were mitigated by boxing `DataflowError`.

A **fourth alternative** is to introduce error streams into reduce operators directly. That way, we could merge the error streams produced by the new fallible reduction operators with the input error streams to produce errors whenever invalid accumulations are detected in a reduction function. The latter option changes the requirements on reductions. These new requirements could be satisfied by both changes to differential dataflow as well as a larger refactoring of our code. Alternatively, we could implement a fallible reduction operator entirely in Materialize. In either case, the generalization of reductions into fallible reductions would require non-trivial design and implementation effort.

A **fifth alternative** is to employ a side channel, e.g., similar to the internal dataflow commands used in the STORAGE layer, that directly informs the worker about the error. The worker could then take measures to mark the dataflow as failed, terminate it, and report errors. However, employing such a side channel implies careful synchronization between the dataflow runtime and the external mechanism. The latter can be a source for subtle bugs. Additionally, the use of a side channel in this way may compromise our ability to retract errors.

### Category 2 Errors

A **sixth alternative** is to first ensure that a negative number observed in the output from a sum of `uint8` values results in a query-level error, instead of resulting in a negative result being returned to the user. This alternative has the same weakness of the first alternative above: combination of a negative number with other query expressions may lead to the error not manifesting for the query. Another disadvantage of this alternative is that it is not a solution uniformly applicable to all unsigned integer types, since as discussed above not all of their sums result in `numeric`. Changing this behavior would have unfortunate implications for backwards compatibility.

## Open questions

* Is it cleaner to introduce `MirScalarExpr`s as post-processing steps to a reduce by changing `MirRelationExpr::Reduce` or `HirRelationExpr::Reduce` planning? Or is there another and even better possibility?
* Would it be desirable to implement the reduce post-processing step exclusively in rendering? This strategy would not reduce the complexity of the rendering code nor allow for reuse of `MirScalarExpr` code. However, it could have better performance than `MirScalarExpr` interpretation. Another issue here is that we would not have control over where to place the fallible operator in the query plan. So this could impact our ability to provide arranged data to downstream operators, e.g., joins.
* This design does not address improving reduction performance by "atomization", as proposed in issue [#8086](https://github.com/MaterializeInc/materialize/issues/8066). Should this additional scope also be considered as part of this improvement effort?
