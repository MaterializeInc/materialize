- name: installation-landing-intro
  content: |
    You can install Self-Managed Materialize on a Kubernetes cluster running
    locally or on a cloud provider. Self-Managed Materialize requires:

    {{% self-managed/materialize-components-list %}}

    ## License key

    Starting in v26.0, Materialize requires a license key.

    {{< yaml-table data="self_managed/license_key" >}}

    ## Installation guides

    The following installation guides are available to help you get started:

- name: installation-landing-guides-helm
  content: |

    ### Install using Helm Commands

    |  Guide         | Description  |
    | ------------- | -------|
    | [Install locally on Kind](/self-managed-deployments/installation/install-on-local-kind/) | Uses standard Helm commands to deploy Materialize to a Kind cluster in Docker.


- name: installation-landing-guides-unified
  content: |
    ### Install using Terraform Modules

    {{< tip >}}
    The Terraform modules are provided as examples. They are not required for
    installing Materialize.
    {{< /tip >}}

    |  Guide         | Description  |
    | ------------- | -------|
    | [Install on AWS](/self-managed-deployments/installation/install-on-aws/) |Uses Terraform module to deploy Materialize to AWS Elastic Kubernetes Service (EKS).
    | [Install on Azure](/self-managed-deployments/installation/install-on-azure/) | Uses Terraform module to deploy Materialize to Azure Kubernetes Service (AKS).
    | [Install on GCP](/self-managed-deployments/installation/install-on-gcp/) | Uses Terraform module to deploy Materialize to Google Kubernetes Engine (GKE).


- name: installation-landing-guides-legacy
  content: |

    ### Install using Legacy Terraform Modules

    {{< tip >}}
    The Terraform modules are provided as examples. They are not required for
    installing Materialize.
    {{< /tip >}}

    |  Guide         | Description  |
    | -------------  | ----------- |
    | [Install on AWS (Legacy Terraform)](/self-managed-deployments/installation/legacy/install-on-aws-legacy/) | Uses legacy Terraform module to deploy Materialize to AWS Elastic Kubernetes Service (EKS).
    | [Install on Azure (Legacy Terraform)](/self-managed-deployments/installation/legacy/install-on-azure-legacy/) | Uses legacy Terraform module to deploy Materialize to Azure Kubernetes Service (AKS).
    | [Install on GCP (Legacy Terraform)](/self-managed-deployments/installation/legacy/install-on-gcp-legacy/) | Uses legacy Terraform module to deploy Materialize to Google Kubernetes Engine (GKE).

- name: install-uses-self-signed-cluster-issuer
  content: |
    The example uses a self-signed ClusterIssuer. As such, you may encounter a
    warning with regards to the certificate. In production, run with
    certificates from an official Certificate Authority (CA) rather than
    self-signed certificates.

- name: installation-verify-status
  content: |
    {{< tabs >}}
    {{< tab "Operator" >}}
    To check the status of the Materialize operator, which runs in the `materialize` namespace:
    ```bash
    kubectl -n materialize get all
    ```
    {{< /tabs >}}
    {{< tab "Materialize instance" >}}
    To check the status of the Materialize instance, which runs in the `materialize-environment` namespace:
    ```bash
    kubectl -n materialize-environment get all
    ```
    {{< /tab >}}
    {{< /tabs >}}

    If you run into an error during deployment, refer to the
    [Troubleshooting](/self-managed-deployments/troubleshooting/).

- name: installation-tfvars-variables-optional
  content: |
    **Optional variables**:

    - `internal_load_balancer`: Flag that determines whether the load balancer
      is internal (default) or public.
    - `ingress_cidr_blocks`: List of CIDR blocks allowed to reach the load
      balancer if the load balancer is public (`internal_load_balancer: false`).
      If unset, defaults to `["0.0.0.0/0"]` (i.e., <red>**all**</red> IPv4
      addresses on the internet). **Only applied when the load balancer is public**.
    - `k8s_apiserver_authorized_networks`: List of CIDR
      blocks allowed to access your cluster endpoint. If unset, defaults to
      `["0.0.0.0/0"]` (<red>**all**</red> IPv4 addresses on the internet).

    {{< note >}}
    Refer to your organization's security practices to set these values accordingly.
    {{< /note >}}

- name: installation-access-methods
  content: |
    {{< note >}}
    - **If using a public NLB:** Both SQL and Console are available via the
    public NLB. You can connect directly using the NLB's DNS name from anywhere
    on the internet (subject to your `ingress_cidr_blocks` configuration).

    - **If using a private (internal) NLB:** You can connect from inside the same VPC or from networks that are privately connected to it. Alternatively, use Kubernetes port-forwarding for both SQL and Console.
    {{< /note >}}
