`client_id` | `text` | Use the supplied value as the Kafka client identifier.
`group_id_prefix` | `text` | Use the specified prefix in the consumer group ID. The resulting `group.id` looks like `<group_id_prefix>materialize-X-Y`, where `X` and `Y` are values that allow multiple concurrent Kafka consumers from the same topic.
`ignore_source_keys` | `boolean` | Default: `false`. If `true`, do not perform optimizations assuming uniqueness of primary keys in schemas.
`isolation_level` | `text` | Default: `read_committed`. Controls how to read messages that were transactionally written to Kafka. Supported options are `read_committed` to read only committed messages and `read_uncommitted` to read all messages, including those that are part of an open transaction or were aborted.
`security_protocol` | `text` | Use [`ssl`](#ssl-with-options) or, for [Kerberos](#kerberized-kafka-details), `sasl_plaintext`, `sasl-scram-sha-256`, or `sasl-sha-512` to connect to the Kafka cluster.
`kafka_time_offset` | `int` | Use the specified value to set `start_offset` based on the Kafka timestamp. Negative values will be interpreted as relative to the current system time in milliseconds (e.g. `-1000` means 1000 ms ago). The offset for each partition will be the earliest offset whose timestamp is greater than or equal to the given timestamp in the corresponding partition. If no such offset exists for a partition, the partition's end offset will be used.
`statistics_interval_ms` | `int` | `librdkafka` statistics emit interval in `ms`. Accepts values [0, 86400000]. A value of 0 disables statistics. Statistics can be queried using the `mz_kafka_consumer_partitions` system table.
`start_offset`| `int` | Read partitions from the specified offset. You cannot update the offsets once a source has been created; you will need to recreate the source. Values must be zero or positive integers. See [Kafka source details](#partition-offsets) for important warnings for this feature.
`timestamp_frequency_ms`| `int` | Default: `1000`. Sets the timestamping frequency in `ms`. Reflects how frequently the source advances its timestamp. This measure reflects how stale data in views will be. Lower values result in more-up-to-date views but may reduce throughput.
`topic_metadata_refresh_interval_ms` | `int` | Default: `30000`. Sets the frequency in `ms` at which the system checks for new partitions. Accepts values [0,3600000].
`enable_auto_commit` | `boolean`| Default: `false`. Controls whether or not Materialize commits read offsets back into Kafka. This is purely for consumer progress monitoring and does not cause Materialize to resume reading from where it left off across restarts.

#### SSL `WITH` options

Use the following options to connect Materialize to an SSL-encrypted Kafka
cluster. For more detail, see [SSL-encrypted Kafka details](#ssl-encrypted-kafka-details).

Field | Value | Description
------|-------|------------
`ssl_certificate_location` | `text` | The absolute path to your SSL certificate. Required for SSL client authentication.
`ssl_key_location` | `text` | The absolute path to your SSL certificate's key. Required for SSL client authentication.
`ssl_key_password` | `text` | Your SSL key's password, if any.
`ssl_ca_location` | `text` | The absolute path to the certificate authority (CA) certificate. Used for both SSL client and server authentication. If unspecified, uses the system's default CA certificates.

#### Kerberos `WITH` options

Use the following options to connect Materialize to a Kerberized Kafka
cluster. For more detail, see [Kerberized Kafka details](#kerberized-kafka-details).

Field | Value | Description
------|-------|------------
`sasl_mechanisms` | `text` | The SASL mechanism to use for authentication. Currently, the only supported mechanisms are `GSSAPI` (the default) and `PLAIN`.
`sasl_username` | `text` | Your SASL username, if any. Required if `sasl_mechanisms` is `PLAIN`.
`sasl_password` | `text` | Your SASL password, if any. Required if `sasl_mechanisms` is `PLAIN`.<br/><br/>This option stores the password in Materialize's on-disk catalog. For an alternative, use `sasl_password_env`.
`sasl_password_env` | `text` | Use the value stored in the named environment variable as the value for `sasl_password`. <br/><br/>This option does not store the password on-disk in Materialize's catalog, but requires the environment variable's presence to boot Materialize.
`sasl_kerberos_keytab` | `text` | The absolute path to your keytab. Required if `sasl_mechanisms` is `GSSAPI`.
`sasl_kerberos_kinit_cmd` | `text` | Shell command to refresh or acquire the client's Kerberos ticket. Required if `sasl_mechanisms` is `GSSAPI`.
`sasl_kerberos_min_time_before_relogin` | `text` | Minimum time in milliseconds between key refresh attempts. Disable automatic key refresh by setting this property to 0. Required if `sasl_mechanisms` is `GSSAPI`.
`sasl_kerberos_principal` | `text` | Materialize Kerberos principal name. Required if `sasl_mechanisms` is `GSSAPI`.
`sasl_kerberos_service_name` | `text` | Kafka's service name on its host, i.e. the service principal name not including `/hostname@REALM`. Required if `sasl_mechanisms` is `GSSAPI`.

#### Inline schema `WITH` options

Field | Value | Description
------|-------|------------
`confluent_wire_format` | `boolean` | Whether to look for the Confluent Schema Registry schema ID within Avro messages.

If you specify a source with an inline schemas you may still have records that are generated by a
client that inlines a confluent schema registry ID at the beginning of each record. If
`confluent_wire_format` is `false` then `materialized` will *not* validate that a well-formatted
schema-id is present at the beginning of each record.
