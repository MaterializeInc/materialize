===> ENV Variables ...
ALLOW_UNSIGNED=false
COMPONENT=kafka
CONFLUENT_DEB_VERSION=1
CONFLUENT_MAJOR_VERSION=5
CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS=kafka:9092
CONFLUENT_METRICS_REPORTER_TOPIC_CREATE=false
CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS=1
CONFLUENT_MINOR_VERSION=3
CONFLUENT_MVN_LABEL=
CONFLUENT_PATCH_VERSION=0
CONFLUENT_PLATFORM_LABEL=
CONFLUENT_VERSION=5.3.0
CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
HOME=/root
HOSTNAME=761aac12be55
KAFKA_ADVERTISED_HOST_NAME=kafka
KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://kafka:9093
KAFKA_BROKER_ID=1
KAFKA_JMX_PORT=9991
KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
KAFKA_METRIC_REPORTERS=io.confluent.metrics.reporter.ConfluentMetricsReporter
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
KAFKA_VERSION=5.3.0
KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
LANG=C.UTF-8
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PWD=/
PYTHON_PIP_VERSION=8.1.2
PYTHON_VERSION=2.7.9-1
SCALA_VERSION=2.12
SHLVL=1
ZULU_OPENJDK_VERSION=8=8.38.0.13
_=/usr/bin/env
===> User
uid=0(root) gid=0(root) groups=0(root)
===> Configuring ...
===> Running preflight checks ... 
===> Check if /var/lib/kafka/data is writable ...
===> Check if Zookeeper is healthy ...
===> Launching ... 
===> Launching kafka ... 
[2020-11-25 21:11:23,877] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-11-25 21:11:24,360] INFO KafkaConfig values: 
	advertised.host.name = kafka
	advertised.listeners = PLAINTEXT://kafka:9092,EXTERNAL://kafka:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
	listeners = PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-11-25 21:11:24,447] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[2020-11-25 21:11:24,456] WARN Please note that the support metrics collection feature ("Metrics") of Proactive Support is enabled.  With Metrics enabled, this broker is configured to collect and report certain broker and cluster metadata ("Metadata") about your use of the Confluent Platform (including without limitation, your remote internet protocol address) to Confluent, Inc. ("Confluent") or its parent, subsidiaries, affiliates or service providers every 24hours.  This Metadata may be transferred to any country in which Confluent maintains facilities.  For a more in depth discussion of how Confluent processes such information, please read our Privacy Policy located at http://www.confluent.io/privacy. By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer, storage and use of Metadata by Confluent.  You can turn the Metrics feature off by setting `confluent.support.metrics.enable=false` in the broker configuration and restarting the broker.  See the Confluent Platform documentation for further information. (io.confluent.support.metrics.SupportedServerStartable)
[2020-11-25 21:11:24,459] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-11-25 21:11:24,459] INFO starting (kafka.server.KafkaServer)
[2020-11-25 21:11:24,460] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2020-11-25 21:11:24,480] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-11-25 21:11:24,484] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,484] INFO Client environment:host.name=761aac12be55 (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,484] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,484] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,484] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,484] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/confluent-metrics-5.3.0-ce.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/avro-1.8.1.jar:/usr/bin/../share/java/kafka/kafka-clients-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.28.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/usr/bin/../share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/bin/../share/java/kafka/support-metrics-common-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/guava-20.0.jar:/usr/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/bin/../share/java/kafka/reflections-0.9.11.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/bin/../share/java/kafka/hk2-api-2.5.0.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/jsr305-3.0.2.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/connect-api-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.26.jar:/usr/bin/../share/java/kafka/scala-reflect-2.12.8.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpcore-4.4.11.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.0-ccs-sources.jar:/usr/bin/../share/java/kafka/jackson-databind-2.9.9.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.12-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.0-ccs-javadoc.jar:/usr/bin/../share/java/kafka/connect-file-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.0-ccs-test.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/paranamer-2.7.jar:/usr/bin/../share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/commons-codec-1.11.jar:/usr/bin/../share/java/kafka/jersey-client-2.28.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/bin/../share/java/kafka/kafka-streams-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/xz-1.5.jar:/usr/bin/../share/java/kafka/connect-transforms-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/support-metrics-client-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/usr/bin/../share/java/kafka/jersey-server-2.28.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jackson-core-2.9.9.jar:/usr/bin/../share/java/kafka/zkclient-0.11.jar:/usr/bin/../share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/bin/../share/java/kafka/connect-json-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/httpclient-4.5.7.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/scala-library-2.12.8.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/bin/../share/java/kafka/commons-compress-1.8.1.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.14.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.0-ccs-scaladoc.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka-tools-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/bin/../share/java/kafka/httpmime-4.5.7.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/bin/../share/java/kafka/connect-runtime-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/usr/bin/../share/java/kafka/lz4-java-1.6.0.jar:/usr/bin/../share/java/kafka/jersey-common-2.28.jar:/usr/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/usr/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.0-ccs-test-sources.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-5.3.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/usr/bin/../support-metrics-client/build/dependant-libs-2.12/*:/usr/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,485] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,485] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,485] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,485] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,485] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,485] INFO Client environment:os.version=5.8.0-29-generic (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,485] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,485] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,485] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,487] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6e20b53a (org.apache.zookeeper.ZooKeeper)
[2020-11-25 21:11:24,497] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-11-25 21:11:24,503] INFO Opening socket connection to server zookeeper/172.23.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-11-25 21:11:24,510] INFO Socket connection established to zookeeper/172.23.0.4:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-11-25 21:11:24,517] INFO Session establishment complete on server zookeeper/172.23.0.4:2181, sessionid = 0x100085764300003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-11-25 21:11:24,523] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-11-25 21:11:24,974] INFO Cluster ID = rBJq9R_ZQCmo8cVU9ooR3Q (kafka.server.KafkaServer)
[2020-11-25 21:11:24,979] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-11-25 21:11:25,061] INFO KafkaConfig values: 
	advertised.host.name = kafka
	advertised.listeners = PLAINTEXT://kafka:9092,EXTERNAL://kafka:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
	listeners = PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-11-25 21:11:25,074] INFO KafkaConfig values: 
	advertised.host.name = kafka
	advertised.listeners = PLAINTEXT://kafka:9092,EXTERNAL://kafka:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
	listeners = PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-11-25 21:11:25,104] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-11-25 21:11:25,105] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-11-25 21:11:25,105] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-11-25 21:11:25,148] INFO Loading logs. (kafka.log.LogManager)
[2020-11-25 21:11:25,157] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-11-25 21:11:25,175] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-11-25 21:11:25,179] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-11-25 21:11:25,182] INFO Starting the log cleaner (kafka.log.LogCleaner)
[2020-11-25 21:11:25,284] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
[2020-11-25 21:11:25,567] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-11-25 21:11:25,598] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-11-25 21:11:25,602] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-11-25 21:11:25,614] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9093,ListenerName(EXTERNAL),PLAINTEXT) (kafka.network.SocketServer)
[2020-11-25 21:11:25,615] INFO [SocketServer brokerId=1] Started 2 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-11-25 21:11:25,647] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-11-25 21:11:25,647] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-11-25 21:11:25,648] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-11-25 21:11:25,648] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-11-25 21:11:25,662] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-11-25 21:11:25,700] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-11-25 21:11:25,733] INFO Stat of the created znode at /brokers/ids/1 is: 31,31,1606338685720,1606338685720,1,0,0,72066765473972227,229,0,31
 (kafka.zk.KafkaZkClient)
[2020-11-25 21:11:25,734] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka,9092,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka,9093,ListenerName(EXTERNAL),PLAINTEXT)), czxid (broker epoch): 31 (kafka.zk.KafkaZkClient)
[2020-11-25 21:11:25,736] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-11-25 21:11:25,829] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
[2020-11-25 21:11:25,837] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-11-25 21:11:25,840] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-11-25 21:11:25,841] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-11-25 21:11:25,856] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-11-25 21:11:25,864] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1 (kafka.controller.KafkaController)
[2020-11-25 21:11:25,865] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
[2020-11-25 21:11:25,868] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:25,869] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
[2020-11-25 21:11:25,870] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:25,874] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
[2020-11-25 21:11:25,874] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:25,877] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
[2020-11-25 21:11:25,888] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-11-25 21:11:25,916] INFO [Controller id=1] Initialized broker epochs cache: Map(1 -> 31) (kafka.controller.KafkaController)
[2020-11-25 21:11:25,919] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-11-25 21:11:25,921] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-11-25 21:11:25,922] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
[2020-11-25 21:11:25,922] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-11-25 21:11:25,928] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
[2020-11-25 21:11:25,936] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
[2020-11-25 21:11:25,938] INFO [Controller id=1] Partitions being reassigned: Map() (kafka.controller.KafkaController)
[2020-11-25 21:11:25,939] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
[2020-11-25 21:11:25,939] INFO [Controller id=1] Currently shutting brokers in the cluster: Set() (kafka.controller.KafkaController)
[2020-11-25 21:11:25,940] INFO [Controller id=1] Current list of topics in the cluster: Set() (kafka.controller.KafkaController)
[2020-11-25 21:11:25,940] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
[2020-11-25 21:11:25,944] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
[2020-11-25 21:11:25,944] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
[2020-11-25 21:11:25,944] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
[2020-11-25 21:11:25,945] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: Set() (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:25,946] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
[2020-11-25 21:11:25,960] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
[2020-11-25 21:11:25,961] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
[2020-11-25 21:11:25,966] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
[2020-11-25 21:11:25,966] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map() (kafka.controller.ZkReplicaStateMachine)
[2020-11-25 21:11:25,967] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
[2020-11-25 21:11:25,968] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
[2020-11-25 21:11:25,969] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:9092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
[2020-11-25 21:11:25,971] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map() (kafka.controller.ZkPartitionStateMachine)
[2020-11-25 21:11:25,971] INFO [Controller id=1] Ready to serve as the new controller with epoch 1 (kafka.controller.KafkaController)
[2020-11-25 21:11:25,973] INFO [Controller id=1] Removing partitions Set() from the list of reassigned partitions in zookeeper (kafka.controller.KafkaController)
[2020-11-25 21:11:25,973] INFO [Controller id=1] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions (kafka.controller.KafkaController)
[2020-11-25 21:11:25,978] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
[2020-11-25 21:11:25,979] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
[2020-11-25 21:11:25,979] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
[2020-11-25 21:11:25,979] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
[2020-11-25 21:11:25,980] INFO [Controller id=1] Starting preferred replica leader election for partitions  (kafka.controller.KafkaController)
[2020-11-25 21:11:25,982] INFO ConfluentMetricsReporterConfig values: 
	confluent.metrics.reporter.bootstrap.servers = kafka:9092
	confluent.metrics.reporter.publish.ms = 15000
	confluent.metrics.reporter.topic = _confluent-metrics
	confluent.metrics.reporter.topic.create = false
	confluent.metrics.reporter.topic.max.message.bytes = 10485760
	confluent.metrics.reporter.topic.partitions = 12
	confluent.metrics.reporter.topic.replicas = 1
	confluent.metrics.reporter.topic.retention.bytes = -1
	confluent.metrics.reporter.topic.retention.ms = 259200000
	confluent.metrics.reporter.topic.roll.ms = 14400000
	confluent.metrics.reporter.volume.metrics.refresh.ms = 15000
	confluent.metrics.reporter.whitelist = .*MaxLag.*|kafka.log:type=Log,name=Size.*|.*name=(ActiveControllerCount|BytesInPerSec|BytesOutPerSec|FailedFetchRequestsPerSec|FailedProduceRequestsPerSec|InSyncReplicasCount|LeaderCount|LeaderElectionRateAndTimeMs|LocalTimeMs|LogEndOffset|LogStartOffset|NetworkProcessorAvgIdlePercent|NumLogSegments|OfflinePartitionsCount|PartitionCount|RemoteTimeMs|ReplicasCount|RequestHandlerAvgIdlePercent|RequestQueueSize|RequestQueueTimeMs|RequestsPerSec|ResponseQueueSize|ResponseQueueTimeMs|ResponseSendTimeMs|Size|TotalFetchRequestsPerSec|TotalProduceRequestsPerSec|TotalTimeMs|UncleanLeaderElectionsPerSec|UnderReplicated|UnderReplicatedPartitions|ZooKeeperDisconnectsPerSec|ZooKeeperExpiresPerSec).*
 (io.confluent.metrics.reporter.ConfluentMetricsReporterConfig)
[2020-11-25 21:11:25,996] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
[2020-11-25 21:11:26,002] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [kafka:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = confluent-metrics-reporter
	compression.type = lz4
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 10485760
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig)
[2020-11-25 21:11:26,020] WARN The configuration 'topic.create' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[2020-11-25 21:11:26,020] WARN The configuration 'topic.replicas' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[2020-11-25 21:11:26,023] INFO Kafka version: 5.3.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2020-11-25 21:11:26,023] INFO Kafka commitId: a8eb7a79910d0f1a (org.apache.kafka.common.utils.AppInfoParser)
[2020-11-25 21:11:26,023] INFO Kafka startTimeMs: 1606338686020 (org.apache.kafka.common.utils.AppInfoParser)
[2020-11-25 21:11:26,027] INFO Starting Confluent metrics reporter for cluster id rBJq9R_ZQCmo8cVU9ooR3Q with an interval of 15000 ms (io.confluent.metrics.reporter.ConfluentMetricsReporter)
[2020-11-25 21:11:26,041] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-11-25 21:11:26,053] INFO [SocketServer brokerId=1] Started data-plane processors for 2 acceptors (kafka.network.SocketServer)
[2020-11-25 21:11:26,054] INFO Kafka version: 5.3.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2020-11-25 21:11:26,055] INFO Kafka commitId: a8eb7a79910d0f1a (org.apache.kafka.common.utils.AppInfoParser)
[2020-11-25 21:11:26,055] INFO Kafka startTimeMs: 1606338686054 (org.apache.kafka.common.utils.AppInfoParser)
[2020-11-25 21:11:26,055] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-11-25 21:11:26,056] INFO Waiting until monitored service is ready for metrics collection (io.confluent.support.metrics.BaseMetricsReporter)
[2020-11-25 21:11:26,058] INFO Monitored service is now ready (io.confluent.support.metrics.BaseMetricsReporter)
[2020-11-25 21:11:26,058] INFO Attempting to collect and submit metrics (io.confluent.support.metrics.BaseMetricsReporter)
[2020-11-25 21:11:26,085] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 0 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:26,340] WARN The replication factor of topic __confluent.support.metrics will be set to 1, which is less than the desired replication factor of 3 (reason: this cluster contains only 1 brokers).  If you happen to add more brokers to this cluster, then it is important to increase the replication factor of the topic to eventually 3 to ensure reliable and durable metrics collection. (io.confluent.support.metrics.common.kafka.KafkaUtilities)
[2020-11-25 21:11:26,340] INFO Attempting to create topic __confluent.support.metrics with 1 replicas, assuming 1 total brokers (io.confluent.support.metrics.common.kafka.KafkaUtilities)
[2020-11-25 21:11:26,365] INFO Creating topic __confluent.support.metrics with configuration {retention.ms=31536000000} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:26,392] INFO [Controller id=1] New topics: [Set(__confluent.support.metrics)], deleted topics: [Set()], new partition replica assignment [Map(__confluent.support.metrics-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:26,392] INFO [Controller id=1] New partition creation callback for __confluent.support.metrics-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:26,397] TRACE [Controller id=1 epoch=1] Changed partition __confluent.support.metrics-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,404] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __confluent.support.metrics-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,437] TRACE [Controller id=1 epoch=1] Changed partition __confluent.support.metrics-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,438] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __confluent.support.metrics-0 (state.change.logger)
[2020-11-25 21:11:26,440] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __confluent.support.metrics-0 (state.change.logger)
[2020-11-25 21:11:26,442] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __confluent.support.metrics-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,445] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 1 from controller 1 epoch 1 for partition __confluent.support.metrics-0 (state.change.logger)
[2020-11-25 21:11:26,456] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 1 starting the become-leader transition for partition __confluent.support.metrics-0 (state.change.logger)
[2020-11-25 21:11:26,459] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__confluent.support.metrics-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:26,494] INFO ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://kafka:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig)
[2020-11-25 21:11:26,499] INFO Kafka version: 5.3.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2020-11-25 21:11:26,499] INFO Kafka commitId: a8eb7a79910d0f1a (org.apache.kafka.common.utils.AppInfoParser)
[2020-11-25 21:11:26,499] INFO Kafka startTimeMs: 1606338686499 (org.apache.kafka.common.utils.AppInfoParser)
[2020-11-25 21:11:26,523] INFO [Producer clientId=confluent-metrics-reporter] Cluster ID: rBJq9R_ZQCmo8cVU9ooR3Q (org.apache.kafka.clients.Metadata)
[2020-11-25 21:11:26,532] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 1 : {__confluent.support.metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[2020-11-25 21:11:26,532] INFO [Producer clientId=producer-1] Cluster ID: rBJq9R_ZQCmo8cVU9ooR3Q (org.apache.kafka.clients.Metadata)
[2020-11-25 21:11:26,534] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,542] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2020-11-25 21:11:26,544] INFO Created log for partition __confluent.support.metrics-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 31536000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,544] INFO [Partition __confluent.support.metrics-0 broker=1] No checkpointed highwatermark is found for partition __confluent.support.metrics-0 (kafka.cluster.Partition)
[2020-11-25 21:11:26,546] INFO Replica loaded for partition __confluent.support.metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,549] INFO [Partition __confluent.support.metrics-0 broker=1] __confluent.support.metrics-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,571] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 1 for partition __confluent.support.metrics-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,572] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 1 for the become-leader transition for partition __confluent.support.metrics-0 (state.change.logger)
[2020-11-25 21:11:26,578] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=__confluent.support.metrics,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:26,585] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __confluent.support.metrics-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 2 (state.change.logger)
[2020-11-25 21:11:26,585] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 2 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:26,601] INFO Creating topic connect_offsets with configuration {cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:26,617] INFO [Controller id=1] New topics: [Set(connect_offsets)], deleted topics: [Set()], new partition replica assignment [Map(connect_offsets-14 -> Vector(1), connect_offsets-1 -> Vector(1), connect_offsets-20 -> Vector(1), connect_offsets-19 -> Vector(1), connect_offsets-15 -> Vector(1), connect_offsets-11 -> Vector(1), connect_offsets-5 -> Vector(1), connect_offsets-13 -> Vector(1), connect_offsets-8 -> Vector(1), connect_offsets-24 -> Vector(1), connect_offsets-16 -> Vector(1), connect_offsets-23 -> Vector(1), connect_offsets-6 -> Vector(1), connect_offsets-2 -> Vector(1), connect_offsets-22 -> Vector(1), connect_offsets-9 -> Vector(1), connect_offsets-17 -> Vector(1), connect_offsets-4 -> Vector(1), connect_offsets-12 -> Vector(1), connect_offsets-3 -> Vector(1), connect_offsets-7 -> Vector(1), connect_offsets-18 -> Vector(1), connect_offsets-10 -> Vector(1), connect_offsets-21 -> Vector(1), connect_offsets-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:26,617] INFO [Controller id=1] New partition creation callback for connect_offsets-14,connect_offsets-1,connect_offsets-20,connect_offsets-19,connect_offsets-15,connect_offsets-11,connect_offsets-5,connect_offsets-13,connect_offsets-8,connect_offsets-24,connect_offsets-16,connect_offsets-23,connect_offsets-6,connect_offsets-2,connect_offsets-22,connect_offsets-9,connect_offsets-17,connect_offsets-4,connect_offsets-12,connect_offsets-3,connect_offsets-7,connect_offsets-18,connect_offsets-10,connect_offsets-21,connect_offsets-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:26,618] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-14 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,618] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,618] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-20 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,618] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-19 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,618] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-15 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,618] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-11 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,618] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-5 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-13 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-8 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-24 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-16 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-23 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-6 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-22 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-9 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-17 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,619] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-12 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,620] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,620] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-7 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,620] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-18 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,620] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-10 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,620] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-21 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,620] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-16 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-9 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-8 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-18 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-2 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-19 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-20 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-13 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-14 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-23 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-4 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-6 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-5 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-17 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-22 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,623] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-11 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,624] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-3 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,624] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-7 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,624] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-21 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,624] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-15 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,624] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-24 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,624] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-10 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,624] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-12 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,624] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-1 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:26,696] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-14 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,696] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,696] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-20 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,696] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-19 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,696] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-15 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,696] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-13 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-24 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-16 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-23 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-22 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,697] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,698] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-17 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,698] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,698] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-12 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,698] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,698] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,698] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-18 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,698] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,698] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-21 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,698] TRACE [Controller id=1 epoch=1] Changed partition connect_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:26,699] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-10 (state.change.logger)
[2020-11-25 21:11:26,699] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-21 (state.change.logger)
[2020-11-25 21:11:26,699] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-7 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-18 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-15 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-4 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-20 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-9 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-23 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-1 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-12 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-6 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-17 (state.change.logger)
[2020-11-25 21:11:26,700] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-14 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-3 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-11 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-22 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-0 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-16 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-19 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-8 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-2 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-24 (state.change.logger)
[2020-11-25 21:11:26,701] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-13 (state.change.logger)
[2020-11-25 21:11:26,702] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_offsets-5 (state.change.logger)
[2020-11-25 21:11:26,702] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-10 (state.change.logger)
[2020-11-25 21:11:26,703] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-21 (state.change.logger)
[2020-11-25 21:11:26,703] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-7 (state.change.logger)
[2020-11-25 21:11:26,703] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-18 (state.change.logger)
[2020-11-25 21:11:26,703] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-15 (state.change.logger)
[2020-11-25 21:11:26,703] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-4 (state.change.logger)
[2020-11-25 21:11:26,703] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-20 (state.change.logger)
[2020-11-25 21:11:26,703] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-9 (state.change.logger)
[2020-11-25 21:11:26,703] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-23 (state.change.logger)
[2020-11-25 21:11:26,704] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-1 (state.change.logger)
[2020-11-25 21:11:26,704] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-12 (state.change.logger)
[2020-11-25 21:11:26,704] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-6 (state.change.logger)
[2020-11-25 21:11:26,704] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-17 (state.change.logger)
[2020-11-25 21:11:26,704] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-14 (state.change.logger)
[2020-11-25 21:11:26,704] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-3 (state.change.logger)
[2020-11-25 21:11:26,704] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-11 (state.change.logger)
[2020-11-25 21:11:26,704] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-22 (state.change.logger)
[2020-11-25 21:11:26,704] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-0 (state.change.logger)
[2020-11-25 21:11:26,705] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-16 (state.change.logger)
[2020-11-25 21:11:26,705] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-19 (state.change.logger)
[2020-11-25 21:11:26,705] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-8 (state.change.logger)
[2020-11-25 21:11:26,705] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-2 (state.change.logger)
[2020-11-25 21:11:26,705] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-24 (state.change.logger)
[2020-11-25 21:11:26,705] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-13 (state.change.logger)
[2020-11-25 21:11:26,705] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_offsets-5 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-1 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-3 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-5 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-7 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-9 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-11 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-14 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-16 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-16 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-18 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-9 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-20 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-8 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-22 (state.change.logger)
[2020-11-25 21:11:26,707] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-18 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-24 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-0 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-2 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-2 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-4 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-19 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-6 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-20 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-8 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-13 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-10 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-14 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-12 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-23 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-13 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-15 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-4 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-17 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-6 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-19 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-5 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-21 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-17 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 3 from controller 1 epoch 1 for partition connect_offsets-23 (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-22 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-11 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,709] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-3 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,709] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-7 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,709] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-21 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,709] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-15 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,709] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-24 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,709] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-10 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,709] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-12 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,709] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_offsets-1 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:26,720] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer)
[2020-11-25 21:11:26,722] INFO Successfully submitted metrics to Kafka topic __confluent.support.metrics (io.confluent.support.metrics.submitters.KafkaSubmitter)
[2020-11-25 21:11:26,736] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-17 (state.change.logger)
[2020-11-25 21:11:26,736] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-14 (state.change.logger)
[2020-11-25 21:11:26,736] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-11 (state.change.logger)
[2020-11-25 21:11:26,736] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-8 (state.change.logger)
[2020-11-25 21:11:26,736] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-5 (state.change.logger)
[2020-11-25 21:11:26,736] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-24 (state.change.logger)
[2020-11-25 21:11:26,736] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-21 (state.change.logger)
[2020-11-25 21:11:26,736] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-2 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-18 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-15 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-12 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-9 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-16 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-6 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-13 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-22 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-3 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-10 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-19 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-0 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-7 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-4 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-23 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-20 (state.change.logger)
[2020-11-25 21:11:26,737] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 1 epoch 1 starting the become-leader transition for partition connect_offsets-1 (state.change.logger)
[2020-11-25 21:11:26,737] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(connect_offsets-14, connect_offsets-1, connect_offsets-20, connect_offsets-19, connect_offsets-15, connect_offsets-11, connect_offsets-5, connect_offsets-13, connect_offsets-8, connect_offsets-24, connect_offsets-16, connect_offsets-23, connect_offsets-6, connect_offsets-2, connect_offsets-22, connect_offsets-9, connect_offsets-17, connect_offsets-4, connect_offsets-12, connect_offsets-3, connect_offsets-7, connect_offsets-18, connect_offsets-10, connect_offsets-21, connect_offsets-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:26,743] INFO [Log partition=connect_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,743] INFO [Log partition=connect_offsets-17, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:26,744] INFO Created log for partition connect_offsets-17 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,745] INFO [Partition connect_offsets-17 broker=1] No checkpointed highwatermark is found for partition connect_offsets-17 (kafka.cluster.Partition)
[2020-11-25 21:11:26,745] INFO Replica loaded for partition connect_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,745] INFO [Partition connect_offsets-17 broker=1] connect_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,750] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-17 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,754] INFO [Log partition=connect_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,756] INFO [Log partition=connect_offsets-14, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-11-25 21:11:26,757] INFO Created log for partition connect_offsets-14 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,757] INFO [Partition connect_offsets-14 broker=1] No checkpointed highwatermark is found for partition connect_offsets-14 (kafka.cluster.Partition)
[2020-11-25 21:11:26,757] INFO Replica loaded for partition connect_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,757] INFO [Partition connect_offsets-14 broker=1] connect_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,762] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-14 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,767] INFO [Log partition=connect_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,767] INFO [Log partition=connect_offsets-11, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:26,769] INFO Created log for partition connect_offsets-11 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,769] INFO [Partition connect_offsets-11 broker=1] No checkpointed highwatermark is found for partition connect_offsets-11 (kafka.cluster.Partition)
[2020-11-25 21:11:26,769] INFO Replica loaded for partition connect_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,769] INFO [Partition connect_offsets-11 broker=1] connect_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,774] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-11 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,778] INFO [Log partition=connect_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,779] INFO [Log partition=connect_offsets-8, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:26,780] INFO Created log for partition connect_offsets-8 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,780] INFO [Partition connect_offsets-8 broker=1] No checkpointed highwatermark is found for partition connect_offsets-8 (kafka.cluster.Partition)
[2020-11-25 21:11:26,781] INFO Replica loaded for partition connect_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,781] INFO [Partition connect_offsets-8 broker=1] connect_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,785] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-8 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,789] INFO [Log partition=connect_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,789] INFO [Log partition=connect_offsets-5, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:26,790] INFO Created log for partition connect_offsets-5 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,791] INFO [Partition connect_offsets-5 broker=1] No checkpointed highwatermark is found for partition connect_offsets-5 (kafka.cluster.Partition)
[2020-11-25 21:11:26,791] INFO Replica loaded for partition connect_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,791] INFO [Partition connect_offsets-5 broker=1] connect_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,795] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-5 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,799] INFO [Log partition=connect_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,799] INFO [Log partition=connect_offsets-24, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:26,800] INFO Created log for partition connect_offsets-24 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,801] INFO [Partition connect_offsets-24 broker=1] No checkpointed highwatermark is found for partition connect_offsets-24 (kafka.cluster.Partition)
[2020-11-25 21:11:26,801] INFO Replica loaded for partition connect_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,801] INFO [Partition connect_offsets-24 broker=1] connect_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,805] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-24 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,811] INFO [Log partition=connect_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,812] INFO [Log partition=connect_offsets-21, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-11-25 21:11:26,813] INFO Created log for partition connect_offsets-21 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,814] INFO [Partition connect_offsets-21 broker=1] No checkpointed highwatermark is found for partition connect_offsets-21 (kafka.cluster.Partition)
[2020-11-25 21:11:26,814] INFO Replica loaded for partition connect_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,814] INFO [Partition connect_offsets-21 broker=1] connect_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,818] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-21 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,823] INFO [Log partition=connect_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,824] INFO [Log partition=connect_offsets-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:26,825] INFO Created log for partition connect_offsets-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,826] INFO [Partition connect_offsets-2 broker=1] No checkpointed highwatermark is found for partition connect_offsets-2 (kafka.cluster.Partition)
[2020-11-25 21:11:26,826] INFO Replica loaded for partition connect_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,826] INFO [Partition connect_offsets-2 broker=1] connect_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,830] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-2 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,835] INFO [Log partition=connect_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,835] INFO [Log partition=connect_offsets-18, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:26,837] INFO Created log for partition connect_offsets-18 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,837] INFO [Partition connect_offsets-18 broker=1] No checkpointed highwatermark is found for partition connect_offsets-18 (kafka.cluster.Partition)
[2020-11-25 21:11:26,837] INFO Replica loaded for partition connect_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,837] INFO [Partition connect_offsets-18 broker=1] connect_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,841] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-18 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,846] INFO [Log partition=connect_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,846] INFO [Log partition=connect_offsets-15, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:26,848] INFO Created log for partition connect_offsets-15 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,848] INFO [Partition connect_offsets-15 broker=1] No checkpointed highwatermark is found for partition connect_offsets-15 (kafka.cluster.Partition)
[2020-11-25 21:11:26,848] INFO Replica loaded for partition connect_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,848] INFO [Partition connect_offsets-15 broker=1] connect_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,853] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-15 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,858] INFO [Log partition=connect_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,859] INFO [Log partition=connect_offsets-12, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-11-25 21:11:26,860] INFO Created log for partition connect_offsets-12 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,860] INFO [Partition connect_offsets-12 broker=1] No checkpointed highwatermark is found for partition connect_offsets-12 (kafka.cluster.Partition)
[2020-11-25 21:11:26,860] INFO Replica loaded for partition connect_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,860] INFO [Partition connect_offsets-12 broker=1] connect_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,864] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-12 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,869] INFO [Log partition=connect_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,870] INFO [Log partition=connect_offsets-9, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:26,871] INFO Created log for partition connect_offsets-9 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,871] INFO [Partition connect_offsets-9 broker=1] No checkpointed highwatermark is found for partition connect_offsets-9 (kafka.cluster.Partition)
[2020-11-25 21:11:26,871] INFO Replica loaded for partition connect_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,872] INFO [Partition connect_offsets-9 broker=1] connect_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,876] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-9 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,880] INFO [Log partition=connect_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,881] INFO [Log partition=connect_offsets-16, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:26,882] INFO Created log for partition connect_offsets-16 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,882] INFO [Partition connect_offsets-16 broker=1] No checkpointed highwatermark is found for partition connect_offsets-16 (kafka.cluster.Partition)
[2020-11-25 21:11:26,883] INFO Replica loaded for partition connect_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,883] INFO [Partition connect_offsets-16 broker=1] connect_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,888] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-16 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,900] INFO [Log partition=connect_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,903] INFO [Log partition=connect_offsets-6, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-11-25 21:11:26,906] INFO Created log for partition connect_offsets-6 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,908] INFO [Partition connect_offsets-6 broker=1] No checkpointed highwatermark is found for partition connect_offsets-6 (kafka.cluster.Partition)
[2020-11-25 21:11:26,908] INFO Replica loaded for partition connect_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,908] INFO [Partition connect_offsets-6 broker=1] connect_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,920] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-6 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,926] INFO [Log partition=connect_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,927] INFO [Log partition=connect_offsets-13, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-11-25 21:11:26,928] INFO Created log for partition connect_offsets-13 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,929] INFO [Partition connect_offsets-13 broker=1] No checkpointed highwatermark is found for partition connect_offsets-13 (kafka.cluster.Partition)
[2020-11-25 21:11:26,929] INFO Replica loaded for partition connect_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,929] INFO [Partition connect_offsets-13 broker=1] connect_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,933] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-13 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,938] INFO [Log partition=connect_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,939] INFO [Log partition=connect_offsets-22, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:26,939] INFO Created log for partition connect_offsets-22 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:26,940] INFO [Partition connect_offsets-22 broker=1] No checkpointed highwatermark is found for partition connect_offsets-22 (kafka.cluster.Partition)
[2020-11-25 21:11:26,940] INFO Replica loaded for partition connect_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:26,940] INFO [Partition connect_offsets-22 broker=1] connect_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:26,947] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-22 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:26,998] INFO [Log partition=connect_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:26,998] INFO [Log partition=connect_offsets-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2020-11-25 21:11:26,999] INFO Created log for partition connect_offsets-3 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,000] INFO [Partition connect_offsets-3 broker=1] No checkpointed highwatermark is found for partition connect_offsets-3 (kafka.cluster.Partition)
[2020-11-25 21:11:27,000] INFO Replica loaded for partition connect_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,000] INFO [Partition connect_offsets-3 broker=1] connect_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,005] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-3 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,009] INFO [Log partition=connect_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,009] INFO [Log partition=connect_offsets-10, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,010] INFO Created log for partition connect_offsets-10 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,010] INFO [Partition connect_offsets-10 broker=1] No checkpointed highwatermark is found for partition connect_offsets-10 (kafka.cluster.Partition)
[2020-11-25 21:11:27,011] INFO Replica loaded for partition connect_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,011] INFO [Partition connect_offsets-10 broker=1] connect_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,015] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-10 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,019] INFO [Log partition=connect_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,020] INFO [Log partition=connect_offsets-19, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,021] INFO Created log for partition connect_offsets-19 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,021] INFO [Partition connect_offsets-19 broker=1] No checkpointed highwatermark is found for partition connect_offsets-19 (kafka.cluster.Partition)
[2020-11-25 21:11:27,022] INFO Replica loaded for partition connect_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,022] INFO [Partition connect_offsets-19 broker=1] connect_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,026] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-19 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,030] INFO [Log partition=connect_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,030] INFO [Log partition=connect_offsets-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,032] INFO Created log for partition connect_offsets-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,032] INFO [Partition connect_offsets-0 broker=1] No checkpointed highwatermark is found for partition connect_offsets-0 (kafka.cluster.Partition)
[2020-11-25 21:11:27,032] INFO Replica loaded for partition connect_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,032] INFO [Partition connect_offsets-0 broker=1] connect_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,036] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,041] INFO [Log partition=connect_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,041] INFO [Log partition=connect_offsets-7, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,042] INFO Created log for partition connect_offsets-7 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,042] INFO [Partition connect_offsets-7 broker=1] No checkpointed highwatermark is found for partition connect_offsets-7 (kafka.cluster.Partition)
[2020-11-25 21:11:27,042] INFO Replica loaded for partition connect_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,043] INFO [Partition connect_offsets-7 broker=1] connect_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,047] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-7 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,050] INFO [Log partition=connect_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,051] INFO [Log partition=connect_offsets-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,052] INFO Created log for partition connect_offsets-4 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,053] INFO [Partition connect_offsets-4 broker=1] No checkpointed highwatermark is found for partition connect_offsets-4 (kafka.cluster.Partition)
[2020-11-25 21:11:27,053] INFO Replica loaded for partition connect_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,053] INFO [Partition connect_offsets-4 broker=1] connect_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,057] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-4 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,061] INFO [Log partition=connect_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,061] INFO [Log partition=connect_offsets-23, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,062] INFO Created log for partition connect_offsets-23 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,063] INFO [Partition connect_offsets-23 broker=1] No checkpointed highwatermark is found for partition connect_offsets-23 (kafka.cluster.Partition)
[2020-11-25 21:11:27,063] INFO Replica loaded for partition connect_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,063] INFO [Partition connect_offsets-23 broker=1] connect_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,067] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-23 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,071] INFO [Log partition=connect_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,072] INFO [Log partition=connect_offsets-20, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,073] INFO Created log for partition connect_offsets-20 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,073] INFO [Partition connect_offsets-20 broker=1] No checkpointed highwatermark is found for partition connect_offsets-20 (kafka.cluster.Partition)
[2020-11-25 21:11:27,073] INFO Replica loaded for partition connect_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,073] INFO [Partition connect_offsets-20 broker=1] connect_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,077] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-20 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,082] INFO [Log partition=connect_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,082] INFO [Log partition=connect_offsets-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,084] INFO Created log for partition connect_offsets-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,084] INFO [Partition connect_offsets-1 broker=1] No checkpointed highwatermark is found for partition connect_offsets-1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,084] INFO Replica loaded for partition connect_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,084] INFO [Partition connect_offsets-1 broker=1] connect_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 3 for partition connect_offsets-1 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-17 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-14 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-11 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-8 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-5 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-24 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-21 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-2 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-18 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-15 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-12 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-9 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-16 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-6 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-13 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-22 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-3 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-10 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-19 (state.change.logger)
[2020-11-25 21:11:27,089] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-0 (state.change.logger)
[2020-11-25 21:11:27,090] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-7 (state.change.logger)
[2020-11-25 21:11:27,090] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-4 (state.change.logger)
[2020-11-25 21:11:27,090] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-23 (state.change.logger)
[2020-11-25 21:11:27,090] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-20 (state.change.logger)
[2020-11-25 21:11:27,090] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 1 epoch 1 for the become-leader transition for partition connect_offsets-1 (state.change.logger)
[2020-11-25 21:11:27,093] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=connect_offsets,partition=1,error_code=0},{topic=connect_offsets,partition=3,error_code=0},{topic=connect_offsets,partition=5,error_code=0},{topic=connect_offsets,partition=7,error_code=0},{topic=connect_offsets,partition=9,error_code=0},{topic=connect_offsets,partition=11,error_code=0},{topic=connect_offsets,partition=14,error_code=0},{topic=connect_offsets,partition=16,error_code=0},{topic=connect_offsets,partition=18,error_code=0},{topic=connect_offsets,partition=20,error_code=0},{topic=connect_offsets,partition=22,error_code=0},{topic=connect_offsets,partition=24,error_code=0},{topic=connect_offsets,partition=0,error_code=0},{topic=connect_offsets,partition=2,error_code=0},{topic=connect_offsets,partition=4,error_code=0},{topic=connect_offsets,partition=6,error_code=0},{topic=connect_offsets,partition=8,error_code=0},{topic=connect_offsets,partition=10,error_code=0},{topic=connect_offsets,partition=12,error_code=0},{topic=connect_offsets,partition=13,error_code=0},{topic=connect_offsets,partition=15,error_code=0},{topic=connect_offsets,partition=17,error_code=0},{topic=connect_offsets,partition=19,error_code=0},{topic=connect_offsets,partition=21,error_code=0},{topic=connect_offsets,partition=23,error_code=0}]} for request LEADER_AND_ISR with correlation id 3 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:27,097] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,097] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,097] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,097] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,097] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,097] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,097] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,097] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,097] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,098] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 4 (state.change.logger)
[2020-11-25 21:11:27,108] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 4 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:27,371] INFO Creating topic connect-status with configuration {cleanup.policy=compact} and initial partition assignment Map(2 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:27,381] INFO [Controller id=1] New topics: [Set(connect-status)], deleted topics: [Set()], new partition replica assignment [Map(connect-status-4 -> Vector(1), connect-status-3 -> Vector(1), connect-status-2 -> Vector(1), connect-status-0 -> Vector(1), connect-status-1 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:27,381] INFO [Controller id=1] New partition creation callback for connect-status-4,connect-status-3,connect-status-2,connect-status-0,connect-status-1 (kafka.controller.KafkaController)
[2020-11-25 21:11:27,382] TRACE [Controller id=1 epoch=1] Changed partition connect-status-4 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,382] TRACE [Controller id=1 epoch=1] Changed partition connect-status-3 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,382] TRACE [Controller id=1 epoch=1] Changed partition connect-status-2 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,382] TRACE [Controller id=1 epoch=1] Changed partition connect-status-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,382] TRACE [Controller id=1 epoch=1] Changed partition connect-status-1 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,383] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-3 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,383] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-4 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,383] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-2 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,383] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-1 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,383] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Changed partition connect-status-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Changed partition connect-status-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Changed partition connect-status-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Changed partition connect-status-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Changed partition connect-status-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect-status-2 (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect-status-4 (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect-status-1 (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect-status-3 (state.change.logger)
[2020-11-25 21:11:27,404] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect-status-0 (state.change.logger)
[2020-11-25 21:11:27,405] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect-status-2 (state.change.logger)
[2020-11-25 21:11:27,405] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect-status-4 (state.change.logger)
[2020-11-25 21:11:27,405] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect-status-1 (state.change.logger)
[2020-11-25 21:11:27,405] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect-status-3 (state.change.logger)
[2020-11-25 21:11:27,405] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect-status-0 (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 5 from controller 1 epoch 1 for partition connect-status-1 (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 5 from controller 1 epoch 1 for partition connect-status-2 (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 5 from controller 1 epoch 1 for partition connect-status-0 (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-3 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 5 from controller 1 epoch 1 for partition connect-status-3 (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-4 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 5 from controller 1 epoch 1 for partition connect-status-4 (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-2 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-1 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,406] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect-status-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,411] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition connect-status-1 (state.change.logger)
[2020-11-25 21:11:27,411] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition connect-status-2 (state.change.logger)
[2020-11-25 21:11:27,411] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition connect-status-3 (state.change.logger)
[2020-11-25 21:11:27,411] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition connect-status-0 (state.change.logger)
[2020-11-25 21:11:27,411] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 1 epoch 1 starting the become-leader transition for partition connect-status-4 (state.change.logger)
[2020-11-25 21:11:27,412] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(connect-status-4, connect-status-3, connect-status-2, connect-status-0, connect-status-1) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:27,419] INFO [Log partition=connect-status-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,420] INFO [Log partition=connect-status-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2020-11-25 21:11:27,421] INFO Created log for partition connect-status-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,422] INFO [Partition connect-status-1 broker=1] No checkpointed highwatermark is found for partition connect-status-1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,422] INFO Replica loaded for partition connect-status-1 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,422] INFO [Partition connect-status-1 broker=1] connect-status-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,426] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 5 for partition connect-status-1 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,430] INFO [Log partition=connect-status-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,431] INFO [Log partition=connect-status-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,432] INFO Created log for partition connect-status-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,433] INFO [Partition connect-status-2 broker=1] No checkpointed highwatermark is found for partition connect-status-2 (kafka.cluster.Partition)
[2020-11-25 21:11:27,433] INFO Replica loaded for partition connect-status-2 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,433] INFO [Partition connect-status-2 broker=1] connect-status-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,437] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 5 for partition connect-status-2 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,441] INFO [Log partition=connect-status-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,442] INFO [Log partition=connect-status-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,443] INFO Created log for partition connect-status-3 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,444] INFO [Partition connect-status-3 broker=1] No checkpointed highwatermark is found for partition connect-status-3 (kafka.cluster.Partition)
[2020-11-25 21:11:27,444] INFO Replica loaded for partition connect-status-3 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,444] INFO [Partition connect-status-3 broker=1] connect-status-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,449] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 5 for partition connect-status-3 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,453] INFO [Log partition=connect-status-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,454] INFO [Log partition=connect-status-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,455] INFO Created log for partition connect-status-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,455] INFO [Partition connect-status-0 broker=1] No checkpointed highwatermark is found for partition connect-status-0 (kafka.cluster.Partition)
[2020-11-25 21:11:27,455] INFO Replica loaded for partition connect-status-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,455] INFO [Partition connect-status-0 broker=1] connect-status-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,459] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 5 for partition connect-status-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,464] INFO [Log partition=connect-status-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,465] INFO [Log partition=connect-status-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,465] INFO Created log for partition connect-status-4 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,466] INFO [Partition connect-status-4 broker=1] No checkpointed highwatermark is found for partition connect-status-4 (kafka.cluster.Partition)
[2020-11-25 21:11:27,466] INFO Replica loaded for partition connect-status-4 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,466] INFO [Partition connect-status-4 broker=1] connect-status-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,470] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 5 for partition connect-status-4 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,470] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition connect-status-1 (state.change.logger)
[2020-11-25 21:11:27,470] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition connect-status-2 (state.change.logger)
[2020-11-25 21:11:27,470] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition connect-status-3 (state.change.logger)
[2020-11-25 21:11:27,470] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition connect-status-0 (state.change.logger)
[2020-11-25 21:11:27,470] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 1 epoch 1 for the become-leader transition for partition connect-status-4 (state.change.logger)
[2020-11-25 21:11:27,472] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=connect-status,partition=1,error_code=0},{topic=connect-status,partition=2,error_code=0},{topic=connect-status,partition=0,error_code=0},{topic=connect-status,partition=3,error_code=0},{topic=connect-status,partition=4,error_code=0}]} for request LEADER_AND_ISR with correlation id 5 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:27,473] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect-status-1 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2020-11-25 21:11:27,474] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect-status-2 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2020-11-25 21:11:27,474] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect-status-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2020-11-25 21:11:27,474] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect-status-3 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2020-11-25 21:11:27,474] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect-status-4 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 6 (state.change.logger)
[2020-11-25 21:11:27,475] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 6 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:27,542] INFO Creating topic connect_configs with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:27,554] INFO [Controller id=1] New topics: [Set(connect_configs)], deleted topics: [Set()], new partition replica assignment [Map(connect_configs-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:27,554] INFO [Controller id=1] New partition creation callback for connect_configs-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:27,555] TRACE [Controller id=1 epoch=1] Changed partition connect_configs-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,555] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_configs-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,565] TRACE [Controller id=1 epoch=1] Changed partition connect_configs-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,565] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition connect_configs-0 (state.change.logger)
[2020-11-25 21:11:27,566] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition connect_configs-0 (state.change.logger)
[2020-11-25 21:11:27,567] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition connect_configs-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,567] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 7 from controller 1 epoch 1 for partition connect_configs-0 (state.change.logger)
[2020-11-25 21:11:27,568] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 7 from controller 1 epoch 1 starting the become-leader transition for partition connect_configs-0 (state.change.logger)
[2020-11-25 21:11:27,568] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(connect_configs-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:27,573] INFO [Log partition=connect_configs-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,574] INFO [Log partition=connect_configs-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,575] INFO Created log for partition connect_configs-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,575] INFO [Partition connect_configs-0 broker=1] No checkpointed highwatermark is found for partition connect_configs-0 (kafka.cluster.Partition)
[2020-11-25 21:11:27,575] INFO Replica loaded for partition connect_configs-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,575] INFO [Partition connect_configs-0 broker=1] connect_configs-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,584] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 7 for partition connect_configs-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,584] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 7 from controller 1 epoch 1 for the become-leader transition for partition connect_configs-0 (state.change.logger)
[2020-11-25 21:11:27,585] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=connect_configs,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 7 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:27,586] INFO Successfully submitted metrics to Confluent via secure endpoint (io.confluent.support.metrics.submitters.ConfluentSubmitter)
[2020-11-25 21:11:27,587] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition connect_configs-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 8 (state.change.logger)
[2020-11-25 21:11:27,588] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 8 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:27,674] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(1), 32 -> ArrayBuffer(1), 41 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 35 -> ArrayBuffer(1), 44 -> ArrayBuffer(1), 26 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 38 -> ArrayBuffer(1), 47 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 46 -> ArrayBuffer(1), 49 -> ArrayBuffer(1), 40 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 31 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 43 -> ArrayBuffer(1), 25 -> ArrayBuffer(1), 34 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 37 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 28 -> ArrayBuffer(1), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:27,696] INFO [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-11-25 21:11:27,702] INFO [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-22 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-21 -> Vector(1), __consumer_offsets-4 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-46 -> Vector(1), __consumer_offsets-25 -> Vector(1), __consumer_offsets-35 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-49 -> Vector(1), __consumer_offsets-47 -> Vector(1), __consumer_offsets-16 -> Vector(1), __consumer_offsets-28 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-36 -> Vector(1), __consumer_offsets-42 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-18 -> Vector(1), __consumer_offsets-37 -> Vector(1), __consumer_offsets-15 -> Vector(1), __consumer_offsets-24 -> Vector(1), __consumer_offsets-38 -> Vector(1), __consumer_offsets-17 -> Vector(1), __consumer_offsets-48 -> Vector(1), __consumer_offsets-19 -> Vector(1), __consumer_offsets-11 -> Vector(1), __consumer_offsets-13 -> Vector(1), __consumer_offsets-2 -> Vector(1), __consumer_offsets-43 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-14 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-39 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-26 -> Vector(1), __consumer_offsets-29 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-40 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:27,703] INFO [Controller id=1] New partition creation callback for __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 (kafka.controller.KafkaController)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-22 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-30 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-8 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-21 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-27 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-7 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-9 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-46 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-25 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-35 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-41 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-33 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-23 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-49 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-47 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-16 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-28 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-31 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-36 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-42 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,704] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-18 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-37 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-15 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-24 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-38 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-17 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-48 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-19 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-11 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-13 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-43 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-6 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-14 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-20 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-44 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-39 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-12 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-45 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-5 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-26 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-29 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-34 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-10 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,705] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-32 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,706] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-40 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,708] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,709] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,710] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,711] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-22 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-30 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-21 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-27 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-46 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-25 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-35 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-41 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-33 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-23 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,821] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-49 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-47 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-16 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-28 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-31 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-36 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-42 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-18 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-37 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-15 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-24 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-38 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-17 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-48 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-19 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-13 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-43 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-14 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-20 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-44 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-39 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-12 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-45 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-26 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-29 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-34 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-32 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,822] TRACE [Controller id=1 epoch=1] Changed partition __consumer_offsets-40 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2020-11-25 21:11:27,823] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-49 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-38 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-27 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-16 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-8 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-19 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-13 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-2 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-46 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-35 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-24 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-5 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-43 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-21 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-32 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-10 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-37 (state.change.logger)
[2020-11-25 21:11:27,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-48 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-40 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-18 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-29 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-7 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-23 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-45 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-34 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-26 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-4 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-15 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-42 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-9 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-31 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-20 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-12 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-1 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-28 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-17 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-6 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-39 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-44 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-47 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-36 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-25 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-3 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-14 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-30 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-41 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-22 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-33 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-11 (state.change.logger)
[2020-11-25 21:11:27,825] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition __consumer_offsets-0 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-13 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-46 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-9 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-42 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-21 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-17 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-30 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-26 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-5 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-38 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-1 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-34 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-16 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-45 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-12 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-41 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-24 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-20 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-49 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-0 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-29 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-25 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-8 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-37 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-4 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-33 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-15 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-48 (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,827] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-11 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-44 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-23 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-19 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-32 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-28 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-7 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-40 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-3 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-36 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-47 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-14 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-43 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-10 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-22 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-18 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-31 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-27 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-39 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-6 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-35 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 9 from controller 1 epoch 1 for partition __consumer_offsets-2 (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,828] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
[2020-11-25 21:11:27,866] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
[2020-11-25 21:11:27,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 1 epoch 1 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
[2020-11-25 21:11:27,867] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:27,872] INFO [Log partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,872] INFO [Log partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,873] INFO Created log for partition __consumer_offsets-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,873] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-11-25 21:11:27,873] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,873] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,878] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,882] INFO [Log partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,883] INFO [Log partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,884] INFO Created log for partition __consumer_offsets-29 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,884] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-11-25 21:11:27,884] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,884] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,888] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-29 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,892] INFO [Log partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,893] INFO [Log partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,894] INFO Created log for partition __consumer_offsets-48 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,894] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-11-25 21:11:27,894] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,894] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,898] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-48 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,902] INFO [Log partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,903] INFO [Log partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,904] INFO Created log for partition __consumer_offsets-10 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,904] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-11-25 21:11:27,904] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,904] INFO [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,908] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-10 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,913] INFO [Log partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,914] INFO [Log partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,915] INFO Created log for partition __consumer_offsets-45 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,915] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-11-25 21:11:27,916] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,916] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,920] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-45 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,924] INFO [Log partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,925] INFO [Log partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,926] INFO Created log for partition __consumer_offsets-26 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,926] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-11-25 21:11:27,926] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,926] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,930] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-26 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,934] INFO [Log partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,935] INFO [Log partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,935] INFO Created log for partition __consumer_offsets-7 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,936] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-11-25 21:11:27,936] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,936] INFO [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,941] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-7 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,945] INFO [Log partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,946] INFO [Log partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,947] INFO Created log for partition __consumer_offsets-42 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,947] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-11-25 21:11:27,947] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,947] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,951] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-42 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,956] INFO [Log partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,957] INFO [Log partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,958] INFO Created log for partition __consumer_offsets-4 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,958] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-11-25 21:11:27,958] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,958] INFO [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,963] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-4 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,967] INFO [Log partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,968] INFO [Log partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,969] INFO Created log for partition __consumer_offsets-23 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,969] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-11-25 21:11:27,969] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,969] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,974] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-23 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,979] INFO [Log partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,980] INFO [Log partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:27,981] INFO Created log for partition __consumer_offsets-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,981] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,981] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,981] INFO [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,986] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-1 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,988] INFO [Log partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,989] INFO [Log partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:27,989] INFO Created log for partition __consumer_offsets-20 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,990] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-11-25 21:11:27,990] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,990] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:27,994] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-20 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:27,997] INFO [Log partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:27,997] INFO [Log partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:27,998] INFO Created log for partition __consumer_offsets-39 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:27,998] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-11-25 21:11:27,998] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:27,999] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,003] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-39 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,006] INFO [Log partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,007] INFO [Log partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:28,007] INFO Created log for partition __consumer_offsets-17 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,008] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-11-25 21:11:28,008] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,008] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,012] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-17 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,015] INFO [Log partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,015] INFO [Log partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:28,016] INFO Created log for partition __consumer_offsets-36 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,016] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-11-25 21:11:28,016] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,016] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,020] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-36 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,024] INFO [Log partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,025] INFO [Log partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,026] INFO Created log for partition __consumer_offsets-14 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,026] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-11-25 21:11:28,026] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,026] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,030] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-14 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,034] INFO [Log partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,035] INFO [Log partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,036] INFO Created log for partition __consumer_offsets-33 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,036] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-11-25 21:11:28,036] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,036] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,040] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-33 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,044] INFO [Log partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,045] INFO [Log partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,046] INFO Created log for partition __consumer_offsets-49 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,046] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-11-25 21:11:28,046] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,047] INFO [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,050] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-49 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,053] INFO [Log partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,054] INFO [Log partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,054] INFO Created log for partition __consumer_offsets-11 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,055] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-11-25 21:11:28,055] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,055] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,059] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-11 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,061] INFO [Log partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,062] INFO [Log partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,062] INFO Created log for partition __consumer_offsets-30 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,062] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-11-25 21:11:28,062] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,062] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,075] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-30 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,119] INFO [Log partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,121] INFO [Log partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2020-11-25 21:11:28,125] INFO Created log for partition __consumer_offsets-46 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,125] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-11-25 21:11:28,125] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,126] INFO [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,137] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-46 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,140] INFO [Log partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,140] INFO [Log partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:28,141] INFO Created log for partition __consumer_offsets-27 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,141] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-11-25 21:11:28,141] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,141] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,149] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-27 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,153] INFO [Log partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,154] INFO [Log partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,155] INFO Created log for partition __consumer_offsets-8 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,155] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-11-25 21:11:28,155] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,155] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,167] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-8 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,170] INFO [Log partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,170] INFO [Log partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:28,171] INFO Created log for partition __consumer_offsets-24 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,171] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-11-25 21:11:28,171] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,171] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,179] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-24 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,183] INFO [Log partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,184] INFO [Log partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,184] INFO Created log for partition __consumer_offsets-43 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,184] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-11-25 21:11:28,184] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,184] INFO [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,188] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-43 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,191] INFO [Log partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,191] INFO [Log partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:28,192] INFO Created log for partition __consumer_offsets-5 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,192] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-11-25 21:11:28,192] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,192] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,196] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-5 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,199] INFO [Log partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,199] INFO [Log partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:28,200] INFO Created log for partition __consumer_offsets-21 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,200] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-11-25 21:11:28,200] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,200] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,204] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-21 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,208] INFO [Log partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,208] INFO [Log partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,209] INFO Created log for partition __consumer_offsets-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,209] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-11-25 21:11:28,210] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,210] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,214] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-2 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,217] INFO [Log partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,218] INFO [Log partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,219] INFO Created log for partition __consumer_offsets-40 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,220] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-11-25 21:11:28,220] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,220] INFO [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,224] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-40 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,230] INFO [Log partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,230] INFO [Log partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:28,232] INFO Created log for partition __consumer_offsets-37 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,232] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-11-25 21:11:28,232] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,232] INFO [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,236] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-37 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,238] INFO [Log partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,239] INFO [Log partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,239] INFO Created log for partition __consumer_offsets-18 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,240] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-11-25 21:11:28,240] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,240] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,243] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-18 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,247] INFO [Log partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,247] INFO [Log partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,248] INFO Created log for partition __consumer_offsets-34 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,248] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-11-25 21:11:28,248] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,249] INFO [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,253] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-34 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,255] INFO [Log partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,255] INFO [Log partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:28,256] INFO Created log for partition __consumer_offsets-15 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,256] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-11-25 21:11:28,256] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,256] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,260] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-15 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,262] INFO [Log partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,263] INFO [Log partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,264] INFO Created log for partition __consumer_offsets-12 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,264] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-11-25 21:11:28,264] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,264] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,268] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-12 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,271] INFO [Log partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,271] INFO [Log partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:28,272] INFO Created log for partition __consumer_offsets-31 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,272] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-11-25 21:11:28,272] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,272] INFO [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,279] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-31 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,282] INFO [Log partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,283] INFO [Log partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,283] INFO Created log for partition __consumer_offsets-9 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,283] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-11-25 21:11:28,284] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,284] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,288] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-9 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,291] INFO [Log partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,291] INFO [Log partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:28,292] INFO Created log for partition __consumer_offsets-47 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,292] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-11-25 21:11:28,292] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,292] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,296] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-47 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,299] INFO [Log partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,300] INFO [Log partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,300] INFO Created log for partition __consumer_offsets-19 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,300] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-11-25 21:11:28,300] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,301] INFO [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,304] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-19 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,308] INFO [Log partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,308] INFO [Log partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,309] INFO Created log for partition __consumer_offsets-28 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,309] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-11-25 21:11:28,309] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,310] INFO [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,314] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-28 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,317] INFO [Log partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,318] INFO [Log partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,319] INFO Created log for partition __consumer_offsets-38 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,319] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-11-25 21:11:28,319] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,319] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,323] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-38 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,328] INFO [Log partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,328] INFO [Log partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,329] INFO Created log for partition __consumer_offsets-35 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,330] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-11-25 21:11:28,330] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,330] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,334] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-35 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,339] INFO [Log partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,340] INFO [Log partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:28,341] INFO Created log for partition __consumer_offsets-44 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,341] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-11-25 21:11:28,341] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,341] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,346] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-44 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,349] INFO [Log partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,349] INFO [Log partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,350] INFO Created log for partition __consumer_offsets-6 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,350] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-11-25 21:11:28,350] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,350] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,354] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-6 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,357] INFO [Log partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,357] INFO [Log partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:28,357] INFO Created log for partition __consumer_offsets-25 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,358] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-11-25 21:11:28,358] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,358] INFO [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,362] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-25 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,375] INFO Creating topic debezium.tpcch.district with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:28,385] INFO [Controller id=1] New topics: [Set(debezium.tpcch.district)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.district-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:28,385] INFO [Controller id=1] New partition creation callback for debezium.tpcch.district-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:28,385] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.district-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:28,386] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.district-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:28,393] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.district-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:28,393] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:28,393] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:28,394] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.district-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:28,395] INFO [Log partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,397] INFO [Log partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2020-11-25 21:11:28,399] INFO Created log for partition __consumer_offsets-16 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,399] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-11-25 21:11:28,399] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,399] INFO [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,404] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-16 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,409] INFO [Log partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,409] INFO [Log partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,410] INFO Created log for partition __consumer_offsets-22 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,410] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-11-25 21:11:28,410] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,410] INFO [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,414] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-22 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,419] INFO [Log partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,420] INFO [Log partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,421] INFO Created log for partition __consumer_offsets-41 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,421] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-11-25 21:11:28,421] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,421] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,425] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-41 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,428] INFO [Log partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,429] INFO [Log partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,429] INFO Created log for partition __consumer_offsets-32 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,430] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-11-25 21:11:28,430] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,430] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,438] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-32 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,441] INFO [Log partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,442] INFO [Log partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:28,443] INFO Created log for partition __consumer_offsets-3 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,443] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-11-25 21:11:28,443] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,443] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,446] INFO Creating topic debezium.tpcch.warehouse with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:28,447] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-3 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,450] INFO [Log partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,451] INFO [Log partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,452] INFO Created log for partition __consumer_offsets-13 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,452] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-11-25 21:11:28,452] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,452] INFO [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,454] INFO [Controller id=1] New topics: [Set(debezium.tpcch.warehouse)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.warehouse-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:28,454] INFO [Controller id=1] New partition creation callback for debezium.tpcch.warehouse-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:28,454] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.warehouse-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:28,455] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.warehouse-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 9 for partition __consumer_offsets-13 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
[2020-11-25 21:11:28,457] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 1 epoch 1 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
[2020-11-25 21:11:28,460] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.warehouse-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,462] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:28,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.warehouse-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,466] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=13,error_code=0},{topic=__consumer_offsets,partition=46,error_code=0},{topic=__consumer_offsets,partition=9,error_code=0},{topic=__consumer_offsets,partition=42,error_code=0},{topic=__consumer_offsets,partition=21,error_code=0},{topic=__consumer_offsets,partition=17,error_code=0},{topic=__consumer_offsets,partition=30,error_code=0},{topic=__consumer_offsets,partition=26,error_code=0},{topic=__consumer_offsets,partition=5,error_code=0},{topic=__consumer_offsets,partition=38,error_code=0},{topic=__consumer_offsets,partition=1,error_code=0},{topic=__consumer_offsets,partition=34,error_code=0},{topic=__consumer_offsets,partition=16,error_code=0},{topic=__consumer_offsets,partition=45,error_code=0},{topic=__consumer_offsets,partition=12,error_code=0},{topic=__consumer_offsets,partition=41,error_code=0},{topic=__consumer_offsets,partition=24,error_code=0},{topic=__consumer_offsets,partition=20,error_code=0},{topic=__consumer_offsets,partition=49,error_code=0},{topic=__consumer_offsets,partition=0,error_code=0},{topic=__consumer_offsets,partition=29,error_code=0},{topic=__consumer_offsets,partition=25,error_code=0},{topic=__consumer_offsets,partition=8,error_code=0},{topic=__consumer_offsets,partition=37,error_code=0},{topic=__consumer_offsets,partition=4,error_code=0},{topic=__consumer_offsets,partition=33,error_code=0},{topic=__consumer_offsets,partition=15,error_code=0},{topic=__consumer_offsets,partition=48,error_code=0},{topic=__consumer_offsets,partition=11,error_code=0},{topic=__consumer_offsets,partition=44,error_code=0},{topic=__consumer_offsets,partition=23,error_code=0},{topic=__consumer_offsets,partition=19,error_code=0},{topic=__consumer_offsets,partition=32,error_code=0},{topic=__consumer_offsets,partition=28,error_code=0},{topic=__consumer_offsets,partition=7,error_code=0},{topic=__consumer_offsets,partition=40,error_code=0},{topic=__consumer_offsets,partition=3,error_code=0},{topic=__consumer_offsets,partition=36,error_code=0},{topic=__consumer_offsets,partition=47,error_code=0},{topic=__consumer_offsets,partition=14,error_code=0},{topic=__consumer_offsets,partition=43,error_code=0},{topic=__consumer_offsets,partition=10,error_code=0},{topic=__consumer_offsets,partition=22,error_code=0},{topic=__consumer_offsets,partition=18,error_code=0},{topic=__consumer_offsets,partition=31,error_code=0},{topic=__consumer_offsets,partition=27,error_code=0},{topic=__consumer_offsets,partition=39,error_code=0},{topic=__consumer_offsets,partition=6,error_code=0},{topic=__consumer_offsets,partition=35,error_code=0},{topic=__consumer_offsets,partition=2,error_code=0}]} for request LEADER_AND_ISR with correlation id 9 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,468] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,468] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,469] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,470] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 10 (state.change.logger)
[2020-11-25 21:11:28,470] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,471] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,471] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 10 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,471] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,471] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,471] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 11 from controller 1 epoch 1 for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:28,472] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,472] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,472] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,472] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,472] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,472] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,472] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 11 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:28,473] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.district-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:28,473] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,473] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,473] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,473] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,474] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,474] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,474] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,474] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,474] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,475] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,475] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,475] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,475] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,475] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,475] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,475] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,475] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,476] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,476] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,476] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,476] INFO [Log partition=debezium.tpcch.district-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,476] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,476] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,476] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,476] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,476] INFO [Log partition=debezium.tpcch.district-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,476] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,477] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,477] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,477] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,477] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,477] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,477] INFO Created log for partition debezium.tpcch.district-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,477] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,477] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,477] INFO [Partition debezium.tpcch.district-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.district-0 (kafka.cluster.Partition)
[2020-11-25 21:11:28,478] INFO Replica loaded for partition debezium.tpcch.district-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,478] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,478] INFO [Partition debezium.tpcch.district-0 broker=1] debezium.tpcch.district-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,478] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-25 21:11:28,482] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 11 for partition debezium.tpcch.district-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,482] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 11 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:28,483] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.district,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 11 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,484] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.district-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 12 (state.change.logger)
[2020-11-25 21:11:28,485] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 12 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,486] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 13 from controller 1 epoch 1 for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:28,488] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 13 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:28,488] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.warehouse-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:28,491] INFO [Log partition=debezium.tpcch.warehouse-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,492] INFO [Log partition=debezium.tpcch.warehouse-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,493] INFO Created log for partition debezium.tpcch.warehouse-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,493] INFO [Partition debezium.tpcch.warehouse-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.warehouse-0 (kafka.cluster.Partition)
[2020-11-25 21:11:28,493] INFO Replica loaded for partition debezium.tpcch.warehouse-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,493] INFO [Partition debezium.tpcch.warehouse-0 broker=1] debezium.tpcch.warehouse-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,497] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 13 for partition debezium.tpcch.warehouse-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,497] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 13 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:28,498] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.warehouse,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 13 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,500] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.warehouse-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 14 (state.change.logger)
[2020-11-25 21:11:28,501] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 14 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,503] INFO Creating topic debezium.tpcch.neworder with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:28,511] INFO [Controller id=1] New topics: [Set(debezium.tpcch.neworder)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.neworder-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:28,511] INFO [Controller id=1] New partition creation callback for debezium.tpcch.neworder-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:28,511] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.neworder-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:28,511] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.neworder-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:28,520] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.neworder-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:28,520] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:28,521] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:28,521] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.neworder-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:28,521] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 15 from controller 1 epoch 1 for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:28,523] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 15 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:28,523] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.neworder-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:28,527] INFO [Log partition=debezium.tpcch.neworder-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,528] INFO [Log partition=debezium.tpcch.neworder-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,529] INFO Created log for partition debezium.tpcch.neworder-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,529] INFO [Partition debezium.tpcch.neworder-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.neworder-0 (kafka.cluster.Partition)
[2020-11-25 21:11:28,529] INFO Replica loaded for partition debezium.tpcch.neworder-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,529] INFO [Partition debezium.tpcch.neworder-0 broker=1] debezium.tpcch.neworder-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,531] INFO Creating topic debezium.tpcch.item with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:28,533] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 15 for partition debezium.tpcch.neworder-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,533] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 15 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:28,534] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.neworder,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 15 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,535] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.neworder-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 16 (state.change.logger)
[2020-11-25 21:11:28,537] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 16 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,540] INFO [Controller id=1] New topics: [Set(debezium.tpcch.item)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.item-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:28,540] INFO [Controller id=1] New partition creation callback for debezium.tpcch.item-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:28,540] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.item-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:28,541] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.item-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:28,548] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.item-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:28,548] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:28,548] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:28,549] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.item-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:28,549] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 17 from controller 1 epoch 1 for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:28,550] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 17 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:28,550] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.item-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:28,554] INFO [Log partition=debezium.tpcch.item-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,554] INFO [Log partition=debezium.tpcch.item-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,555] INFO Created log for partition debezium.tpcch.item-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,555] INFO [Partition debezium.tpcch.item-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.item-0 (kafka.cluster.Partition)
[2020-11-25 21:11:28,555] INFO Replica loaded for partition debezium.tpcch.item-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,555] INFO [Partition debezium.tpcch.item-0 broker=1] debezium.tpcch.item-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,561] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 17 for partition debezium.tpcch.item-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,561] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 17 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:28,562] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.item,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 17 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,563] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.item-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 18 (state.change.logger)
[2020-11-25 21:11:28,564] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 18 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,591] INFO Creating topic debezium.tpcch.history with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:28,592] INFO Creating topic debezium.tpcch.customer with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:28,597] INFO [GroupCoordinator 1]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member connect-1-7e0d91af-21d2-4112-9138-4ad51849589e with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:28,614] INFO [Controller id=1] New topics: [Set(debezium.tpcch.history, debezium.tpcch.customer)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.customer-0 -> Vector(1), debezium.tpcch.history-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:28,614] INFO [Controller id=1] New partition creation callback for debezium.tpcch.customer-0,debezium.tpcch.history-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:28,614] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.customer-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:28,614] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.history-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:28,615] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.customer-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:28,615] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.history-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:28,626] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.customer-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:28,626] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.history-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:28,626] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:28,626] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:28,627] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:28,627] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:28,627] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.customer-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:28,627] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.history-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:28,628] INFO Creating topic debezium.tpcch.orderline with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:28,628] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 19 from controller 1 epoch 1 for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:28,628] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 19 from controller 1 epoch 1 for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:28,630] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 19 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:28,630] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 19 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:28,630] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.customer-0, debezium.tpcch.history-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:28,634] INFO [Log partition=debezium.tpcch.customer-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,635] INFO Creating topic debezium.tpcch.order with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:28,635] INFO [Log partition=debezium.tpcch.customer-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,636] INFO [Controller id=1] New topics: [Set(debezium.tpcch.orderline)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.orderline-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:28,636] INFO Created log for partition debezium.tpcch.customer-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,636] INFO [Controller id=1] New partition creation callback for debezium.tpcch.orderline-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:28,636] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.orderline-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:28,636] INFO [Partition debezium.tpcch.customer-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.customer-0 (kafka.cluster.Partition)
[2020-11-25 21:11:28,637] INFO Replica loaded for partition debezium.tpcch.customer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,637] INFO [Partition debezium.tpcch.customer-0 broker=1] debezium.tpcch.customer-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,637] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.orderline-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:28,642] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 19 for partition debezium.tpcch.customer-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,647] INFO [Log partition=debezium.tpcch.history-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,647] INFO [Log partition=debezium.tpcch.history-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,648] INFO Created log for partition debezium.tpcch.history-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,648] INFO [Partition debezium.tpcch.history-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.history-0 (kafka.cluster.Partition)
[2020-11-25 21:11:28,648] INFO Replica loaded for partition debezium.tpcch.history-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,648] INFO [Partition debezium.tpcch.history-0 broker=1] debezium.tpcch.history-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,652] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.orderline-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:28,652] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:28,653] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:28,653] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.orderline-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:28,654] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 19 for partition debezium.tpcch.history-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,654] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 19 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:28,654] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 19 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:28,655] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.customer,partition=0,error_code=0},{topic=debezium.tpcch.history,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 19 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,656] INFO [Controller id=1] New topics: [Set(debezium.tpcch.order)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.order-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:28,656] INFO [Controller id=1] New partition creation callback for debezium.tpcch.order-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:28,656] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.order-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:28,656] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.order-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:28,656] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.customer-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 20 (state.change.logger)
[2020-11-25 21:11:28,656] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.history-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 20 (state.change.logger)
[2020-11-25 21:11:28,659] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 20 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,660] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 21 from controller 1 epoch 1 for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:28,662] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 21 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:28,662] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.orderline-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:28,665] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.order-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:28,665] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:28,665] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:28,665] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.order-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:28,667] INFO [Log partition=debezium.tpcch.orderline-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,667] INFO [Log partition=debezium.tpcch.orderline-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,668] INFO Created log for partition debezium.tpcch.orderline-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,668] INFO [Partition debezium.tpcch.orderline-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.orderline-0 (kafka.cluster.Partition)
[2020-11-25 21:11:28,668] INFO Replica loaded for partition debezium.tpcch.orderline-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,669] INFO [Partition debezium.tpcch.orderline-0 broker=1] debezium.tpcch.orderline-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,672] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 21 for partition debezium.tpcch.orderline-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,672] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 21 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:28,673] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.orderline,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 21 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,674] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.orderline-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 22 (state.change.logger)
[2020-11-25 21:11:28,676] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 22 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,677] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 23 from controller 1 epoch 1 for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:28,678] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 23 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:28,678] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.order-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:28,680] INFO [Log partition=debezium.tpcch.order-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:28,681] INFO [Log partition=debezium.tpcch.order-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:28,681] INFO Created log for partition debezium.tpcch.order-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:28,681] INFO [Partition debezium.tpcch.order-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.order-0 (kafka.cluster.Partition)
[2020-11-25 21:11:28,681] INFO Replica loaded for partition debezium.tpcch.order-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:28,682] INFO [Partition debezium.tpcch.order-0 broker=1] debezium.tpcch.order-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:28,686] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 23 for partition debezium.tpcch.order-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:28,686] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 23 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:28,687] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.order,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 23 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:28,688] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.order-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 24 (state.change.logger)
[2020-11-25 21:11:28,689] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 24 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:29,493] INFO Creating topic _schemas with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:29,507] INFO [Controller id=1] New topics: [Set(_schemas)], deleted topics: [Set()], new partition replica assignment [Map(_schemas-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:29,507] INFO [Controller id=1] New partition creation callback for _schemas-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:29,507] TRACE [Controller id=1 epoch=1] Changed partition _schemas-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:29,508] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _schemas-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:29,515] TRACE [Controller id=1 epoch=1] Changed partition _schemas-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:29,515] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _schemas-0 (state.change.logger)
[2020-11-25 21:11:29,515] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _schemas-0 (state.change.logger)
[2020-11-25 21:11:29,516] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _schemas-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:29,516] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 25 from controller 1 epoch 1 for partition _schemas-0 (state.change.logger)
[2020-11-25 21:11:29,518] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 25 from controller 1 epoch 1 starting the become-leader transition for partition _schemas-0 (state.change.logger)
[2020-11-25 21:11:29,518] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_schemas-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:29,520] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:29,521] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:29,522] INFO Created log for partition _schemas-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:29,522] INFO [Partition _schemas-0 broker=1] No checkpointed highwatermark is found for partition _schemas-0 (kafka.cluster.Partition)
[2020-11-25 21:11:29,522] INFO Replica loaded for partition _schemas-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:29,522] INFO [Partition _schemas-0 broker=1] _schemas-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:29,529] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 25 for partition _schemas-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:29,529] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 25 from controller 1 epoch 1 for the become-leader transition for partition _schemas-0 (state.change.logger)
[2020-11-25 21:11:29,530] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_schemas,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 25 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:29,531] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _schemas-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 26 (state.change.logger)
[2020-11-25 21:11:29,532] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 26 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,130] INFO Creating topic _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=67108864, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,141] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,141] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,141] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,141] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,152] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,152] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,152] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,153] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,153] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 27 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,155] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 27 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,155] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,158] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,158] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:30,159] INFO Created log for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,159] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,160] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,160] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,164] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 27 for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,164] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 27 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,165] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 27 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,167] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 28 (state.change.logger)
[2020-11-25 21:11:30,168] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 28 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,175] INFO Creating topic _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=67108864, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,183] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,183] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,183] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,184] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,191] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,191] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,191] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,191] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,192] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 29 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,193] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 29 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,193] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,196] INFO [Log partition=_confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,197] INFO [Log partition=_confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,198] INFO Created log for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,198] INFO [Partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,198] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,198] INFO [Partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,202] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 29 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,202] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 29 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,203] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 29 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,204] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 30 (state.change.logger)
[2020-11-25 21:11:30,205] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 30 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,208] INFO Creating topic _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,222] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,222] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,222] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,222] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,229] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,229] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,229] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,229] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,230] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 31 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,231] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 31 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,231] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,234] INFO [Log partition=_confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,235] INFO [Log partition=_confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,235] INFO Created log for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,235] INFO [Partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,236] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,236] INFO [Partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 broker=1] _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,240] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 31 for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,240] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 31 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,241] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 31 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,243] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 32 (state.change.logger)
[2020-11-25 21:11:30,244] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 32 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,248] INFO Creating topic _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=67108864, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,257] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,257] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,257] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,257] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,267] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,267] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,267] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,267] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,268] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 33 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,269] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 33 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,269] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,272] INFO [Log partition=_confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,272] INFO [Log partition=_confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:30,273] INFO Created log for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,273] INFO [Partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,273] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,273] INFO [Partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,277] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 33 for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,277] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 33 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,278] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 33 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,279] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 34 (state.change.logger)
[2020-11-25 21:11:30,281] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 34 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,285] INFO Creating topic _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,295] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,295] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,295] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,296] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,303] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,303] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,303] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,304] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,304] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 35 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,308] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 35 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,308] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,311] INFO [Log partition=_confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,311] INFO [Log partition=_confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,312] INFO Created log for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,312] INFO [Partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,312] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,312] INFO [Partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,316] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 35 for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,316] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 35 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,317] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 35 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,318] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 36 (state.change.logger)
[2020-11-25 21:11:30,320] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 36 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,324] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,333] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,333] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,333] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,333] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,339] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,339] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,340] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,340] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,340] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 37 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,342] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 37 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,342] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,346] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,346] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,347] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,348] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,348] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,348] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,352] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 37 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,352] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 37 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,353] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 37 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,355] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 38 (state.change.logger)
[2020-11-25 21:11:30,356] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 38 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,361] INFO Creating topic _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=67108864, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,369] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,369] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,369] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,370] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,380] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,380] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,380] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,381] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,381] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 39 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,383] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 39 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,383] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,386] INFO [Log partition=_confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,387] INFO [Log partition=_confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,388] INFO Created log for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,388] INFO [Partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,388] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,388] INFO [Partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,393] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 39 for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,393] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 39 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,394] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 39 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,396] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 40 (state.change.logger)
[2020-11-25 21:11:30,398] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 40 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,402] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,410] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,410] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,410] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,411] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,417] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,417] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,417] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,417] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,418] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 41 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,419] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 41 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,419] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,422] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,422] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,423] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,423] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,423] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,424] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,425] INFO Creating topic debezium.tpcch.nation with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,428] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 41 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,428] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 41 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,429] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 41 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,430] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 42 (state.change.logger)
[2020-11-25 21:11:30,432] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 42 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,435] INFO [Controller id=1] New topics: [Set(debezium.tpcch.nation)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.nation-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,435] INFO [Controller id=1] New partition creation callback for debezium.tpcch.nation-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,435] INFO Creating topic _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,435] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.nation-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,435] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.nation-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,444] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.nation-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,444] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:30,444] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:30,444] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.nation-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,445] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 43 from controller 1 epoch 1 for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:30,446] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 43 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:30,446] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.nation-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,447] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,447] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,447] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,447] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,448] INFO [Log partition=debezium.tpcch.nation-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,449] INFO [Log partition=debezium.tpcch.nation-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,449] INFO Created log for partition debezium.tpcch.nation-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,450] INFO [Partition debezium.tpcch.nation-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.nation-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,450] INFO Replica loaded for partition debezium.tpcch.nation-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,450] INFO [Partition debezium.tpcch.nation-0 broker=1] debezium.tpcch.nation-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,454] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 43 for partition debezium.tpcch.nation-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,454] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 43 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:30,454] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.nation,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 43 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,456] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.nation-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 44 (state.change.logger)
[2020-11-25 21:11:30,457] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 44 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,460] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,460] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 (state.change.logger)
[2020-11-25 21:11:30,460] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 (state.change.logger)
[2020-11-25 21:11:30,460] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,461] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 45 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 (state.change.logger)
[2020-11-25 21:11:30,463] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 45 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 (state.change.logger)
[2020-11-25 21:11:30,463] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,466] INFO [Log partition=_confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,466] INFO [Log partition=_confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,467] INFO Created log for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,467] INFO [Partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,467] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,467] INFO [Partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 broker=1] _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,470] INFO Creating topic debezium.tpcch.stock with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,471] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 45 for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,471] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 45 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 (state.change.logger)
[2020-11-25 21:11:30,472] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 45 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,473] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 46 (state.change.logger)
[2020-11-25 21:11:30,474] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 46 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,478] INFO [Controller id=1] New topics: [Set(debezium.tpcch.stock)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.stock-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,478] INFO [Controller id=1] New partition creation callback for debezium.tpcch.stock-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,478] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.stock-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,479] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.stock-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,485] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.stock-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,485] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:30,485] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:30,486] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.stock-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,486] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 47 from controller 1 epoch 1 for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:30,487] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 47 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:30,487] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.stock-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,490] INFO [Log partition=debezium.tpcch.stock-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,490] INFO [Log partition=debezium.tpcch.stock-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:30,491] INFO Created log for partition debezium.tpcch.stock-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,491] INFO [Partition debezium.tpcch.stock-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.stock-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,491] INFO Replica loaded for partition debezium.tpcch.stock-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,491] INFO [Partition debezium.tpcch.stock-0 broker=1] debezium.tpcch.stock-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,495] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 47 for partition debezium.tpcch.stock-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,495] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 47 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:30,496] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.stock,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 47 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,498] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.stock-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 48 (state.change.logger)
[2020-11-25 21:11:30,498] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 48 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,524] INFO Creating topic _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,538] INFO Creating topic debezium.tpcch.supplier with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,538] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,538] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,539] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,539] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,548] INFO Creating topic debezium.tpcch.region with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,550] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,550] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,550] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,551] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,551] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 49 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,553] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 49 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,553] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,556] INFO [Controller id=1] New topics: [Set(debezium.tpcch.supplier)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.supplier-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,556] INFO [Controller id=1] New partition creation callback for debezium.tpcch.supplier-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,556] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.supplier-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,556] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.supplier-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,558] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,558] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:30,559] INFO Created log for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,559] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,559] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,559] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,564] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 49 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,564] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 49 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,564] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 49 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,566] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 50 (state.change.logger)
[2020-11-25 21:11:30,567] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 50 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,576] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.supplier-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,576] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:30,577] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:30,577] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.supplier-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,577] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 51 from controller 1 epoch 1 for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:30,577] INFO Creating topic _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition with configuration {message.timestamp.type=CreateTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,579] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 51 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:30,579] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.supplier-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,580] INFO [Controller id=1] New topics: [Set(debezium.tpcch.region)], deleted topics: [Set()], new partition replica assignment [Map(debezium.tpcch.region-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,580] INFO [Controller id=1] New partition creation callback for debezium.tpcch.region-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,580] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.region-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,580] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.region-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,583] INFO [Log partition=debezium.tpcch.supplier-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,583] INFO [Log partition=debezium.tpcch.supplier-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,584] INFO Created log for partition debezium.tpcch.supplier-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,584] INFO [Partition debezium.tpcch.supplier-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.supplier-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,584] INFO Replica loaded for partition debezium.tpcch.supplier-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,584] INFO [Partition debezium.tpcch.supplier-0 broker=1] debezium.tpcch.supplier-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,589] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 51 for partition debezium.tpcch.supplier-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,589] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 51 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:30,589] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.region-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,590] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:30,590] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.supplier,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 51 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,590] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:30,591] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.region-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,591] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.supplier-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 52 (state.change.logger)
[2020-11-25 21:11:30,592] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 52 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,593] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 53 from controller 1 epoch 1 for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:30,593] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 53 from controller 1 epoch 1 starting the become-leader transition for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:30,593] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.region-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,594] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,594] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,594] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,594] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,595] INFO [Log partition=debezium.tpcch.region-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,596] INFO [Log partition=debezium.tpcch.region-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,596] INFO Created log for partition debezium.tpcch.region-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,596] INFO [Partition debezium.tpcch.region-0 broker=1] No checkpointed highwatermark is found for partition debezium.tpcch.region-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,596] INFO Replica loaded for partition debezium.tpcch.region-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,596] INFO [Partition debezium.tpcch.region-0 broker=1] debezium.tpcch.region-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,602] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 53 for partition debezium.tpcch.region-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,602] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 53 from controller 1 epoch 1 for the become-leader transition for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:30,602] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.region,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 53 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,603] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.tpcch.region-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 54 (state.change.logger)
[2020-11-25 21:11:30,604] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 54 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,614] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,614] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[2020-11-25 21:11:30,614] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[2020-11-25 21:11:30,614] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,615] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 55 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[2020-11-25 21:11:30,615] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 55 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[2020-11-25 21:11:30,616] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,618] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,619] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,620] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,620] INFO [Partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,620] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,620] INFO [Partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 broker=1] _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,624] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 55 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,624] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 55 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[2020-11-25 21:11:30,625] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 55 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,626] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 56 (state.change.logger)
[2020-11-25 21:11:30,627] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 56 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,631] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,640] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,640] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,640] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,640] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,648] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,648] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,648] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,648] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,649] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 57 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,650] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 57 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,650] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,653] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,653] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:30,654] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,654] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,654] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,654] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,658] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 57 for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,658] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 57 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,659] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 57 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,660] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 58 (state.change.logger)
[2020-11-25 21:11:30,662] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 58 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,666] INFO Creating topic _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,676] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,677] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,677] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,677] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,684] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,684] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,685] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,685] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,685] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 59 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,686] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 59 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,687] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,689] INFO [Log partition=_confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,689] INFO [Log partition=_confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:30,690] INFO Created log for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,690] INFO [Partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,690] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,690] INFO [Partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,694] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 59 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,694] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 59 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,695] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 59 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,696] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 60 (state.change.logger)
[2020-11-25 21:11:30,697] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 60 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,702] INFO Creating topic _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,714] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,714] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,714] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,715] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,723] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,723] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,723] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,723] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,724] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 61 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,725] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 61 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,725] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,728] INFO [Log partition=_confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,729] INFO [Log partition=_confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,730] INFO Created log for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,730] INFO [Partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,730] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,730] INFO [Partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,735] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 61 for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,735] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 61 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,735] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 61 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,737] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 62 (state.change.logger)
[2020-11-25 21:11:30,738] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 62 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,742] INFO Creating topic _confluent-metrics with configuration {message.timestamp.type=CreateTime, retention.ms=259200000, min.insync.replicas=1, max.message.bytes=10485760, cleanup.policy=delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,750] INFO [Controller id=1] New topics: [Set(_confluent-metrics)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-metrics-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,750] INFO [Controller id=1] New partition creation callback for _confluent-metrics-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,751] TRACE [Controller id=1 epoch=1] Changed partition _confluent-metrics-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,751] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-metrics-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,760] TRACE [Controller id=1 epoch=1] Changed partition _confluent-metrics-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,760] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-metrics-0 (state.change.logger)
[2020-11-25 21:11:30,760] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-metrics-0 (state.change.logger)
[2020-11-25 21:11:30,760] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-metrics-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,761] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 63 from controller 1 epoch 1 for partition _confluent-metrics-0 (state.change.logger)
[2020-11-25 21:11:30,762] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 63 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-metrics-0 (state.change.logger)
[2020-11-25 21:11:30,762] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-metrics-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,765] INFO [Log partition=_confluent-metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,765] INFO [Log partition=_confluent-metrics-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,767] INFO Created log for partition _confluent-metrics-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 259200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 10485760, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,767] INFO [Partition _confluent-metrics-0 broker=1] No checkpointed highwatermark is found for partition _confluent-metrics-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,767] INFO Replica loaded for partition _confluent-metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,767] INFO [Partition _confluent-metrics-0 broker=1] _confluent-metrics-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,772] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 63 for partition _confluent-metrics-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,772] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 63 from controller 1 epoch 1 for the become-leader transition for partition _confluent-metrics-0 (state.change.logger)
[2020-11-25 21:11:30,772] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-metrics,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 63 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,773] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-metrics-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 64 (state.change.logger)
[2020-11-25 21:11:30,774] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 64 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,778] INFO Creating topic _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,789] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,790] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,790] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,790] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,799] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,799] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,799] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,799] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,800] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 65 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 65 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,801] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,803] INFO [Log partition=_confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,804] INFO [Log partition=_confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,804] INFO Created log for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,804] INFO [Partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,804] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,805] INFO [Partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 broker=1] _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,809] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 65 for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,809] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 65 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,810] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 65 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,812] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 66 (state.change.logger)
[2020-11-25 21:11:30,812] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 66 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,817] INFO Creating topic _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,826] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,826] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,826] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,826] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,833] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,833] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,833] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,833] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,833] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 67 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,834] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 67 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,834] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,837] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,837] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:30,838] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,838] INFO [Partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,838] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,838] INFO [Partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,843] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 67 for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,843] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 67 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,843] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 67 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,845] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 68 (state.change.logger)
[2020-11-25 21:11:30,846] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 68 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,850] INFO Creating topic _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,858] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,858] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,858] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,858] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,865] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,865] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,865] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,865] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,866] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 69 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 69 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,867] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,870] INFO [Log partition=_confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,871] INFO [Log partition=_confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:30,871] INFO Created log for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,871] INFO [Partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,872] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,872] INFO [Partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,876] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 69 for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,876] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 69 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,876] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 69 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,878] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 70 (state.change.logger)
[2020-11-25 21:11:30,879] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 70 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,883] INFO Creating topic _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,895] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,895] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,895] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,895] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,902] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,902] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,902] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,903] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,903] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 71 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,904] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 71 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,904] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,908] INFO [Log partition=_confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,909] INFO [Log partition=_confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:30,909] INFO Created log for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,909] INFO [Partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,909] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,910] INFO [Partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,914] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 71 for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,914] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 71 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,914] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 71 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,916] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 72 (state.change.logger)
[2020-11-25 21:11:30,917] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 72 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,921] INFO Creating topic _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,930] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,930] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,930] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,931] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,938] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,938] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,938] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,938] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,939] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 73 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,940] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 73 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,940] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,943] INFO [Log partition=_confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,943] INFO [Log partition=_confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,944] INFO Created log for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,944] INFO [Partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,944] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,944] INFO [Partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,949] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 73 for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,949] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 73 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:30,950] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 73 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,951] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 74 (state.change.logger)
[2020-11-25 21:11:30,953] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 74 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,957] INFO Creating topic _confluent-controlcenter-5-3-0-1-cluster-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,965] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-cluster-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-cluster-rekey-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:30,965] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-cluster-rekey-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:30,965] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:30,965] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:30,971] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:30,971] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,972] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,972] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:30,972] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 75 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,973] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 75 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,973] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-cluster-rekey-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:30,976] INFO [Log partition=_confluent-controlcenter-5-3-0-1-cluster-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:30,977] INFO [Log partition=_confluent-controlcenter-5-3-0-1-cluster-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:30,978] INFO Created log for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:30,978] INFO [Partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 (kafka.cluster.Partition)
[2020-11-25 21:11:30,978] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:30,978] INFO [Partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 broker=1] _confluent-controlcenter-5-3-0-1-cluster-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:30,983] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 75 for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:30,983] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 75 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 (state.change.logger)
[2020-11-25 21:11:30,984] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-cluster-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 75 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,985] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-cluster-rekey-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 76 (state.change.logger)
[2020-11-25 21:11:30,987] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 76 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:30,991] INFO Creating topic _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:30,998] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
[2020-11-25 21:11:30,999] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
[2020-11-25 21:11:31,021] DEBUG [Controller id=1] Preferred replicas by broker Map(1 -> Map(__consumer_offsets-22 -> Vector(1), _confluent-controlcenter-5-3-0-1-aggregate-topic-partition-store-changelog-0 -> Vector(1), connect_offsets-14 -> Vector(1), connect_offsets-1 -> Vector(1), __consumer_offsets-30 -> Vector(1), __consumer_offsets-8 -> Vector(1), __consumer_offsets-21 -> Vector(1), connect_offsets-20 -> Vector(1), debezium.tpcch.nation-0 -> Vector(1), __consumer_offsets-4 -> Vector(1), _confluent-controlcenter-5-3-0-1-Group-THREE_HOURS-changelog-0 -> Vector(1), __consumer_offsets-27 -> Vector(1), __consumer_offsets-7 -> Vector(1), __consumer_offsets-9 -> Vector(1), __consumer_offsets-46 -> Vector(1), debezium.tpcch.item-0 -> Vector(1), _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 -> Vector(1), _confluent-controlcenter-5-3-0-1-AlertHistoryStore-changelog-0 -> Vector(1), __consumer_offsets-25 -> Vector(1), connect-status-4 -> Vector(1), __consumer_offsets-35 -> Vector(1), debezium.tpcch.history-0 -> Vector(1), debezium.tpcch.district-0 -> Vector(1), connect_offsets-19 -> Vector(1), _confluent-controlcenter-5-3-0-1-monitoring-message-rekey-store-0 -> Vector(1), connect_offsets-15 -> Vector(1), connect_offsets-11 -> Vector(1), __consumer_offsets-41 -> Vector(1), __consumer_offsets-33 -> Vector(1), __consumer_offsets-23 -> Vector(1), __consumer_offsets-49 -> Vector(1), _schemas-0 -> Vector(1), connect_offsets-5 -> Vector(1), debezium.tpcch.warehouse-0 -> Vector(1), _confluent-controlcenter-5-3-0-1-group-aggregate-store-THREE_HOURS-changelog-0 -> Vector(1), _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 -> Vector(1), connect_offsets-13 -> Vector(1), connect_offsets-8 -> Vector(1), __consumer_offsets-47 -> Vector(1), _confluent-controlcenter-5-3-0-1-cluster-rekey-0 -> Vector(1), __consumer_offsets-16 -> Vector(1), connect_offsets-24 -> Vector(1), __consumer_offsets-28 -> Vector(1), connect_offsets-16 -> Vector(1), __consumer_offsets-31 -> Vector(1), __consumer_offsets-36 -> Vector(1), connect-status-3 -> Vector(1), connect_offsets-23 -> Vector(1), __consumer_offsets-42 -> Vector(1), debezium.tpcch.order-0 -> Vector(1), __consumer_offsets-3 -> Vector(1), __consumer_offsets-18 -> Vector(1), debezium.tpcch.orderline-0 -> Vector(1), __consumer_offsets-37 -> Vector(1), debezium.tpcch.stock-0 -> Vector(1), __consumer_offsets-15 -> Vector(1), _confluent-controlcenter-5-3-0-1-monitoring-trigger-event-rekey-0 -> Vector(1), __consumer_offsets-24 -> Vector(1), connect_offsets-6 -> Vector(1), connect_offsets-2 -> Vector(1), connect_offsets-22 -> Vector(1), debezium.tpcch.region-0 -> Vector(1), connect_offsets-9 -> Vector(1), _confluent-controlcenter-5-3-0-1-monitoring-aggregate-rekey-store-changelog-0 -> Vector(1), connect_offsets-17 -> Vector(1), connect-status-2 -> Vector(1), __consumer_offsets-38 -> Vector(1), connect_offsets-4 -> Vector(1), __consumer_offsets-17 -> Vector(1), connect_offsets-12 -> Vector(1), __consumer_offsets-48 -> Vector(1), __confluent.support.metrics-0 -> Vector(1), __consumer_offsets-19 -> Vector(1), _confluent-metrics-0 -> Vector(1), __consumer_offsets-11 -> Vector(1), connect_configs-0 -> Vector(1), _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-repartition-0 -> Vector(1), __consumer_offsets-13 -> Vector(1), _confluent-controlcenter-5-3-0-1-TriggerActionsStore-changelog-0 -> Vector(1), connect_offsets-3 -> Vector(1), _confluent-controlcenter-5-3-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 -> Vector(1), __consumer_offsets-2 -> Vector(1), __consumer_offsets-43 -> Vector(1), connect_offsets-7 -> Vector(1), __consumer_offsets-6 -> Vector(1), __consumer_offsets-14 -> Vector(1), _confluent-controlcenter-5-3-0-1-MonitoringTriggerStore-changelog-0 -> Vector(1), debezium.tpcch.supplier-0 -> Vector(1), debezium.tpcch.neworder-0 -> Vector(1), _confluent-controlcenter-5-3-0-1-MetricsAggregateStore-changelog-0 -> Vector(1), connect_offsets-18 -> Vector(1), connect_offsets-10 -> Vector(1), _confluent-controlcenter-5-3-0-1-TriggerEventsStore-changelog-0 -> Vector(1), connect_offsets-21 -> Vector(1), connect-status-0 -> Vector(1), __consumer_offsets-20 -> Vector(1), __consumer_offsets-0 -> Vector(1), __consumer_offsets-44 -> Vector(1), __consumer_offsets-39 -> Vector(1), _confluent-controlcenter-5-3-0-1-group-aggregate-store-ONE_MINUTE-changelog-0 -> Vector(1), _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 -> Vector(1), __consumer_offsets-12 -> Vector(1), __consumer_offsets-45 -> Vector(1), __consumer_offsets-1 -> Vector(1), __consumer_offsets-5 -> Vector(1), __consumer_offsets-26 -> Vector(1), _confluent-controlcenter-5-3-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 -> Vector(1), connect_offsets-0 -> Vector(1), _confluent-controlcenter-5-3-0-1-metrics-trigger-measurement-rekey-0 -> Vector(1), __consumer_offsets-29 -> Vector(1), connect-status-1 -> Vector(1), __consumer_offsets-34 -> Vector(1), __consumer_offsets-10 -> Vector(1), __consumer_offsets-32 -> Vector(1), __consumer_offsets-40 -> Vector(1), debezium.tpcch.customer-0 -> Vector(1))) (kafka.controller.KafkaController)
[2020-11-25 21:11:31,025] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
[2020-11-25 21:11:31,027] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,030] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,030] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,030] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,031] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,037] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,037] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,037] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,037] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,038] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 77 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,040] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 77 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,040] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,043] INFO [Log partition=_confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,044] INFO [Log partition=_confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:31,045] INFO Created log for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,045] INFO [Partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,045] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,045] INFO [Partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 broker=1] _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,050] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 77 for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,050] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 77 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,050] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 77 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,051] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-actual-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 78 (state.change.logger)
[2020-11-25 21:11:31,052] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 78 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,057] INFO Creating topic _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:31,066] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,067] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,067] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,067] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,073] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,073] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,073] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,073] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,074] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 79 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,075] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 79 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,075] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,078] INFO [Log partition=_confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,078] INFO [Log partition=_confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:31,079] INFO Created log for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,079] INFO [Partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,079] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,079] INFO [Partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,083] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 79 for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,084] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 79 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,084] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 79 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,085] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-Group-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 80 (state.change.logger)
[2020-11-25 21:11:31,086] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 80 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,090] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:31,098] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,098] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,098] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,098] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,105] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,105] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,105] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,106] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,106] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 81 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,107] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 81 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,107] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,110] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,111] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:31,111] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,112] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,112] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,112] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,116] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 81 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,116] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 81 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,117] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 81 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,118] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 82 (state.change.logger)
[2020-11-25 21:11:31,119] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 82 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,123] INFO Creating topic _confluent-command with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=259200000, min.insync.replicas=1, cleanup.policy=compact, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:31,134] INFO [Controller id=1] New topics: [Set(_confluent-command)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-command-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,134] INFO [Controller id=1] New partition creation callback for _confluent-command-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,134] TRACE [Controller id=1 epoch=1] Changed partition _confluent-command-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,134] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-command-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,141] TRACE [Controller id=1 epoch=1] Changed partition _confluent-command-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,141] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-command-0 (state.change.logger)
[2020-11-25 21:11:31,141] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-command-0 (state.change.logger)
[2020-11-25 21:11:31,141] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-command-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,142] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 83 from controller 1 epoch 1 for partition _confluent-command-0 (state.change.logger)
[2020-11-25 21:11:31,143] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 83 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-command-0 (state.change.logger)
[2020-11-25 21:11:31,143] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-command-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,145] INFO [Log partition=_confluent-command-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,145] INFO [Log partition=_confluent-command-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:31,146] INFO Created log for partition _confluent-command-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 259200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,146] INFO [Partition _confluent-command-0 broker=1] No checkpointed highwatermark is found for partition _confluent-command-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,146] INFO Replica loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,146] INFO [Partition _confluent-command-0 broker=1] _confluent-command-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,151] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 83 for partition _confluent-command-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,151] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 83 from controller 1 epoch 1 for the become-leader transition for partition _confluent-command-0 (state.change.logger)
[2020-11-25 21:11:31,151] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-command,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 83 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,152] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-command-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 84 (state.change.logger)
[2020-11-25 21:11:31,154] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 84 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,157] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:31,166] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,166] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,166] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,167] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,173] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,173] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,173] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,174] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,174] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 85 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,175] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 85 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,175] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,177] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,178] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:31,178] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,179] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,179] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,179] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,183] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 85 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,183] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 85 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,184] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 85 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,185] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 86 (state.change.logger)
[2020-11-25 21:11:31,186] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 86 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,189] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:31,197] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,197] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,197] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,197] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,204] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,204] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,204] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,204] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,204] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 87 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,205] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 87 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,205] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,208] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,209] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:31,210] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,210] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,210] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,210] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,214] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 87 for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,214] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 87 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,215] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 87 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,216] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringVerifierStore-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 88 (state.change.logger)
[2020-11-25 21:11:31,217] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 88 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,220] INFO Creating topic _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:31,234] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-group-stream-extension-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,234] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,234] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,234] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,240] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,240] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,241] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,241] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,241] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 89 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,242] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 89 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,243] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,246] INFO [Log partition=_confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,246] INFO [Log partition=_confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:31,247] INFO Created log for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,247] INFO [Partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,247] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,247] INFO [Partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 broker=1] _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,252] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 89 for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,252] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 89 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,253] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-group-stream-extension-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 89 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,254] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-group-stream-extension-rekey-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 90 (state.change.logger)
[2020-11-25 21:11:31,255] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 90 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,259] INFO Creating topic _confluent-monitoring with configuration {message.timestamp.type=LogAppendTime, retention.ms=259200000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:31,267] INFO [Controller id=1] New topics: [Set(_confluent-monitoring)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-monitoring-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,267] INFO [Controller id=1] New partition creation callback for _confluent-monitoring-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,267] TRACE [Controller id=1 epoch=1] Changed partition _confluent-monitoring-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,268] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-monitoring-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,274] TRACE [Controller id=1 epoch=1] Changed partition _confluent-monitoring-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,274] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-monitoring-0 (state.change.logger)
[2020-11-25 21:11:31,274] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-monitoring-0 (state.change.logger)
[2020-11-25 21:11:31,275] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-monitoring-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,275] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 91 from controller 1 epoch 1 for partition _confluent-monitoring-0 (state.change.logger)
[2020-11-25 21:11:31,276] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 91 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-monitoring-0 (state.change.logger)
[2020-11-25 21:11:31,276] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-monitoring-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,278] INFO [Log partition=_confluent-monitoring-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,278] INFO [Log partition=_confluent-monitoring-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:31,279] INFO Created log for partition _confluent-monitoring-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 259200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,279] INFO [Partition _confluent-monitoring-0 broker=1] No checkpointed highwatermark is found for partition _confluent-monitoring-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,279] INFO Replica loaded for partition _confluent-monitoring-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,279] INFO [Partition _confluent-monitoring-0 broker=1] _confluent-monitoring-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,283] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 91 for partition _confluent-monitoring-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,283] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 91 from controller 1 epoch 1 for the become-leader transition for partition _confluent-monitoring-0 (state.change.logger)
[2020-11-25 21:11:31,284] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-monitoring,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 91 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,285] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-monitoring-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 92 (state.change.logger)
[2020-11-25 21:11:31,286] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 92 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,289] INFO Creating topic _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:31,297] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,297] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,297] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,297] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,303] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,303] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,303] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,304] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,304] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 93 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,305] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 93 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,305] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,308] INFO [Log partition=_confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,309] INFO [Log partition=_confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:31,309] INFO Created log for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,310] INFO [Partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,310] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,310] INFO [Partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 broker=1] _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,315] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 93 for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,315] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 93 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 (state.change.logger)
[2020-11-25 21:11:31,315] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 93 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,317] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-expected-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 94 (state.change.logger)
[2020-11-25 21:11:31,318] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 94 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,322] INFO Creating topic _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:31,333] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:31,333] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:31,333] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:31,334] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:31,341] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:31,341] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,341] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,341] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:31,341] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 95 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,342] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 95 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,342] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:31,345] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:31,346] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:31,347] INFO Created log for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:31,347] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[2020-11-25 21:11:31,347] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:31,347] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 broker=1] _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:31,351] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 95 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:31,351] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 95 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[2020-11-25 21:11:31,352] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 95 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,353] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 96 (state.change.logger)
[2020-11-25 21:11:31,354] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 96 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:31,607] INFO [GroupCoordinator 1]: Stabilized group 1 generation 1 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:31,631] INFO [GroupCoordinator 1]: Assignment received from leader for group 1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:31,636] INFO [GroupCoordinator 1]: Preparing to rebalance group _confluent-controlcenter-5-3-0-1-command in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member _confluent-controlcenter-5-3-0-1-command-13abc3cc-ca12-403e-8a9c-62f47abf925f-StreamThread-1-consumer-030d49a6-b664-4a96-bfe2-a27c05d71f57 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:32,891] INFO [GroupCoordinator 1]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 1 (__consumer_offsets-49) (reason: Updating metadata for member connect-1-7e0d91af-21d2-4112-9138-4ad51849589e) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:32,893] INFO [GroupCoordinator 1]: Stabilized group 1 generation 2 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:32,901] INFO [GroupCoordinator 1]: Assignment received from leader for group 1 for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:34,420] INFO [GroupCoordinator 1]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 2 (__consumer_offsets-49) (reason: Updating metadata for member connect-1-7e0d91af-21d2-4112-9138-4ad51849589e) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:34,421] INFO [GroupCoordinator 1]: Stabilized group 1 generation 3 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:34,424] INFO [GroupCoordinator 1]: Assignment received from leader for group 1 for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:34,637] INFO [GroupCoordinator 1]: Stabilized group _confluent-controlcenter-5-3-0-1-command generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:34,648] INFO [GroupCoordinator 1]: Assignment received from leader for group _confluent-controlcenter-5-3-0-1-command for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,034] INFO Creating topic debezium.inventory.customers with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:36,043] INFO [KafkaApi-1] Auto creation of topic debezium.inventory.customers with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-11-25 21:11:36,045] INFO [Controller id=1] New topics: [Set(debezium.inventory.customers)], deleted topics: [Set()], new partition replica assignment [Map(debezium.inventory.customers-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:36,046] INFO [Controller id=1] New partition creation callback for debezium.inventory.customers-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:36,046] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.customers-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:36,048] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.customers-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:36,055] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.customers-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:36,055] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.inventory.customers-0 (state.change.logger)
[2020-11-25 21:11:36,056] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.inventory.customers-0 (state.change.logger)
[2020-11-25 21:11:36,056] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.customers-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:36,056] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 97 from controller 1 epoch 1 for partition debezium.inventory.customers-0 (state.change.logger)
[2020-11-25 21:11:36,057] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 1 epoch 1 starting the become-leader transition for partition debezium.inventory.customers-0 (state.change.logger)
[2020-11-25 21:11:36,057] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.inventory.customers-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,060] INFO [Log partition=debezium.inventory.customers-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:36,061] INFO [Log partition=debezium.inventory.customers-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:36,061] INFO Created log for partition debezium.inventory.customers-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:36,064] INFO [Partition debezium.inventory.customers-0 broker=1] No checkpointed highwatermark is found for partition debezium.inventory.customers-0 (kafka.cluster.Partition)
[2020-11-25 21:11:36,064] INFO Replica loaded for partition debezium.inventory.customers-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:36,064] INFO [Partition debezium.inventory.customers-0 broker=1] debezium.inventory.customers-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:36,069] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 97 for partition debezium.inventory.customers-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:36,069] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 1 epoch 1 for the become-leader transition for partition debezium.inventory.customers-0 (state.change.logger)
[2020-11-25 21:11:36,070] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.inventory.customers,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 97 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,071] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.inventory.customers-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 98 (state.change.logger)
[2020-11-25 21:11:36,071] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 98 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,183] DEBUG [Controller id=1] Delete topics listener fired for topics debezium.tpcch.district to be deleted (kafka.controller.KafkaController)
[2020-11-25 21:11:36,183] INFO [Controller id=1] Starting topic deletion for topics debezium.tpcch.district (kafka.controller.KafkaController)
[2020-11-25 21:11:36,185] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.district (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,188] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.district (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,189] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.district (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,192] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.district-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,193] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.district-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,194] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:36,195] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.district-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,197] TRACE [Broker id=1] Deleted partition debezium.tpcch.district-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 99 (state.change.logger)
[2020-11-25 21:11:36,205] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.district-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,206] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 99 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,210] INFO Creating topic debezium.inventory.geom with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:36,216] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.district-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,218] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.district,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,219] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.district,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,220] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.district-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,220] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.district-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,220] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.district-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,220] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.district,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,220] INFO [KafkaApi-1] Auto creation of topic debezium.inventory.geom with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-11-25 21:11:36,222] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:36,222] DEBUG [Controller id=1] Delete topics listener fired for topics debezium.tpcch.supplier,debezium.tpcch.history,debezium.tpcch.district,debezium.tpcch.order,debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item to be deleted (kafka.controller.KafkaController)
[2020-11-25 21:11:36,222] INFO [Controller id=1] Starting topic deletion for topics debezium.tpcch.supplier,debezium.tpcch.history,debezium.tpcch.district,debezium.tpcch.order,debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.KafkaController)
[2020-11-25 21:11:36,222] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:36,222] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.supplier,debezium.tpcch.history,debezium.tpcch.district,debezium.tpcch.order,debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,222] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.supplier (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,222] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.supplier (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,222] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.supplier-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,223] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.supplier-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,223] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:36,223] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.supplier-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,224] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.district,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 100 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,224] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.district-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,224] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.district-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,225] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:36,228] INFO The cleaning for partition debezium.tpcch.district-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,228] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.supplier-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,229] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.supplier,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,229] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.supplier,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,229] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.supplier-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,229] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.supplier,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,229] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.history (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,229] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.history (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,229] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.history-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,229] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.history-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,229] INFO The cleaning for partition debezium.tpcch.district-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,230] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:36,230] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.history-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,235] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.history-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,236] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.history,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,236] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.history,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,236] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.history-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,236] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.history,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,236] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.order (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,236] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.order (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,236] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.order-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,236] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.order-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,236] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:36,237] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.order-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,240] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.order-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,241] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.order,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,241] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.order,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,241] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.order-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,241] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.order,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,241] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.nation (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,241] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.nation (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,241] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.nation-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,241] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.nation-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,241] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:36,241] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.nation-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,245] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.nation-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,245] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.nation,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,245] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.nation,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,245] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.nation-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,245] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.nation,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,245] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.neworder (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,245] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.neworder (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,245] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.neworder-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,246] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.neworder-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,246] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:36,246] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.neworder-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,249] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.neworder-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,250] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.neworder,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,250] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.neworder,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,250] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.neworder-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,250] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.neworder,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,250] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.orderline (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,250] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.orderline (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,250] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.orderline-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,250] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.orderline-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,250] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:36,251] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.orderline-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,255] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.orderline-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,255] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.orderline,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,255] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.orderline,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,255] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.orderline-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,255] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.orderline,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,255] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.stock (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,255] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.stock (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,255] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.stock-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,255] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.stock-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,256] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:36,256] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.stock-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,256] INFO Log for partition debezium.tpcch.district-0 is renamed to /var/lib/kafka/data/debezium.tpcch.district-0.cdd9a19d928642408f8ff7e40060b1f6-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,256] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.district-0 (state.change.logger)
[2020-11-25 21:11:36,257] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.district,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 101 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,259] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.stock-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,259] TRACE [Broker id=1] Deleted partition debezium.tpcch.supplier-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 102 (state.change.logger)
[2020-11-25 21:11:36,259] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.stock,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,259] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.stock,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,259] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.stock-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,259] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.stock,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,259] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.supplier-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,259] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.customer (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,259] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.customer (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,260] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.customer-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,260] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.customer-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,260] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:36,260] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.customer-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,260] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 102 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,261] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.supplier-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,261] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.supplier-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,261] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:36,261] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:36,261] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.supplier,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 103 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,262] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.supplier-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,262] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.supplier-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,262] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:36,263] INFO The cleaning for partition debezium.tpcch.supplier-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,263] INFO The cleaning for partition debezium.tpcch.supplier-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,263] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.customer-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,263] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.customer,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,263] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.customer,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,263] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.customer-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,264] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.customer,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,264] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.warehouse (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,264] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.warehouse (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,264] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.warehouse-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,264] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.warehouse-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,264] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:36,264] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.warehouse-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,268] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.warehouse-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,269] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.warehouse,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,269] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.warehouse,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,269] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.warehouse-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,269] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.warehouse,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,269] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.region (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,269] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.region (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,269] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.region-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,269] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.region-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,270] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:36,270] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.region-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,275] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.region-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,276] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.region,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,276] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.region,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,276] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.region-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,276] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.region,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,276] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.item (re)started (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,276] INFO [Topic Deletion Manager 1] Topic deletion callback for debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,276] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.item-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-11-25 21:11:36,276] TRACE [Controller id=1 epoch=1] Changed partition debezium.tpcch.item-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-11-25 21:11:36,276] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:36,276] INFO [Topic Deletion Manager 1] Partition deletion callback for debezium.tpcch.item-0 (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,279] INFO Log for partition debezium.tpcch.supplier-0 is renamed to /var/lib/kafka/data/debezium.tpcch.supplier-0.0048174e07e449e3a472494c7fc32a98-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,279] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.supplier-0 (state.change.logger)
[2020-11-25 21:11:36,279] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.supplier,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 104 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,280] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.item-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-11-25 21:11:36,280] TRACE [Broker id=1] Deleted partition debezium.tpcch.history-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 105 (state.change.logger)
[2020-11-25 21:11:36,280] DEBUG The stop replica request (delete = false) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.item,Partition=0,Replica=1],false) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,280] DEBUG [Topic Deletion Manager 1] Deletion started for replicas [Topic=debezium.tpcch.item,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,281] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.item-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-11-25 21:11:36,281] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.history-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,281] DEBUG The stop replica request (delete = true) sent to broker 1 is StopReplicaRequestInfo([Topic=debezium.tpcch.item,Partition=0,Replica=1],true) (kafka.controller.ControllerBrokerRequestBatch)
[2020-11-25 21:11:36,281] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 105 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,282] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.history-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,282] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.history-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,282] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:36,282] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:36,282] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.history,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 106 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,283] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.history-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,283] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.history-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,283] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:36,283] INFO [Controller id=1] New topics: [Set(debezium.inventory.geom)], deleted topics: [Set()], new partition replica assignment [Map(debezium.inventory.geom-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:36,283] INFO [Controller id=1] New partition creation callback for debezium.inventory.geom-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:36,283] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.geom-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:36,283] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.geom-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:36,285] INFO The cleaning for partition debezium.tpcch.history-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,285] INFO The cleaning for partition debezium.tpcch.history-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,291] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.geom-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:36,291] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.inventory.geom-0 (state.change.logger)
[2020-11-25 21:11:36,291] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.inventory.geom-0 (state.change.logger)
[2020-11-25 21:11:36,292] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.geom-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:36,293] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.district-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,295] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.district,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,296] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.district-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,296] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.supplier,debezium.tpcch.history,debezium.tpcch.district,debezium.tpcch.order,debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,298] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.district-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,300] INFO Log for partition debezium.tpcch.history-0 is renamed to /var/lib/kafka/data/debezium.tpcch.history-0.460588be893947e4a3c815b1b381a6e6-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,300] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.history-0 (state.change.logger)
[2020-11-25 21:11:36,301] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.history,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 107 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,302] TRACE [Broker id=1] Deleted partition debezium.tpcch.order-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 108 (state.change.logger)
[2020-11-25 21:11:36,302] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.order-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,303] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 108 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,303] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.order-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,304] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.order-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,304] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:36,304] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:36,304] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.order,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 109 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,305] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.order-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,305] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.order-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,305] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:36,306] INFO The cleaning for partition debezium.tpcch.order-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,306] INFO The cleaning for partition debezium.tpcch.order-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,323] INFO Log for partition debezium.tpcch.order-0 is renamed to /var/lib/kafka/data/debezium.tpcch.order-0.92c60a63158f4d699b9739a552e7879c-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,323] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.order-0 (state.change.logger)
[2020-11-25 21:11:36,324] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.order,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 110 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,325] TRACE [Broker id=1] Deleted partition debezium.tpcch.nation-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 111 (state.change.logger)
[2020-11-25 21:11:36,325] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.nation-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,326] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.district successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,326] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 111 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,326] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.nation-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,326] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.nation-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,326] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:36,326] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:36,327] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.supplier-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,327] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.supplier,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,327] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.supplier-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,327] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.nation,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 112 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,327] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.supplier,debezium.tpcch.history,debezium.tpcch.order,debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,327] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.nation-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,327] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.nation-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,327] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:36,328] INFO The cleaning for partition debezium.tpcch.nation-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,328] INFO The cleaning for partition debezium.tpcch.nation-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,328] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.supplier-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,342] INFO Log for partition debezium.tpcch.nation-0 is renamed to /var/lib/kafka/data/debezium.tpcch.nation-0.b8092b074ed0431f9ec018b529e5c780-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,342] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.nation-0 (state.change.logger)
[2020-11-25 21:11:36,343] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.nation,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 113 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,344] TRACE [Broker id=1] Deleted partition debezium.tpcch.neworder-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 114 (state.change.logger)
[2020-11-25 21:11:36,344] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.neworder-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,344] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 114 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,345] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.neworder-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,345] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.neworder-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,345] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:36,345] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:36,346] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.neworder,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 115 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,346] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.neworder-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,346] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.neworder-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,346] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:36,348] INFO The cleaning for partition debezium.tpcch.neworder-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,348] INFO The cleaning for partition debezium.tpcch.neworder-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,349] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.supplier successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,350] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.history-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,350] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.history,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,351] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.history-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,351] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.history,debezium.tpcch.order,debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,351] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.history-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,364] INFO Log for partition debezium.tpcch.neworder-0 is renamed to /var/lib/kafka/data/debezium.tpcch.neworder-0.3bce1085af1f4a98929d1003f577e711-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,364] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.neworder-0 (state.change.logger)
[2020-11-25 21:11:36,364] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.neworder,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 116 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,365] TRACE [Broker id=1] Deleted partition debezium.tpcch.orderline-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 117 (state.change.logger)
[2020-11-25 21:11:36,365] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.orderline-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,366] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 117 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,366] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.orderline-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,367] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.orderline-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,367] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:36,367] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:36,367] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.orderline,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 118 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,368] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.orderline-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,368] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.orderline-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,368] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:36,369] INFO The cleaning for partition debezium.tpcch.orderline-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,369] INFO The cleaning for partition debezium.tpcch.orderline-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,371] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.history successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,373] INFO [Controller id=1] New topics: [Set()], deleted topics: [Set()], new partition replica assignment [Map()] (kafka.controller.KafkaController)
[2020-11-25 21:11:36,374] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.order-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,374] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.order,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,374] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.order-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,374] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.order,debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,374] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.order-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,388] INFO Log for partition debezium.tpcch.orderline-0 is renamed to /var/lib/kafka/data/debezium.tpcch.orderline-0.ed3489bd53b94918b06b470d2741378c-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,388] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.orderline-0 (state.change.logger)
[2020-11-25 21:11:36,389] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.orderline,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 119 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,391] TRACE [Broker id=1] Deleted partition debezium.tpcch.stock-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 120 (state.change.logger)
[2020-11-25 21:11:36,391] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.stock-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,392] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 120 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,393] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.stock-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,393] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.stock-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,393] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:36,393] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:36,393] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.stock,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 121 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,394] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.order successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,394] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.stock-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,394] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.stock-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,394] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:36,395] INFO The cleaning for partition debezium.tpcch.stock-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,395] INFO The cleaning for partition debezium.tpcch.stock-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,395] DEBUG [Controller id=1] Delete topics listener fired for topics debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item to be deleted (kafka.controller.KafkaController)
[2020-11-25 21:11:36,396] INFO [Controller id=1] Starting topic deletion for topics debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.KafkaController)
[2020-11-25 21:11:36,396] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,397] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.nation-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,397] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.nation,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,397] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.nation-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,397] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.nation,debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,397] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.nation-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,410] INFO Log for partition debezium.tpcch.stock-0 is renamed to /var/lib/kafka/data/debezium.tpcch.stock-0.045eb25972194f32a46cd4c2353ec2de-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,410] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.stock-0 (state.change.logger)
[2020-11-25 21:11:36,410] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.stock,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 122 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,411] TRACE [Broker id=1] Deleted partition debezium.tpcch.customer-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 123 (state.change.logger)
[2020-11-25 21:11:36,411] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.customer-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,412] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 123 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,412] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.customer-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,412] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.customer-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,412] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:36,412] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:36,413] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.customer,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 124 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,413] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.customer-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,413] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.customer-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,414] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:36,415] INFO The cleaning for partition debezium.tpcch.customer-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,415] INFO The cleaning for partition debezium.tpcch.customer-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,417] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.nation successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,417] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.neworder-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,418] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.neworder,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,418] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.neworder-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,418] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.neworder,debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,418] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.neworder-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,430] INFO Log for partition debezium.tpcch.customer-0 is renamed to /var/lib/kafka/data/debezium.tpcch.customer-0.b31b84861bae4d3da232398361e88dea-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,430] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.customer-0 (state.change.logger)
[2020-11-25 21:11:36,431] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.customer,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 125 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,432] TRACE [Broker id=1] Deleted partition debezium.tpcch.warehouse-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 126 (state.change.logger)
[2020-11-25 21:11:36,432] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.warehouse-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,432] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 126 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,433] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.warehouse-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,433] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.warehouse-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,433] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:36,433] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:36,434] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.warehouse,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 127 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,434] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.warehouse-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,435] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.warehouse-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,435] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:36,436] INFO The cleaning for partition debezium.tpcch.warehouse-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,436] INFO The cleaning for partition debezium.tpcch.warehouse-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,441] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.neworder successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,443] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.orderline-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,443] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.orderline,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,443] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.orderline-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,443] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.orderline,debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,443] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.orderline-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,453] INFO Log for partition debezium.tpcch.warehouse-0 is renamed to /var/lib/kafka/data/debezium.tpcch.warehouse-0.b5defb831522418b92b96d761ab4d178-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,453] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.warehouse-0 (state.change.logger)
[2020-11-25 21:11:36,454] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.warehouse,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 128 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,455] TRACE [Broker id=1] Deleted partition debezium.tpcch.region-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 129 (state.change.logger)
[2020-11-25 21:11:36,455] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.region-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,455] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 129 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,456] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.region-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,456] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.region-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,456] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:36,456] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:36,456] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.region,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 130 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,457] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.region-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,457] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.region-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,457] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:36,458] INFO The cleaning for partition debezium.tpcch.region-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,458] INFO The cleaning for partition debezium.tpcch.region-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,463] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.orderline successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,465] INFO [Controller id=1] New topics: [Set()], deleted topics: [Set()], new partition replica assignment [Map()] (kafka.controller.KafkaController)
[2020-11-25 21:11:36,466] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.stock-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,466] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.stock,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.stock-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,466] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.stock,debezium.tpcch.customer,debezium.tpcch.warehouse,debezium.tpcch.region,debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,466] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.stock-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,472] INFO Log for partition debezium.tpcch.region-0 is renamed to /var/lib/kafka/data/debezium.tpcch.region-0.72e6c5b8b9d94b4683be2ff073b9c70f-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,472] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.region-0 (state.change.logger)
[2020-11-25 21:11:36,472] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.region,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 131 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,473] TRACE [Broker id=1] Deleted partition debezium.tpcch.item-0 from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 132 (state.change.logger)
[2020-11-25 21:11:36,473] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: debezium.tpcch.item-0. (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:36,479] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 132 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,480] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.item-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,480] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.item-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,480] TRACE [Broker id=1] Handling stop replica (delete=false) for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:36,480] TRACE [Broker id=1] Finished handling stop replica (delete=false) for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:36,480] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.item,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 133 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,481] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.item-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,481] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(debezium.tpcch.item-0) (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-25 21:11:36,481] TRACE [Broker id=1] Handling stop replica (delete=true) for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:36,482] INFO The cleaning for partition debezium.tpcch.item-0 is aborted and paused (kafka.log.LogCleaner)
[2020-11-25 21:11:36,482] INFO The cleaning for partition debezium.tpcch.item-0 is aborted (kafka.log.LogCleaner)
[2020-11-25 21:11:36,483] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.stock successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,485] DEBUG [Controller id=1] Delete topics listener fired for topics debezium.tpcch.warehouse,debezium.tpcch.customer,debezium.tpcch.item,debezium.tpcch.region to be deleted (kafka.controller.KafkaController)
[2020-11-25 21:11:36,485] INFO [Controller id=1] Starting topic deletion for topics debezium.tpcch.warehouse,debezium.tpcch.customer,debezium.tpcch.item,debezium.tpcch.region (kafka.controller.KafkaController)
[2020-11-25 21:11:36,485] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.customer,debezium.tpcch.item,debezium.tpcch.region,debezium.tpcch.warehouse (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,486] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.customer-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,486] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.customer,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,486] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.customer-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,486] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.customer,debezium.tpcch.item,debezium.tpcch.region,debezium.tpcch.warehouse (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,486] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.customer-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,496] INFO Log for partition debezium.tpcch.item-0 is renamed to /var/lib/kafka/data/debezium.tpcch.item-0.6d89c4e60d3b47eda7c5425ee238e2af-delete and is scheduled for deletion (kafka.log.LogManager)
[2020-11-25 21:11:36,496] TRACE [Broker id=1] Finished handling stop replica (delete=true) for partition debezium.tpcch.item-0 (state.change.logger)
[2020-11-25 21:11:36,497] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.tpcch.item,partition=0,error_code=0}]} for request STOP_REPLICA with correlation id 134 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,498] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 135 from controller 1 epoch 1 for partition debezium.inventory.geom-0 (state.change.logger)
[2020-11-25 21:11:36,499] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 135 from controller 1 epoch 1 starting the become-leader transition for partition debezium.inventory.geom-0 (state.change.logger)
[2020-11-25 21:11:36,499] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.inventory.geom-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,506] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.customer successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,507] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.warehouse-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,507] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.warehouse,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,507] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.warehouse-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,507] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.item,debezium.tpcch.region,debezium.tpcch.warehouse (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,507] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.warehouse-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,508] INFO [Log partition=debezium.inventory.geom-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:36,509] INFO [Log partition=debezium.inventory.geom-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-11-25 21:11:36,510] INFO Created log for partition debezium.inventory.geom-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:36,514] INFO [Partition debezium.inventory.geom-0 broker=1] No checkpointed highwatermark is found for partition debezium.inventory.geom-0 (kafka.cluster.Partition)
[2020-11-25 21:11:36,514] INFO Replica loaded for partition debezium.inventory.geom-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:36,514] INFO [Partition debezium.inventory.geom-0 broker=1] debezium.inventory.geom-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:36,520] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 135 for partition debezium.inventory.geom-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:36,520] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 135 from controller 1 epoch 1 for the become-leader transition for partition debezium.inventory.geom-0 (state.change.logger)
[2020-11-25 21:11:36,520] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.inventory.geom,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 135 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,521] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.inventory.geom-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 136 (state.change.logger)
[2020-11-25 21:11:36,522] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 136 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,524] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.warehouse successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,525] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.region-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,525] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.region,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,525] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.region-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,525] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.item,debezium.tpcch.region (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,525] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.region-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,544] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.region successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,546] INFO [Controller id=1] New topics: [Set()], deleted topics: [Set()], new partition replica assignment [Map()] (kafka.controller.KafkaController)
[2020-11-25 21:11:36,546] DEBUG [Controller id=1] Delete topic callback invoked on StopReplica response received from broker 1: request error = NONE, partition errors = Map(debezium.tpcch.item-0 -> NONE) (kafka.controller.KafkaController)
[2020-11-25 21:11:36,547] DEBUG [Topic Deletion Manager 1] Deletion successfully completed for replicas [Topic=debezium.tpcch.item,Partition=0,Replica=1] (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,547] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.item-0 from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2020-11-25 21:11:36,547] INFO [Topic Deletion Manager 1] Handling deletion for topics debezium.tpcch.item (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,547] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.tpcch.item-0 from ReplicaDeletionSuccessful to NonExistentReplica (state.change.logger)
[2020-11-25 21:11:36,563] INFO [Topic Deletion Manager 1] Deletion of topic debezium.tpcch.item successfully completed (kafka.controller.TopicDeletionManager)
[2020-11-25 21:11:36,565] DEBUG [Controller id=1] Delete topics listener fired for topics  to be deleted (kafka.controller.KafkaController)
[2020-11-25 21:11:36,567] INFO [Controller id=1] New topics: [Set()], deleted topics: [Set()], new partition replica assignment [Map()] (kafka.controller.KafkaController)
[2020-11-25 21:11:36,601] INFO Creating topic debezium.inventory.orders with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:36,608] INFO [KafkaApi-1] Auto creation of topic debezium.inventory.orders with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-11-25 21:11:36,610] INFO [Controller id=1] New topics: [Set(debezium.inventory.orders)], deleted topics: [Set()], new partition replica assignment [Map(debezium.inventory.orders-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:36,610] INFO [Controller id=1] New partition creation callback for debezium.inventory.orders-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:36,611] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.orders-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:36,611] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.orders-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:36,618] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.orders-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:36,618] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.inventory.orders-0 (state.change.logger)
[2020-11-25 21:11:36,618] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.inventory.orders-0 (state.change.logger)
[2020-11-25 21:11:36,619] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.orders-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:36,619] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 137 from controller 1 epoch 1 for partition debezium.inventory.orders-0 (state.change.logger)
[2020-11-25 21:11:36,621] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 137 from controller 1 epoch 1 starting the become-leader transition for partition debezium.inventory.orders-0 (state.change.logger)
[2020-11-25 21:11:36,621] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.inventory.orders-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,625] INFO [Log partition=debezium.inventory.orders-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:36,625] INFO [Log partition=debezium.inventory.orders-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:36,626] INFO Created log for partition debezium.inventory.orders-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:36,628] INFO [Partition debezium.inventory.orders-0 broker=1] No checkpointed highwatermark is found for partition debezium.inventory.orders-0 (kafka.cluster.Partition)
[2020-11-25 21:11:36,629] INFO Replica loaded for partition debezium.inventory.orders-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:36,629] INFO [Partition debezium.inventory.orders-0 broker=1] debezium.inventory.orders-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:36,633] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 137 for partition debezium.inventory.orders-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:36,634] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 137 from controller 1 epoch 1 for the become-leader transition for partition debezium.inventory.orders-0 (state.change.logger)
[2020-11-25 21:11:36,634] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.inventory.orders,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 137 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,635] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.inventory.orders-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 138 (state.change.logger)
[2020-11-25 21:11:36,636] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 138 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,754] INFO [Admin Manager on Broker 1]: Error processing create topic request CreatableTopic(name='_confluent-command', numPartitions=1, replicationFactor=1, assignments=[], configs=[CreateableTopicConfig(name='cleanup.policy', value='compact')]) (kafka.server.AdminManager)
org.apache.kafka.common.errors.TopicExistsException: Topic '_confluent-command' already exists.
[2020-11-25 21:11:36,762] INFO Creating topic debezium.inventory.products with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:36,771] INFO [KafkaApi-1] Auto creation of topic debezium.inventory.products with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-11-25 21:11:36,773] INFO [Controller id=1] New topics: [Set(debezium.inventory.products)], deleted topics: [Set()], new partition replica assignment [Map(debezium.inventory.products-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:36,773] INFO [Controller id=1] New partition creation callback for debezium.inventory.products-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:36,773] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.products-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:36,773] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.products-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:36,780] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.products-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:36,780] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.inventory.products-0 (state.change.logger)
[2020-11-25 21:11:36,780] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.inventory.products-0 (state.change.logger)
[2020-11-25 21:11:36,780] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.products-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:36,781] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 139 from controller 1 epoch 1 for partition debezium.inventory.products-0 (state.change.logger)
[2020-11-25 21:11:36,782] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 139 from controller 1 epoch 1 starting the become-leader transition for partition debezium.inventory.products-0 (state.change.logger)
[2020-11-25 21:11:36,782] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.inventory.products-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,785] INFO [Log partition=debezium.inventory.products-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:36,786] INFO [Log partition=debezium.inventory.products-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:36,786] INFO Created log for partition debezium.inventory.products-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:36,787] INFO [Partition debezium.inventory.products-0 broker=1] No checkpointed highwatermark is found for partition debezium.inventory.products-0 (kafka.cluster.Partition)
[2020-11-25 21:11:36,787] INFO Replica loaded for partition debezium.inventory.products-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:36,788] INFO [Partition debezium.inventory.products-0 broker=1] debezium.inventory.products-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:36,792] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 139 for partition debezium.inventory.products-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:36,792] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 139 from controller 1 epoch 1 for the become-leader transition for partition debezium.inventory.products-0 (state.change.logger)
[2020-11-25 21:11:36,793] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.inventory.products,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 139 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,794] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.inventory.products-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 140 (state.change.logger)
[2020-11-25 21:11:36,795] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 140 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,922] INFO Creating topic debezium.inventory.products_on_hand with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:36,931] INFO [KafkaApi-1] Auto creation of topic debezium.inventory.products_on_hand with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-11-25 21:11:36,932] INFO [Controller id=1] New topics: [Set(debezium.inventory.products_on_hand)], deleted topics: [Set()], new partition replica assignment [Map(debezium.inventory.products_on_hand-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:36,932] INFO [Controller id=1] New partition creation callback for debezium.inventory.products_on_hand-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:36,933] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.products_on_hand-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:36,933] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.products_on_hand-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:36,943] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.products_on_hand-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:36,943] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.inventory.products_on_hand-0 (state.change.logger)
[2020-11-25 21:11:36,943] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.inventory.products_on_hand-0 (state.change.logger)
[2020-11-25 21:11:36,943] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.products_on_hand-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:36,944] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 141 from controller 1 epoch 1 for partition debezium.inventory.products_on_hand-0 (state.change.logger)
[2020-11-25 21:11:36,945] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 141 from controller 1 epoch 1 starting the become-leader transition for partition debezium.inventory.products_on_hand-0 (state.change.logger)
[2020-11-25 21:11:36,945] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.inventory.products_on_hand-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:36,948] INFO [Log partition=debezium.inventory.products_on_hand-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:36,949] INFO [Log partition=debezium.inventory.products_on_hand-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:36,950] INFO Created log for partition debezium.inventory.products_on_hand-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:36,951] INFO [Partition debezium.inventory.products_on_hand-0 broker=1] No checkpointed highwatermark is found for partition debezium.inventory.products_on_hand-0 (kafka.cluster.Partition)
[2020-11-25 21:11:36,951] INFO Replica loaded for partition debezium.inventory.products_on_hand-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:36,951] INFO [Partition debezium.inventory.products_on_hand-0 broker=1] debezium.inventory.products_on_hand-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:36,956] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 141 for partition debezium.inventory.products_on_hand-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:36,956] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 141 from controller 1 epoch 1 for the become-leader transition for partition debezium.inventory.products_on_hand-0 (state.change.logger)
[2020-11-25 21:11:36,956] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.inventory.products_on_hand,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 141 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:36,957] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.inventory.products_on_hand-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 142 (state.change.logger)
[2020-11-25 21:11:36,958] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 142 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:37,083] INFO Creating topic debezium.inventory.spatial_ref_sys with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:37,092] INFO [KafkaApi-1] Auto creation of topic debezium.inventory.spatial_ref_sys with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-11-25 21:11:37,094] INFO [Controller id=1] New topics: [Set(debezium.inventory.spatial_ref_sys)], deleted topics: [Set()], new partition replica assignment [Map(debezium.inventory.spatial_ref_sys-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:37,094] INFO [Controller id=1] New partition creation callback for debezium.inventory.spatial_ref_sys-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:37,094] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.spatial_ref_sys-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:37,094] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.spatial_ref_sys-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:37,101] TRACE [Controller id=1 epoch=1] Changed partition debezium.inventory.spatial_ref_sys-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:37,101] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.inventory.spatial_ref_sys-0 (state.change.logger)
[2020-11-25 21:11:37,101] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.inventory.spatial_ref_sys-0 (state.change.logger)
[2020-11-25 21:11:37,101] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.inventory.spatial_ref_sys-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:37,102] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 143 from controller 1 epoch 1 for partition debezium.inventory.spatial_ref_sys-0 (state.change.logger)
[2020-11-25 21:11:37,103] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 143 from controller 1 epoch 1 starting the become-leader transition for partition debezium.inventory.spatial_ref_sys-0 (state.change.logger)
[2020-11-25 21:11:37,103] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.inventory.spatial_ref_sys-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:37,106] INFO [Log partition=debezium.inventory.spatial_ref_sys-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:37,106] INFO [Log partition=debezium.inventory.spatial_ref_sys-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:37,107] INFO Created log for partition debezium.inventory.spatial_ref_sys-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:37,108] INFO [Partition debezium.inventory.spatial_ref_sys-0 broker=1] No checkpointed highwatermark is found for partition debezium.inventory.spatial_ref_sys-0 (kafka.cluster.Partition)
[2020-11-25 21:11:37,108] INFO Replica loaded for partition debezium.inventory.spatial_ref_sys-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:37,108] INFO [Partition debezium.inventory.spatial_ref_sys-0 broker=1] debezium.inventory.spatial_ref_sys-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:37,112] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 143 for partition debezium.inventory.spatial_ref_sys-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:37,112] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 143 from controller 1 epoch 1 for the become-leader transition for partition debezium.inventory.spatial_ref_sys-0 (state.change.logger)
[2020-11-25 21:11:37,113] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.inventory.spatial_ref_sys,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 143 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:37,114] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.inventory.spatial_ref_sys-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 144 (state.change.logger)
[2020-11-25 21:11:37,114] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 144 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:37,736] INFO [GroupCoordinator 1]: Preparing to rebalance group _confluent-controlcenter-5-3-0-1 in state PreparingRebalance with old generation 0 (__consumer_offsets-39) (reason: Adding new member _confluent-controlcenter-5-3-0-1-6e40121f-826c-4561-8ebf-5e1aad8addf1-StreamThread-1-consumer-ffb6ac43-dbd7-434f-a637-8755de4837dd with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:40,739] INFO [GroupCoordinator 1]: Stabilized group _confluent-controlcenter-5-3-0-1 generation 1 (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:11:40,760] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:40,782] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:40,786] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:40,786] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:40,787] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:40,788] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:40,791] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:40,795] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:40,795] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,795] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,796] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:40,797] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 145 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,798] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 145 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,798] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:40,798] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:40,798] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:40,798] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:40,799] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:40,800] INFO Creating topic _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:40,801] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:40,802] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:11:40,803] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:40,804] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 (kafka.cluster.Partition)
[2020-11-25 21:11:40,804] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:40,804] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:40,810] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 145 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:40,810] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 145 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,811] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 145 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,811] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:40,811] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,811] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,812] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:40,813] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-ONE_MINUTE-repartition-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 146 (state.change.logger)
[2020-11-25 21:11:40,813] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 146 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,814] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 147 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,814] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition, _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 -> Vector(1), _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:40,814] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0,_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:40,814] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:40,814] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:40,814] INFO Creating topic _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:40,814] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:40,814] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:40,815] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 147 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,815] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:40,820] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:40,821] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:40,822] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:40,823] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (kafka.cluster.Partition)
[2020-11-25 21:11:40,823] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:40,823] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:40,824] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:40,824] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:40,824] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,824] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,824] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,824] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:40,824] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:40,825] INFO Creating topic _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:11:40,827] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 147 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:40,827] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 147 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,828] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 147 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,829] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:40,829] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:40,829] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:40,829] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:40,829] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 148 (state.change.logger)
[2020-11-25 21:11:40,829] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 148 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,830] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 149 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,830] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 149 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,831] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 149 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,831] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 149 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,831] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:40,838] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:40,838] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:40,838] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:40,838] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,838] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,838] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:40,839] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:40,840] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (kafka.cluster.Partition)
[2020-11-25 21:11:40,840] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:40,840] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:40,840] INFO [Controller id=1] New topics: [Set(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:11:40,840] INFO [Controller id=1] New partition creation callback for _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (kafka.controller.KafkaController)
[2020-11-25 21:11:40,841] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:11:40,841] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:11:40,844] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 149 for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:40,845] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:40,846] INFO [Log partition=_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-11-25 21:11:40,846] INFO Created log for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:40,847] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 (kafka.cluster.Partition)
[2020-11-25 21:11:40,847] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:40,847] INFO [Partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 broker=1] _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:40,848] TRACE [Controller id=1 epoch=1] Changed partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:11:40,848] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,849] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,849] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:11:40,850] INFO [Controller id=1] New topics: [Set()], deleted topics: [Set()], new partition replica assignment [Map()] (kafka.controller.KafkaController)
[2020-11-25 21:11:40,852] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 149 for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:40,852] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 149 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,852] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 149 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,852] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition,partition=0,error_code=0},{topic=_confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 149 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,853] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringStream-THREE_HOURS-repartition-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 150 (state.change.logger)
[2020-11-25 21:11:40,853] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 150 (state.change.logger)
[2020-11-25 21:11:40,854] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 150 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,854] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 151 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,855] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 151 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,855] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:40,857] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:40,858] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:40,858] INFO Created log for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:40,859] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (kafka.cluster.Partition)
[2020-11-25 21:11:40,859] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:40,859] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 broker=1] _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:40,864] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 151 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:40,864] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 151 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,864] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 151 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,865] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 152 (state.change.logger)
[2020-11-25 21:11:40,865] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 152 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,866] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 153 from controller 1 epoch 1 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,867] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 153 from controller 1 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,867] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:11:40,870] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:11:40,870] INFO [Log partition=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-11-25 21:11:40,871] INFO Created log for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:11:40,872] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (kafka.cluster.Partition)
[2020-11-25 21:11:40,872] INFO Replica loaded for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:11:40,872] INFO [Partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 broker=1] _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:11:40,876] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 153 for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:11:40,876] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 153 from controller 1 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[2020-11-25 21:11:40,877] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 153 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,878] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 154 (state.change.logger)
[2020-11-25 21:11:40,879] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 154 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:11:40,894] INFO [GroupCoordinator 1]: Assignment received from leader for group _confluent-controlcenter-5-3-0-1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-11-25 21:12:14,206] INFO Creating topic debezium.transaction with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2020-11-25 21:12:14,214] INFO [KafkaApi-1] Auto creation of topic debezium.transaction with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-11-25 21:12:14,216] INFO [Controller id=1] New topics: [Set(debezium.transaction)], deleted topics: [Set()], new partition replica assignment [Map(debezium.transaction-0 -> Vector(1))] (kafka.controller.KafkaController)
[2020-11-25 21:12:14,217] INFO [Controller id=1] New partition creation callback for debezium.transaction-0 (kafka.controller.KafkaController)
[2020-11-25 21:12:14,217] TRACE [Controller id=1 epoch=1] Changed partition debezium.transaction-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[2020-11-25 21:12:14,217] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.transaction-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-11-25 21:12:14,224] TRACE [Controller id=1 epoch=1] Changed partition debezium.transaction-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[2020-11-25 21:12:14,224] TRACE [Controller id=1 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition debezium.transaction-0 (state.change.logger)
[2020-11-25 21:12:14,224] TRACE [Controller id=1 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1) for partition debezium.transaction-0 (state.change.logger)
[2020-11-25 21:12:14,224] TRACE [Controller id=1 epoch=1] Changed state of replica 1 for partition debezium.transaction-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-11-25 21:12:14,225] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 155 from controller 1 epoch 1 for partition debezium.transaction-0 (state.change.logger)
[2020-11-25 21:12:14,226] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 155 from controller 1 epoch 1 starting the become-leader transition for partition debezium.transaction-0 (state.change.logger)
[2020-11-25 21:12:14,226] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(debezium.transaction-0) (kafka.server.ReplicaFetcherManager)
[2020-11-25 21:12:14,229] INFO [Log partition=debezium.transaction-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-11-25 21:12:14,230] INFO [Log partition=debezium.transaction-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-11-25 21:12:14,231] INFO Created log for partition debezium.transaction-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-11-25 21:12:14,232] INFO [Partition debezium.transaction-0 broker=1] No checkpointed highwatermark is found for partition debezium.transaction-0 (kafka.cluster.Partition)
[2020-11-25 21:12:14,232] INFO Replica loaded for partition debezium.transaction-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-11-25 21:12:14,232] INFO [Partition debezium.transaction-0 broker=1] debezium.transaction-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-11-25 21:12:14,237] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 1 epoch 1 with correlation id 155 for partition debezium.transaction-0 (last update controller epoch 1) (state.change.logger)
[2020-11-25 21:12:14,237] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 155 from controller 1 epoch 1 for the become-leader transition for partition debezium.transaction-0 (state.change.logger)
[2020-11-25 21:12:14,237] TRACE [Controller id=1 epoch=1] Received response {error_code=0,partitions=[{topic=debezium.transaction,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 155 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
[2020-11-25 21:12:14,238] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition debezium.transaction-0 in response to UpdateMetadata request sent by controller 1 epoch 1 with correlation id 156 (state.change.logger)
[2020-11-25 21:12:14,238] TRACE [Controller id=1 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 156 sent to broker kafka:9092 (id: 1 rack: null) (state.change.logger)
