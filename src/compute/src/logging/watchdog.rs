// Copyright Materialize, Inc. and contributors. All rights reserved.
//
// Use of this software is governed by the Business Source License
// included in the LICENSE file.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0.

//! Logging dataflows for watchdog events generated by clusterd.

use std::cell::RefCell;
use std::collections::BTreeSet;
use std::rc::Rc;

use differential_dataflow::trace::{BatchReader, Cursor};
use differential_dataflow::AsCollection;
use timely::dataflow::operators::Inspect;
use timely::dataflow::operators::{Concat, Enter};
use timely::dataflow::{Scope, Stream};

use crate::extensions::arrange::MzArrange;
use crate::extensions::reduce::MzReduce;
use crate::logging::Update;
use crate::typedefs::spines::{ColKeyBuilder, ColValBatcher, ColValBuilder};
use crate::typedefs::{KeyBatcher, KeySpine, KeyValSpine};

pub(super) struct Streams<S: Scope> {
    /// operator id, diff in bytes
    pub(super) arrangement_heap_size: Stream<S, Update<(usize, ())>>,
    /// operator id, diff in bytes
    pub(super) batcher_heap_size: Stream<S, Update<(usize, ())>>,
    /// Operator id to dataflow id
    pub(super) operator_to_dataflow: Stream<S, Update<(usize, usize)>>,
    /// Dataflow -> limit in bytes
    pub(super) heap_size_limits: Stream<S, Update<(usize, u64)>>,
    pub(super) dataflows_exceeding_heap_size_limit: Rc<RefCell<BTreeSet<usize>>>,
}

pub(super) fn construct<S: Scope<Timestamp = mz_repr::Timestamp>>(
    mut scope: S,
    streams: Streams<S>,
) -> () {
    let Streams {
        arrangement_heap_size,
        batcher_heap_size,
        operator_to_dataflow,
        heap_size_limits,
        dataflows_exceeding_heap_size_limit,
    } = streams;

    // The following dataflow computes:
    // ```
    // arrangement_heap_size  batcher_heap_size  operator_to_dataflow  heap_size_limits
    //           |                    |                   |                  |
    //           |----->concat<------ |                arrange            arrange
    //                    |                               |                  |
    //               arrange: op_to_heap_size             |                  |
    //                    |                               |                  |
    //                    |->join: dataflow_to_heap_size<-|                  |
    //                                   |                                   |
    //                                   |                                   |
    //                               arrange                                 |
    //                                   |                                   |
    //                                   |------------>join<-----------------|
    //                                                   |
    //                                                arrange
    //                                                   |
    //                                                reduce size > limit
    //                                                   |
    //                                                result
    // ```
    //
    // We encode the size of a dataflow in the diff field, and the limit as actual data.

    scope.scoped("watchdog", |inner| {
        let arrangement_heap_size = arrangement_heap_size.enter(inner);
        let batcher_heap_size = batcher_heap_size.enter(inner);
        let operator_to_dataflow = operator_to_dataflow.enter(inner);
        let heap_size_limits = heap_size_limits.enter(inner);

        let operator_to_heap_size = arrangement_heap_size.concat(&batcher_heap_size);
        let operator_to_heap_size = operator_to_heap_size
            .as_collection()
            .mz_arrange::<KeyBatcher<_, _, _>, ColKeyBuilder<_, _, _>, KeySpine<_, _, _>>(
                "operator_to_heap_size",
            );

        let operator_to_dataflow = operator_to_dataflow
            .as_collection()
            .mz_arrange::<ColValBatcher<_, _, _, _>, ColValBuilder<_, _, _, _>, KeyValSpine<_, _, _, _>>(
                "operator_to_dataflow",
            );

        let dataflow_to_heap_size = operator_to_heap_size
            .join_core(&operator_to_dataflow, |_op, (), dataflow| {
                Some((*dataflow, ()))
            })
            .mz_arrange::<KeyBatcher<_, _, _>, ColKeyBuilder<_, _, _>, KeySpine<_, _, _>>(
                "dataflow_to_heap_size",
            );

        let heap_size_limits = heap_size_limits
            .as_collection()
            .mz_arrange::<ColValBatcher<_, _, _, _>, ColValBuilder<_, _, _, _>, KeyValSpine<_, _, _, _>>("heap_size_limits");

        let dataflow_to_heap_size_limit = dataflow_to_heap_size
            .join_core(&heap_size_limits, |dataflow, (), limit| {
                std::iter::once((*dataflow, *limit))
            })
            .mz_arrange::<ColValBatcher<usize, u64, _, _>, ColValBuilder<_, _, _, _>, KeyValSpine<usize, u64, _, mz_repr::Diff>>(
                "dataflow_to_heap_size_count",
            )
            .mz_reduce_abelian::<_, usize, (), ColKeyBuilder<_, _, _>, KeySpine<_, _, _>>("Reduce: dataflow_to_heap_size_count", |_dataflow, s, t| {
                t.extend(s.iter().flat_map(|(&limit, size)| {
                    if *size >= limit.try_into().expect("must fit") {
                        // We could output `size` here to report the actual size of the dataflow.
                        Some(((), 1))
                    } else {
                        None
                    }
                }));
            });

        dataflow_to_heap_size_limit.stream.inspect(move |batch| {
            let mut cursor = batch.cursor();
            while cursor.key_valid(batch) {
                let dataflow_id = *cursor.key(batch);
                cursor.map_times(batch, |_time, _diff| {
                    // TODO: This only ever adds, never removes (the main loop drains it). Depending
                    //   on what signals we'd like to have, we could also consider _removing_
                    //   dataflows here.
                    dataflows_exceeding_heap_size_limit
                        .borrow_mut()
                        .insert(dataflow_id);
                });
                cursor.step_key(batch);
            }
        });
    });
}
