// Copyright Materialize, Inc. and contributors. All rights reserved.
//
// Use of this software is governed by the Business Source License
// included in the LICENSE file.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0.

//! Logging dataflows for events generated by timely dataflow.

use std::time::Duration;

use timely::communication::Allocate;
use timely::dataflow::operators::capture::EventLink;
use timely::logging::WorkerIdentifier;

use super::{LogVariant, TimelyLog};
use crate::arrangement::KeysValsHandle;
use dataflow_types::logging::LoggingConfig;
use repr::{Datum, Row, Timestamp};

/// Constructs the logging dataflows and returns a logger and trace handles.
pub fn construct<A: Allocate>(
    worker: &mut timely::worker::Worker<A>,
    config: &LoggingConfig,
    linked: std::rc::Rc<
        EventLink<
            Timestamp,
            (
                Duration,
                WorkerIdentifier,
                (Vec<usize>, usize, usize, String, String, isize),
            ),
        >,
    >,
) -> std::collections::HashMap<LogVariant, (Vec<usize>, KeysValsHandle)> {
    let granularity_ms = std::cmp::max(1, config.granularity_ns / 1_000_000) as Timestamp;

    // A dataflow for multiple log-derived arrangements.
    let traces = worker.dataflow_named("Dataflow: timely reachability logging", move |scope| {
        use differential_dataflow::collection::AsCollection;
        use timely::dataflow::operators::capture::Replay;

        let logs = Some(linked).replay_core(
            scope,
            Some(Duration::from_nanos(config.granularity_ns as u64)),
        );

        use timely::dataflow::operators::generic::builder_rc::OperatorBuilder;

        let mut flatten = OperatorBuilder::new(
            "Timely Reachability Logging Flatten ".to_string(),
            scope.clone(),
        );

        use timely::dataflow::channels::pact::Pipeline;
        let mut input = flatten.new_input(&logs, Pipeline);

        let (mut updates_out, updates) = flatten.new_output();

        let mut buffer = Vec::new();
        flatten.build(move |_capability| {
            move |_frontiers| {
                let mut updates = updates_out.activate();

                input.for_each(|time, data| {
                    data.swap(&mut buffer);

                    let mut updates_session = updates.session(&time);

                    for (time, worker, (addr, source, port, update_type, ts, diff)) in
                        buffer.drain(..)
                    {
                        let time_ms = (((time.as_millis() as Timestamp / granularity_ms) + 1)
                            * granularity_ms) as Timestamp;

                        updates_session.give((
                            (addr, source, port, worker, update_type, ts),
                            time_ms,
                            diff,
                        ));
                    }
                });
            }
        });

        let updates = updates.as_collection();

        // we can count here because we already put the number of occurences in
        // the "diff", above
        use differential_dataflow::operators::Count;
        let updates = updates.count();

        let updates = updates.map({
            move |((mut tracker_id, node, port, worker, update_type, ts), count)| {
                let mut row = Row::default();
                tracker_id.push(node);
                row.push_list(tracker_id.into_iter().map(|id| Datum::Int64(id as i64)));
                row.push(Datum::Int64(port as i64));
                row.push(Datum::Int64(worker as i64));
                row.push(Datum::String(&update_type));
                row.push(Datum::String(&ts));
                row.push(Datum::Int64(count as i64));
                row
            }
        });

        use differential_dataflow::operators::arrange::arrangement::ArrangeByKey;

        // Restrict results by those logs that are meant to be active.
        let logs = vec![(LogVariant::Timely(TimelyLog::Reachability), updates)];

        let mut result = std::collections::HashMap::new();
        for (variant, collection) in logs {
            if config.active_logs.contains_key(&variant) {
                let key = variant.index_by();
                let key_clone = key.clone();
                let trace = collection
                    .map({
                        let mut row_packer = Row::default();
                        move |row| {
                            let datums = row.unpack();
                            row_packer.extend(key.iter().map(|k| datums[*k]));
                            (row_packer.finish_and_reuse(), row)
                        }
                    })
                    .arrange_by_key()
                    .trace;
                result.insert(variant, (key_clone, trace));
            }
        }
        result
    });

    traces
}
