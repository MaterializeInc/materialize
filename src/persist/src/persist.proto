// Copyright Materialize, Inc. and contributors. All rights reserved.
//
// Use of this software is governed by the Business Source License
// included in the LICENSE file.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0.

// See https://developers.google.com/protocol-buffers for what's going on here.

syntax = "proto3";

package mz_persist.gen.persist;

message ProtoU64Antichain {
    repeated uint64 elements = 1;
}

message ProtoU64Description {
    ProtoU64Antichain lower = 1;
    ProtoU64Antichain upper = 2;
    ProtoU64Antichain since = 3;
}

message ProtoBatchPartInline {
    ProtoBatchFormat format = 1;
    // TraceBatchParts can contain partial data for a given trace batch, and so
    // this desc means only that the records contained in this part have to
    // abide by the constraints in the description. There may be other parts
    // for the same trace batch with the same description. However, there will
    // be only one trace batch with the same description and index.
    ProtoU64Description desc = 2;
    uint64 index = 3;
}

enum ProtoBatchFormat {
    Unknown = 0;
    // Arrow, which we'd use for the local blob cache if we use it, gets a
    // structure like `[(K, V, T, D)]` so that we could mmap it and use it
    // directly as our in-mem batches (which have this structure).
    ArrowKVTD = 1;
    // We have more flexibility with Parquet. Initially we'll start with the
    // same `[(K, V, T, D)]` as our in-mem batches. Another option would be
    // something like `[(K, [(V, [(T, D)])])]`, which would only store each
    // key's and each val's data once (this is similar to the
    // [differential_dataflow::trace::layers::Trie] structure of
    // [differential_dataflow::trace::implementations::ord::OrdValBatch]).
    //
    // Which is better probably comes down to how much duplication we expect of
    // keys and vals in a batch as well as how big the batches are (the trie
    // structure introduces more columns, so has some amount of overhead).
    //
    // For unsealed batches, we have a better chance of duplicates than trace,
    // but we probably don't want to pay the cost of converting between the
    // in-mem `[(K, V, T, D)]` representation and anything else (to keep the hot
    // path clean). Unsealed batches are also likely to be our smallest. For
    // this reason, they'll probably always stay as ParquetKvtd.
    //
    // For trace batches, we consolidate them before writing them out, so we're
    // guaranteed to get nothing from the V level of the trie. For duplicate
    // keys, we'll probably get a good amount of benefit from column specific
    // compression, and I'd like to exhaust that direction first before dealing
    // with a trie-like column structure.
    ParquetKvtd = 2;
}
