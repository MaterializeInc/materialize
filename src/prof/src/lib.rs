// Copyright Materialize, Inc. and contributors. All rights reserved.
//
// Use of this software is governed by the Business Source License
// included in the LICENSE file.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0.

// BEGIN LINT CONFIG
// DO NOT EDIT. Automatically generated by bin/gen-lints.
// Have complaints about the noise? See the note in misc/python/cli/gen-lints.py first.
#![allow(clippy::style)]
#![allow(clippy::complexity)]
#![allow(clippy::large_enum_variant)]
#![allow(clippy::mutable_key_type)]
#![allow(clippy::stable_sort_primitive)]
#![allow(clippy::map_entry)]
#![allow(clippy::box_default)]
#![warn(clippy::bool_comparison)]
#![warn(clippy::clone_on_ref_ptr)]
#![warn(clippy::no_effect)]
#![warn(clippy::unnecessary_unwrap)]
#![warn(clippy::dbg_macro)]
#![warn(clippy::todo)]
#![warn(clippy::wildcard_dependencies)]
#![warn(clippy::zero_prefixed_literal)]
#![warn(clippy::borrowed_box)]
#![warn(clippy::deref_addrof)]
#![warn(clippy::double_must_use)]
#![warn(clippy::double_parens)]
#![warn(clippy::extra_unused_lifetimes)]
#![warn(clippy::needless_borrow)]
#![warn(clippy::needless_question_mark)]
#![warn(clippy::needless_return)]
#![warn(clippy::redundant_pattern)]
#![warn(clippy::redundant_slicing)]
#![warn(clippy::redundant_static_lifetimes)]
#![warn(clippy::single_component_path_imports)]
#![warn(clippy::unnecessary_cast)]
#![warn(clippy::useless_asref)]
#![warn(clippy::useless_conversion)]
#![warn(clippy::builtin_type_shadow)]
#![warn(clippy::duplicate_underscore_argument)]
#![warn(clippy::double_neg)]
#![warn(clippy::unnecessary_mut_passed)]
#![warn(clippy::wildcard_in_or_patterns)]
#![warn(clippy::collapsible_if)]
#![warn(clippy::collapsible_else_if)]
#![warn(clippy::crosspointer_transmute)]
#![warn(clippy::excessive_precision)]
#![warn(clippy::overflow_check_conditional)]
#![warn(clippy::as_conversions)]
#![warn(clippy::match_overlapping_arm)]
#![warn(clippy::zero_divided_by_zero)]
#![warn(clippy::must_use_unit)]
#![warn(clippy::suspicious_assignment_formatting)]
#![warn(clippy::suspicious_else_formatting)]
#![warn(clippy::suspicious_unary_op_formatting)]
#![warn(clippy::mut_mutex_lock)]
#![warn(clippy::print_literal)]
#![warn(clippy::same_item_push)]
#![warn(clippy::useless_format)]
#![warn(clippy::write_literal)]
#![warn(clippy::redundant_closure)]
#![warn(clippy::redundant_closure_call)]
#![warn(clippy::unnecessary_lazy_evaluations)]
#![warn(clippy::partialeq_ne_impl)]
#![warn(clippy::redundant_field_names)]
#![warn(clippy::transmutes_expressible_as_ptr_casts)]
#![warn(clippy::unused_async)]
#![warn(clippy::disallowed_methods)]
#![warn(clippy::disallowed_macros)]
#![warn(clippy::from_over_into)]
// END LINT CONFIG

use std::collections::{HashMap, BTreeMap};
use std::ffi::c_void;
use std::sync::atomic::AtomicBool;
use std::time::Instant;

use mz_ore::cast::CastFrom;

pub mod http;
#[cfg(all(not(target_os = "macos"), feature = "jemalloc"))]
pub mod jemalloc;
pub mod jemalloc_metrics;
pub mod time;

#[derive(Copy, Clone, Debug)]
// These constructors are dead on macOS
#[allow(dead_code)]
pub enum ProfStartTime {
    Instant(Instant),
    TimeImmemorial,
}

#[derive(Clone, Debug)]
pub struct WeightedStack {
    pub addrs: Vec<usize>,
    pub weight: f64,
}

#[derive(Default)]
pub struct StackProfile {
    annotations: Vec<String>,
    // The second element is the index in `annotations`, if one exists.
    stacks: Vec<(WeightedStack, Option<usize>)>,
    mappings: Vec<Mapping>,
}
pub struct Mapping {
    pub begin: usize,
    pub end: usize,
    pub offset: usize,
    pub pathname: String,
    pub build_id: Option<Vec<u8>>,
}

impl StackProfile {
    /// Writes out the `.mzfg` format, which is fully described in flamegraph.js.
    pub fn to_mzfg(&self, symbolicate: bool, header_extra: &[(&str, &str)]) -> String {
        // All the unwraps in this function are justified by the fact that
        // String's fmt::Write impl is infallible.
        use std::fmt::Write;
        let mut builder = r#"!!! COMMENT !!!: Open with bin/fgviz /path/to/mzfg
mz_fg_version: 1
"#
        .to_owned();
        for (k, v) in header_extra {
            assert!(!(k.contains(':') || k.contains('\n') || v.contains('\n')));
            writeln!(&mut builder, "{k}: {v}").unwrap();
        }
        writeln!(&mut builder, "").unwrap();

        for (WeightedStack { addrs, weight }, anno) in &self.stacks {
            let anno = anno.map(|i| &self.annotations[i]);
            for &addr in addrs {
                write!(&mut builder, "{addr:#x};").unwrap();
            }
            write!(&mut builder, " {weight}").unwrap();
            if let Some(anno) = anno {
                write!(&mut builder, " {anno}").unwrap()
            }
            writeln!(&mut builder, "").unwrap();
        }

        if symbolicate {
            let symbols = crate::symbolicate(self);
            writeln!(&mut builder, "").unwrap();

            for (addr, names) in symbols {
                if !names.is_empty() {
                    write!(&mut builder, "{addr:#x} ").unwrap();
                    for mut name in names {
                        // The client splits on semicolons, so
                        // we have to escape them.
                        name = name.replace('\\', "\\\\");
                        name = name.replace(';', "\\;");
                        write!(&mut builder, "{name};").unwrap();
                    }
                    writeln!(&mut builder, "").unwrap();
                }
            }
        }

        builder
    }

    /// Converts the profile into pprof's Profile format, which is
    /// a gzipped protobuf message, of the message type defined
    /// (and rather well-documented)
    /// in `profile.proto` in the `mz-proto` crate.
    pub fn to_pprof(
        &self,
        sample_type: &str,
        sample_unit: &str,
        resolution: usize,
        anno_key: Option<&str>,
        // Unlike `pprof`, Polar Signals requires that addresses in profile files be
        // relative to file offsets, rather than memory offsets.
        polar_signals_mode: bool,
    ) -> Vec<u8> {
        use mz_proto::profile::{
            Label, Location, Mapping as ProtoMapping, Profile, Sample, ValueType,
        };

        let mut anno_indices = HashMap::new();
        let mut pathname_indices = HashMap::new();
        let mut recorded_locations = HashMap::new();
        let mut build_id_indices = HashMap::new();

        const SAMPLE_TYPE_IDX: i64 = 1;
        const SAMPLE_UNIT_IDX: i64 = 2;
        const ANNO_KEY_IDX: i64 = 3;

        let mut profile = Profile {
            sample_type: vec![ValueType {
                ty: SAMPLE_TYPE_IDX,
                unit: SAMPLE_UNIT_IDX,
            }],
            string_table: if let Some(anno_key) = anno_key {
                vec![
                    String::new(),
                    sample_type.to_owned(),
                    sample_unit.to_owned(),
                    anno_key.to_owned(),
                ]
            } else {
                vec![
                    String::new(),
                    sample_type.to_owned(),
                    sample_unit.to_owned(),
                ]
            },
            time_nanos: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_nanos()
                .try_into()
                .unwrap(),
            ..Default::default()
        };
        for (
            mapping_index,
            Mapping {
                begin,
                end,
                offset,
                pathname,
                build_id,
            },
        ) in self.mappings.iter().enumerate()
        {
            let build_id_index = {
                build_id.as_ref().map(|bi| {
                    let &mut idx = build_id_indices.entry(bi.clone()).or_insert_with(|| {
                        let build_id_string = {
                            let mut builder = String::with_capacity(40);
                            for byte in bi {
                                use std::fmt::Write;
                                write!(&mut builder, "{byte:02x}")
                                    .expect("Write is infallible for String");
                            }
                            builder
                        };
                        profile.string_table.push(build_id_string);
                        profile.string_table.len() - 1
                    });
                    (idx).try_into().expect("vector length must fit into i64")
                })
            };
            let &mut pathname_index =
                pathname_indices
                    .entry(pathname.as_str())
                    .or_insert_with(|| {
                        profile.string_table.push(pathname.to_string());
                        profile.string_table.len() - 1
                    });
            profile.mapping.push(ProtoMapping {
                id: u64::cast_from(mapping_index) + 1,
                memory_start: u64::cast_from(*begin),
                memory_limit: u64::cast_from(*end),
                file_offset: u64::cast_from(*offset),
                filename: pathname_index
                    .try_into()
                    .expect("vector length must fit into i64"),
                build_id: build_id_index.unwrap_or(0),
                ..Default::default()
            })
        }
        for (WeightedStack { addrs, weight }, anno) in self.iter() {
            let mut sample = Sample::default();
            if let Some(anno) = anno {
                assert!(anno_key.is_some());
                let &mut index = anno_indices.entry(anno).or_insert_with(|| {
                    profile.string_table.push(anno.to_string());
                    profile.string_table.len() - 1
                });
                sample.label.push(Label {
                    key: ANNO_KEY_IDX,
                    str: index.try_into().expect("vector length must fit into i64"),
                    ..Default::default()
                });
            }
            sample.value = vec![(*weight * (resolution as f64)) as i64];
            for &addr in addrs.iter().rev() {
                let addr = u64::cast_from(addr);
                let &mut loc_id = recorded_locations.entry(addr).or_insert_with(|| {
                    let id = u64::cast_from(profile.location.len()) + 1;
                    let mapping_id = profile
                        .mapping
                        .iter()
                        .position(
                            |&ProtoMapping {
                                 memory_start,
                                 memory_limit,
                                 ..
                             }| {
                                memory_start <= addr && addr <= memory_limit
                            },
                        )
                        .map(|x| x + 1)
                        .unwrap_or(0);
                    
                    let addr = if polar_signals_mode && mapping_id > 0 {
                        let mapping = &profile.mapping[mapping_id as usize - 1];
                        addr - mapping.memory_start + mapping.file_offset
                    } else {
                        addr
                    };

                    let loc = Location {
                        address: addr,
                        id,
                        mapping_id: u64::cast_from(mapping_id),
                        ..Default::default()
                    };
                    profile.location.push(loc);
                    id
                });

                sample.location_id.push(loc_id);
            }
            profile.sample.push(sample);
        }

        use prost::Message;
        let out_uncompressed = profile.encode_to_vec();

        use flate2::write::GzEncoder;
        use flate2::Compression;

        let mut e = GzEncoder::new(Vec::new(), Compression::default());
        use std::io::Write;
        e.write_all(&out_uncompressed).unwrap();
        e.finish().unwrap()
    }
}

pub struct StackProfileIter<'a> {
    inner: &'a StackProfile,
    idx: usize,
}

impl<'a> Iterator for StackProfileIter<'a> {
    type Item = (&'a WeightedStack, Option<&'a str>);

    fn next(&mut self) -> Option<Self::Item> {
        let (stack, anno) = self.inner.stacks.get(self.idx)?;
        self.idx += 1;
        let anno = anno.map(|idx| self.inner.annotations.get(idx).unwrap().as_str());
        Some((stack, anno))
    }
}

impl StackProfile {
    pub fn push(&mut self, stack: WeightedStack, annotation: Option<&str>) {
        let anno_idx = if let Some(annotation) = annotation {
            Some(
                self.annotations
                    .iter()
                    .position(|anno| annotation == anno.as_str())
                    .unwrap_or_else(|| {
                        self.annotations.push(annotation.to_string());
                        self.annotations.len() - 1
                    }),
            )
        } else {
            None
        };
        self.stacks.push((stack, anno_idx))
    }
    pub fn push_mapping(&mut self, mapping: Mapping) {
        self.mappings.push(mapping);
    }
    pub fn iter(&self) -> StackProfileIter<'_> {
        StackProfileIter {
            inner: self,
            idx: 0,
        }
    }
    pub fn mappings(&self) -> &[Mapping] {
        &self.mappings
    }
}

static EVER_SYMBOLICATED: AtomicBool = AtomicBool::new(false);

/// Check whether symbolication has ever been run in this process.
/// This controls whether we display a warning about increasing RAM usage
/// due to the backtrace cache on the
/// profiler page. (Because the RAM hit is one-time, we don't need to warn if it's already happened).
pub fn ever_symbolicated() -> bool {
    EVER_SYMBOLICATED.load(std::sync::atomic::Ordering::SeqCst)
}

/// Given some stack traces, generate a map of addresses to their
/// corresponding symbols.
///
/// Each address could correspond to more than one symbol, because
/// of inlining. (E.g. if 0x1234 comes from "g", which is inlined in "f", the corresponding vec of symbols will be ["f", "g"].)
pub fn symbolicate(profile: &StackProfile) -> BTreeMap<usize, Vec<String>> {
    EVER_SYMBOLICATED.store(true, std::sync::atomic::Ordering::SeqCst);
    let mut all_addrs = vec![];
    for (stack, _annotation) in profile.stacks.iter() {
        all_addrs.extend(stack.addrs.iter().cloned());
    }
    // Sort so addresses from the same images are together,
    // to avoid thrashing `backtrace::resolve`'s cache of
    // parsed images.
    all_addrs.sort_unstable();
    all_addrs.dedup();
    all_addrs
        .into_iter()
        .map(|addr| {
            let mut syms = vec![];
            // No other known way to convert usize to pointer.
            #[allow(clippy::as_conversions)]
            let addr_ptr = addr as *mut c_void;
            backtrace::resolve(addr_ptr, |sym| {
                let name = sym
                    .name()
                    .map(|sn| sn.to_string())
                    .unwrap_or_else(|| "???".to_string());
                syms.push(name);
            });
            syms.reverse();
            (addr, syms)
        })
        .collect()
}
