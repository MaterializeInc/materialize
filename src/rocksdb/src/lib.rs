// Copyright Materialize, Inc. and contributors. All rights reserved.
//
// Use of this software is governed by the Business Source License
// included in the LICENSE file.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0.

// BEGIN LINT CONFIG
// DO NOT EDIT. Automatically generated by bin/gen-lints.
// Have complaints about the noise? See the note in misc/python/materialize/cli/gen-lints.py first.
#![allow(clippy::style)]
#![allow(clippy::complexity)]
#![allow(clippy::large_enum_variant)]
#![allow(clippy::mutable_key_type)]
#![allow(clippy::stable_sort_primitive)]
#![allow(clippy::map_entry)]
#![allow(clippy::box_default)]
#![warn(clippy::bool_comparison)]
#![warn(clippy::clone_on_ref_ptr)]
#![warn(clippy::no_effect)]
#![warn(clippy::unnecessary_unwrap)]
#![warn(clippy::dbg_macro)]
#![warn(clippy::todo)]
#![warn(clippy::wildcard_dependencies)]
#![warn(clippy::zero_prefixed_literal)]
#![warn(clippy::borrowed_box)]
#![warn(clippy::deref_addrof)]
#![warn(clippy::double_must_use)]
#![warn(clippy::double_parens)]
#![warn(clippy::extra_unused_lifetimes)]
#![warn(clippy::needless_borrow)]
#![warn(clippy::needless_question_mark)]
#![warn(clippy::needless_return)]
#![warn(clippy::redundant_pattern)]
#![warn(clippy::redundant_slicing)]
#![warn(clippy::redundant_static_lifetimes)]
#![warn(clippy::single_component_path_imports)]
#![warn(clippy::unnecessary_cast)]
#![warn(clippy::useless_asref)]
#![warn(clippy::useless_conversion)]
#![warn(clippy::builtin_type_shadow)]
#![warn(clippy::duplicate_underscore_argument)]
#![warn(clippy::double_neg)]
#![warn(clippy::unnecessary_mut_passed)]
#![warn(clippy::wildcard_in_or_patterns)]
#![warn(clippy::crosspointer_transmute)]
#![warn(clippy::excessive_precision)]
#![warn(clippy::overflow_check_conditional)]
#![warn(clippy::as_conversions)]
#![warn(clippy::match_overlapping_arm)]
#![warn(clippy::zero_divided_by_zero)]
#![warn(clippy::must_use_unit)]
#![warn(clippy::suspicious_assignment_formatting)]
#![warn(clippy::suspicious_else_formatting)]
#![warn(clippy::suspicious_unary_op_formatting)]
#![warn(clippy::mut_mutex_lock)]
#![warn(clippy::print_literal)]
#![warn(clippy::same_item_push)]
#![warn(clippy::useless_format)]
#![warn(clippy::write_literal)]
#![warn(clippy::redundant_closure)]
#![warn(clippy::redundant_closure_call)]
#![warn(clippy::unnecessary_lazy_evaluations)]
#![warn(clippy::partialeq_ne_impl)]
#![warn(clippy::redundant_field_names)]
#![warn(clippy::transmutes_expressible_as_ptr_casts)]
#![warn(clippy::unused_async)]
#![warn(clippy::disallowed_methods)]
#![warn(clippy::disallowed_macros)]
#![warn(clippy::disallowed_types)]
#![warn(clippy::from_over_into)]
// END LINT CONFIG

//! An async wrapper around RocksDB, that does IO on a separate thread.
//!
//! This crate offers a limited API to communicate with RocksDB, to get
//! the best performance possible (most importantly, by batching operations).
//! Currently this API is only `upsert`, which replaces (or deletes) values for
//! a set of keys, and returns the previous values.

#![warn(missing_docs)]

use std::path::{Path, PathBuf};
use std::time::Instant;

use rocksdb::{
    DBCompressionType, Env, Error as RocksDBError, Options as RocksDBOptions, WriteOptions, DB,
};
use tokio::sync::{mpsc, oneshot};

use mz_ore::cast::CastLossy;
use mz_ore::metrics::DeleteOnDropHistogram;
use mz_persist_types::Codec;

/// An error using this RocksDB wrapper.
#[derive(Debug, thiserror::Error)]
pub enum Error {
    /// An error from the underlying Kafka library.
    #[error(transparent)]
    RocksDB(#[from] RocksDBError),

    /// Error when using the instance after RocksDB as errored
    /// or been shutdown.
    #[error("RocksDB thread has been shut down or errored")]
    RocksDBThreadGoneAway,

    /// Error decoding a value previously written.
    #[error("failed to decode value: {0}")]
    DecodeError(String),

    /// A tokio thread used by the implementation panicked.
    #[error("tokio thread panicked")]
    TokioPanic(#[from] tokio::task::JoinError),
}

/// Options to configure a [`RocksDBInstance`].
pub struct Options {
    /// Whether or not to clear state at the instance
    /// path before starting.
    pub cleanup_on_new: bool,

    /// Whether or not to write writes
    /// to the wal.
    pub use_wal: bool,

    /// Compression type for blocks and blobs.
    pub compression_type: DBCompressionType,

    /// A possibly shared RocksDB `Env`.
    pub env: Env,
}

/// Metrics about an instances usage of RocksDB. User-provided
/// so the user can choose the labels.
pub struct RocksDBMetrics {
    /// Latency of multi_gets, in fractional seconds.
    pub multi_get_latency: DeleteOnDropHistogram<'static, Vec<String>>,
    /// Size of multi_get batches.
    pub multi_get_batch_size: DeleteOnDropHistogram<'static, Vec<String>>,
    /// Latency of write batch writes, in fractional seconds.
    pub write_latency: DeleteOnDropHistogram<'static, Vec<String>>,
    /// Size of write batches.
    pub write_batch_size: DeleteOnDropHistogram<'static, Vec<String>>,
}

impl Options {
    /// A new `Options` object with reasonable defaults.
    pub fn new_with_defaults() -> Result<Self, RocksDBError> {
        Ok(Options {
            cleanup_on_new: true,
            use_wal: false,
            compression_type: DBCompressionType::Snappy,
            env: rocksdb::Env::new()?,
        })
    }

    fn as_rocksdb_options(&self) -> RocksDBOptions {
        let mut options = rocksdb::Options::default();
        options.create_if_missing(true);

        /*
        // Dumped every 600 seconds.
        rocks_options.enable_statistics();
        rocks_options.set_report_bg_io_stats(true);
        */

        options.set_compression_type(self.compression_type);
        options.set_blob_compression_type(self.compression_type);

        options.set_env(&self.env);
        options
    }

    fn as_rocksdb_write_options(&self) -> WriteOptions {
        let mut wo = rocksdb::WriteOptions::new();
        wo.disable_wal(!self.use_wal);
        wo
    }
}

/// A (key, value) to insert (or delete). RocksDB runs a different thread,
/// which is why owned versions are required.
#[derive(Clone, Debug, Eq, PartialEq)]
pub struct UpsertValue<K, V> {
    /// The key to upsert.
    pub key: K,
    /// The value to upsert (or delete).
    pub val: Option<V>,
}

/// A previous value for a key, plus the
/// key and value being upserted.
#[derive(Clone, Debug, Eq, PartialEq)]
pub struct UpsertResult<K, V> {
    /// The key that was upserted.
    pub key: K,
    /// The value that was upserted (or deleted).
    pub val: Option<V>,
    /// The previous value for the key, if any.
    pub previous_value: Option<V>,
}

#[derive(Debug)]
enum Command<K, V> {
    Upsert {
        // TODO(guswynn): consider using columnar storage or a re-used vector to avoid allocations
        // here.
        batch: Vec<UpsertValue<K, V>>,
        response_sender: oneshot::Sender<Result<Vec<UpsertResult<K, V>>, Error>>,
    },
    Shutdown {
        done_sender: oneshot::Sender<()>,
    },
}

/// An async wrapper around RocksDB.
#[derive(Clone)]
pub struct RocksDBInstance<K, V> {
    tx: mpsc::Sender<Command<K, V>>,
}

impl<K, V> RocksDBInstance<K, V>
where
    K: Codec + Send + Sync + 'static,
    V: Codec + Send + Sync + 'static,
{
    /// Start a new RocksDB instance at the path.
    pub async fn new(
        instance_path: &Path,
        options: Options,
        metrics: RocksDBMetrics,
    ) -> Result<Self, Error> {
        if options.cleanup_on_new && instance_path.exists() {
            let instance_path_owned = instance_path.to_owned();
            mz_ore::task::spawn_blocking(
                || format!("RocksDB instance at {}: cleanup", instance_path.display()),
                move || {
                    DB::destroy(&RocksDBOptions::default(), instance_path_owned).unwrap();
                },
            )
            .await?;
        }

        // The buffer can be small here, as all interactions with it take `&mut self`.
        let (tx, rx): (mpsc::Sender<Command<K, V>>, _) = mpsc::channel(10);

        let instance_path = instance_path.to_owned();

        std::thread::spawn(move || rocksdb_core_loop(options, instance_path, rx, metrics));

        Ok(Self { tx })
    }

    /// Upsert a batch of values, returning the keys and values back, along
    /// with previous values. If this errors, the `RocksDB` instance becomes
    /// unusable.
    pub async fn upsert(
        &mut self,
        batch: Vec<UpsertValue<K, V>>,
    ) -> Result<Vec<UpsertResult<K, V>>, Error> {
        if batch.is_empty() {
            return Ok(Vec::new());
        }

        let (tx, rx) = oneshot::channel();
        self.tx
            .send(Command::Upsert {
                batch,
                response_sender: tx,
            })
            .await
            .map_err(|_| Error::RocksDBThreadGoneAway)?;

        // We also unwrap all rocksdb errors here.
        rx.await.map_err(|_| Error::RocksDBThreadGoneAway)?
    }

    /// Gracefully shut down RocksDB. Can error if the instance
    /// is already shut down or errored.
    pub async fn close(self) -> Result<(), Error> {
        let (tx, rx) = oneshot::channel();
        self.tx
            .send(Command::Shutdown { done_sender: tx })
            .await
            .map_err(|_| Error::RocksDBThreadGoneAway)?;

        let _ = rx.await;

        Ok(())
    }
}

// TODO(guswynn): retry retryable rocksdb errors.
fn rocksdb_core_loop<K, V>(
    options: Options,
    instance_path: PathBuf,
    mut cmd_rx: mpsc::Receiver<Command<K, V>>,
    metrics: RocksDBMetrics,
) where
    K: Codec + Send + Sync + 'static,
    V: Codec + Send + Sync + 'static,
{
    let db: DB = DB::open(&options.as_rocksdb_options(), &instance_path).unwrap();
    let wo = options.as_rocksdb_write_options();

    let mut encoded_keys = Vec::new();
    let mut encoded_values = Vec::new();

    while let Some(cmd) = cmd_rx.blocking_recv() {
        let (batch, response_sender) = match cmd {
            Command::Shutdown { done_sender } => {
                db.cancel_all_background_work(true);
                drop(db);
                let _ = done_sender.send(());
                return;
            }
            Command::Upsert {
                batch,
                response_sender,
            } => (batch, response_sender),
        };

        encoded_keys.clear();
        encoded_values.clear();
        for up in batch.iter() {
            encoded_keys.push({
                let mut encode_buf = Vec::<u8>::new();
                up.key.encode(&mut encode_buf);
                encode_buf
            });
            encoded_values.push(up.val.as_ref().map(|val| {
                let mut encode_buf = Vec::<u8>::new();
                val.encode(&mut encode_buf);
                encode_buf
            }));
        }

        let batch_size = batch.len();

        // Perform the multi_get and record metrics, if there wasn't an error.
        let now = Instant::now();
        let gets = db.multi_get(encoded_keys.iter().map(|k| k.as_slice()));
        let latency = now.elapsed();

        let gets: Result<Vec<_>, _> = gets.into_iter().collect();
        let gets = match gets {
            Ok(gets) => {
                metrics.multi_get_latency.observe(latency.as_secs_f64());
                metrics
                    .multi_get_batch_size
                    .observe(f64::cast_lossy(batch_size));
                gets
            }
            Err(e) => {
                let _ = response_sender.send(Err(Error::RocksDB(e)));
                return;
            }
        };

        let mut result = Vec::new();
        let mut writes = rocksdb::WriteBatch::default();

        // TODO(guswynn): sort by key before writing.
        for (UpsertValue { key, val }, encoded_key, encoded_value, previous_value) in
            itertools::multizip((batch, encoded_keys.iter(), encoded_values.iter(), gets))
        {
            match encoded_value {
                Some(update) => {
                    writes.put(encoded_key.as_slice(), update.as_slice());
                }
                None => writes.delete(encoded_key.as_slice()),
            }
            let previous_value = match previous_value.map(|v| V::decode(&v)).transpose() {
                Ok(v) => v,
                Err(e) => {
                    let _ = response_sender.send(Err(Error::DecodeError(e)));
                    return;
                }
            };

            result.push(UpsertResult {
                key,
                val,
                previous_value,
            });
        }
        // Perform the multi_get and record metrics, if there wasn't an error.
        let now = Instant::now();
        match db.write_opt(writes, &wo) {
            Ok(()) => {
                let latency = now.elapsed();
                metrics.write_latency.observe(latency.as_secs_f64());
                metrics
                    .write_batch_size
                    .observe(f64::cast_lossy(batch_size));
            }
            Err(e) => {
                let _ = response_sender.send(Err(Error::RocksDB(e)));
                return;
            }
        }

        let _ = response_sender.send(Ok(result));
    }

    // Gracefully cleanup if the `RocksDBInstance` has gone away.
    db.cancel_all_background_work(true);
    drop(db);
}
