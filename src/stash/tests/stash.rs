// Copyright Materialize, Inc. and contributors. All rights reserved.
//
// Use of this software is governed by the Business Source License
// included in the LICENSE file.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0.

// BEGIN LINT CONFIG
// DO NOT EDIT. Automatically generated by bin/gen-lints.
// Have complaints about the noise? See the note in misc/python/cli/gen-lints.py first.
#![allow(clippy::style)]
#![allow(clippy::complexity)]
#![allow(clippy::large_enum_variant)]
#![allow(clippy::mutable_key_type)]
#![allow(clippy::needless_collect)]
#![allow(clippy::stable_sort_primitive)]
#![allow(clippy::map_entry)]
#![allow(clippy::box_default)]
#![deny(warnings)]
#![deny(clippy::bool_comparison)]
#![deny(clippy::clone_on_ref_ptr)]
#![deny(clippy::no_effect)]
#![deny(clippy::unnecessary_unwrap)]
#![deny(clippy::dbg_macro)]
#![deny(clippy::todo)]
#![deny(clippy::wildcard_dependencies)]
#![deny(clippy::zero_prefixed_literal)]
#![deny(clippy::borrowed_box)]
#![deny(clippy::deref_addrof)]
#![deny(clippy::double_must_use)]
#![deny(clippy::double_parens)]
#![deny(clippy::extra_unused_lifetimes)]
#![deny(clippy::needless_borrow)]
#![deny(clippy::needless_question_mark)]
#![deny(clippy::needless_return)]
#![deny(clippy::redundant_pattern)]
#![deny(clippy::redundant_slicing)]
#![deny(clippy::redundant_static_lifetimes)]
#![deny(clippy::single_component_path_imports)]
#![deny(clippy::unnecessary_cast)]
#![deny(clippy::useless_asref)]
#![deny(clippy::useless_conversion)]
#![deny(clippy::builtin_type_shadow)]
#![deny(clippy::duplicate_underscore_argument)]
#![deny(clippy::double_neg)]
#![deny(clippy::unnecessary_mut_passed)]
#![deny(clippy::wildcard_in_or_patterns)]
#![deny(clippy::collapsible_if)]
#![deny(clippy::collapsible_else_if)]
#![deny(clippy::crosspointer_transmute)]
#![deny(clippy::excessive_precision)]
#![deny(clippy::overflow_check_conditional)]
#![deny(clippy::as_conversions)]
#![deny(clippy::match_overlapping_arm)]
#![deny(clippy::zero_divided_by_zero)]
#![deny(clippy::must_use_unit)]
#![deny(clippy::suspicious_assignment_formatting)]
#![deny(clippy::suspicious_else_formatting)]
#![deny(clippy::suspicious_unary_op_formatting)]
#![deny(clippy::mut_mutex_lock)]
#![deny(clippy::print_literal)]
#![deny(clippy::same_item_push)]
#![deny(clippy::useless_format)]
#![deny(clippy::write_literal)]
#![deny(clippy::redundant_closure)]
#![deny(clippy::redundant_closure_call)]
#![deny(clippy::unnecessary_lazy_evaluations)]
#![deny(clippy::partialeq_ne_impl)]
#![deny(clippy::redundant_field_names)]
#![deny(clippy::transmutes_expressible_as_ptr_casts)]
#![deny(clippy::unused_async)]
#![deny(clippy::disallowed_methods)]
#![deny(clippy::disallowed_macros)]
#![deny(clippy::from_over_into)]
// END LINT CONFIG

use std::{
    collections::{BTreeMap, BTreeSet},
    convert::Infallible,
};

use futures::Future;
use postgres_openssl::MakeTlsConnector;
use timely::progress::Antichain;
use tokio_postgres::Config;

use mz_ore::{assert_contains, metrics::MetricsRegistry};

use mz_stash::{
    Append, Cache, Memory, Postgres, PostgresFactory, Stash, StashCollection, StashError,
    TableTransaction, Timestamp, TypedCollection,
};

#[tokio::test]
async fn test_stash_memory() {
    test_stash(|| async { Memory::new() }).await;
    test_append(|| async { Memory::new() }).await;
}

#[tokio::test]
async fn test_stash_cache() {
    test_stash(|| async { Cache::new(Memory::new()) }).await;
    test_append(|| async { Cache::new(Memory::new()) }).await;
}

#[tokio::test]
async fn test_stash_postgres() {
    mz_ore::test::init_logging();

    let tls = mz_postgres_util::make_tls(&Config::new()).unwrap();
    let factory = PostgresFactory::new(&MetricsRegistry::new());

    {
        // Verify invalid URLs fail on connect.
        assert!(factory
            .open("host=invalid".into(), None, tls.clone(),)
            .await
            .unwrap_err()
            .to_string()
            .contains("stash error: postgres: error connecting to server"));
    }

    let connstr = match std::env::var("POSTGRES_URL") {
        Ok(s) => s,
        Err(_) => {
            println!("skipping test_stash_postgres because POSTGRES_URL is not set");
            return;
        }
    };
    async fn connect(
        factory: &PostgresFactory,
        connstr: &str,
        tls: MakeTlsConnector,
        clear: bool,
    ) -> Postgres {
        if clear {
            Postgres::clear(connstr, tls.clone()).await.unwrap();
        }
        factory.open(connstr.to_string(), None, tls).await.unwrap()
    }
    {
        connect(&factory, &connstr, tls.clone(), true).await;
        let stash =
            test_stash(|| async { connect(&factory, &connstr, tls.clone(), false).await }).await;
        stash.verify().await.unwrap();
    }
    {
        connect(&factory, &connstr, tls.clone(), true).await;
        let stash =
            test_append(|| async { connect(&factory, &connstr, tls.clone(), false).await }).await;
        stash.verify().await.unwrap();
    }
    // Test the fence.
    {
        let mut conn1 = connect(&factory, &connstr, tls.clone(), true).await;
        // Don't clear the stash tables.
        let mut conn2 = connect(&factory, &connstr, tls.clone(), false).await;
        assert!(match conn1.collection::<String, String>("c").await {
            Err(e) => e.is_unrecoverable(),
            _ => panic!("expected error"),
        });
        let _: StashCollection<String, String> = conn2.collection("c").await.unwrap();
    }
    // Test readonly.
    {
        Postgres::clear(&connstr, tls.clone()).await.unwrap();
        let mut stash_rw = factory
            .open(connstr.to_string(), None, tls.clone())
            .await
            .unwrap();
        let col_rw = stash_rw.collection::<i64, i64>("c1").await.unwrap();
        let mut batch = col_rw.make_batch(&mut stash_rw).await.unwrap();
        col_rw.append_to_batch(&mut batch, &1, &2, 1);
        stash_rw.append(&[batch]).await.unwrap();

        // Now make a readonly stash. We should fail to create new collections,
        // but be able to read existing collections.
        let mut stash_ro = factory
            .open_readonly(connstr.to_string(), None, tls.clone())
            .await
            .unwrap();
        let res = stash_ro.collection::<i64, i64>("c2").await;
        assert_contains!(
            res.unwrap_err().to_string(),
            "cannot execute INSERT in a read-only transaction"
        );
        let col_ro = stash_ro.collection::<i64, i64>("c1").await.unwrap();
        assert_eq!(stash_ro.peek(col_ro).await.unwrap(), vec![(1, 2, 1)],);

        // The previous stash should still be the leader.
        assert!(stash_rw.confirm_leadership().await.is_ok());
        stash_rw.verify().await.unwrap();
    }
    // Test savepoint.
    {
        let mut stash_rw = factory
            .open(connstr.to_string(), None, tls.clone())
            .await
            .unwrap();
        // Data still present from previous test.
        let c1_rw = stash_rw.collection::<i64, i64>("c1").await.unwrap();

        // Now make a savepoint stash. We should be allowed to create anything
        // we want, but it shouldn't be viewable to other stashes.
        let mut stash_sp = factory
            .open_savepoint(connstr.to_string(), tls)
            .await
            .unwrap();
        let c1_sp = stash_rw.collection::<i64, i64>("c1").await.unwrap();
        let mut batch = c1_sp.make_batch(&mut stash_sp).await.unwrap();
        c1_sp.append_to_batch(&mut batch, &5, &6, 1);
        stash_sp.append(&[batch]).await.unwrap();
        assert_eq!(
            stash_sp.peek(c1_sp).await.unwrap(),
            vec![(1, 2, 1), (5, 6, 1)]
        );
        // RW collection can't see the new row.
        assert_eq!(stash_rw.peek(c1_rw).await.unwrap(), vec![(1, 2, 1)]);

        // SP stash can create a new collection, append to it, peek it.
        let c_savepoint = stash_sp
            .collection::<i64, i64>("c_savepoint")
            .await
            .unwrap();
        let mut batch = c_savepoint.make_batch(&mut stash_sp).await.unwrap();
        c_savepoint.append_to_batch(&mut batch, &3, &4, 1);
        stash_sp.append(&[batch]).await.unwrap();
        assert_eq!(stash_sp.peek(c_savepoint).await.unwrap(), vec![(3, 4, 1)]);
        // But the RW collection can't see it.
        assert_eq!(
            stash_rw.collections().await.unwrap(),
            BTreeSet::from(["c1".to_string()])
        );

        drop(stash_sp);

        // The previous stash should still be the leader.
        assert!(stash_rw.confirm_leadership().await.is_ok());
        // Verify c1 didn't change.
        assert_eq!(stash_rw.peek(c1_rw).await.unwrap(), vec![(1, 2, 1)]);
        stash_rw.verify().await.unwrap();
    }
}

async fn test_append<F, S, O>(f: F) -> S
where
    S: Append,
    O: Future<Output = S>,
    F: Fn() -> O,
{
    const TYPED: TypedCollection<String, String> = TypedCollection::new("typed");

    let mut stash = f().await;

    // Can't peek if since == upper.
    assert!(TYPED
        .peek_one(&mut stash)
        .await
        .unwrap_err()
        .to_string()
        .contains("since {-9223372036854775808} is not less than upper {-9223372036854775808}"));
    TYPED
        .upsert_key(&mut stash, &"k1".to_string(), |_| {
            Ok::<_, Infallible>("v1".to_string())
        })
        .await
        .unwrap()
        .unwrap();
    assert_eq!(
        TYPED.peek_one(&mut stash).await.unwrap(),
        BTreeMap::from([("k1".to_string(), "v1".to_string())])
    );
    TYPED
        .upsert_key(&mut stash, &"k1".to_string(), |_| {
            Ok::<_, Infallible>("v2".to_string())
        })
        .await
        .unwrap()
        .unwrap();
    assert_eq!(
        TYPED.peek_one(&mut stash).await.unwrap(),
        BTreeMap::from([("k1".to_string(), "v2".to_string())])
    );
    assert_eq!(
        TYPED
            .peek_key_one(&mut stash, &"k1".to_string())
            .await
            .unwrap(),
        Some("v2".to_string()),
    );
    assert_eq!(
        TYPED
            .peek_key_one(&mut stash, &"k2".to_string())
            .await
            .unwrap(),
        None
    );
    TYPED
        .upsert(
            &mut stash,
            vec![
                ("k1".to_string(), "v3".to_string()),
                ("k2".to_string(), "v4".to_string()),
            ],
        )
        .await
        .unwrap();
    assert_eq!(
        TYPED.peek_one(&mut stash).await.unwrap(),
        BTreeMap::from([
            ("k1".to_string(), "v3".to_string()),
            ("k2".to_string(), "v4".to_string())
        ])
    );

    // Test append across collections.
    let orders = stash.collection::<String, String>("orders").await.unwrap();
    let other = stash.collection::<String, String>("other").await.unwrap();
    // Seal so we can invalidate the upper below.
    stash
        .seal(other, Antichain::from_elem(1).borrow())
        .await
        .unwrap();
    let mut orders_batch = orders.make_batch(&mut stash).await.unwrap();
    orders.append_to_batch(&mut orders_batch, &"k1".to_string(), &"v1".to_string(), 1);
    let mut other_batch = other.make_batch(&mut stash).await.unwrap();
    other.append_to_batch(&mut other_batch, &"k2".to_string(), &"v2".to_string(), 1);

    // Invalidate one upper and ensure append doesn't commit partial batches.
    let other_upper = other_batch.upper;
    other_batch.upper = Antichain::from_elem(Timestamp::MIN);
    assert_eq!(
          stash
            .append(&[orders_batch.clone(), other_batch.clone()]).await
            .unwrap_err()
            .to_string(),
        "stash error: seal request {-9223372036854775808} is less than the current upper frontier {1}",
    );
    // Test batches in the other direction too.
    assert_eq!(
        stash
            .append(&[other_batch.clone(),orders_batch.clone() ]).await
            .unwrap_err()
            .to_string(),
        "stash error: seal request {-9223372036854775808} is less than the current upper frontier {1}",
    );

    // Fix the upper, append should work now.
    other_batch.upper = other_upper;
    stash.append(&[other_batch, orders_batch]).await.unwrap();
    assert_eq!(
        stash.iter(orders).await.unwrap(),
        &[(("k1".into(), "v1".into()), -9223372036854775808, 1),]
    );
    assert_eq!(
        stash.iter(other).await.unwrap(),
        &[(("k2".into(), "v2".into()), 1, 1),]
    );
    assert_eq!(
        stash.peek_one(orders).await.unwrap(),
        BTreeMap::from([("k1".to_string(), "v1".to_string())])
    );
    assert_eq!(
        stash.peek_one(other).await.unwrap(),
        BTreeMap::from([("k2".to_string(), "v2".to_string())])
    );

    // Verify the upper got bumped.
    assert_eq!(
        stash.since(orders).await.unwrap().into_option().unwrap(),
        stash.upper(orders).await.unwrap().into_option().unwrap() - 1
    );
    // Multiple empty batches should bump the upper and the since because append
    // must also compact and consolidate.
    for _ in 0..5 {
        let orders_batch = orders.make_batch(&mut stash).await.unwrap();
        stash.append(&[orders_batch]).await.unwrap();
        assert_eq!(
            stash.since(orders).await.unwrap().into_option().unwrap(),
            stash.upper(orders).await.unwrap().into_option().unwrap() - 1
        );
    }

    // Don't attempt to verify persisted data for stashes that do not advertise it.
    if stash.epoch().is_none() {
        return stash;
    }

    // Remake the stash and ensure data remains.
    let mut stash = f().await;
    assert_eq!(
        stash.peek_one(orders).await.unwrap(),
        BTreeMap::from([("k1".to_string(), "v1".to_string())])
    );
    assert_eq!(
        stash.peek_one(other).await.unwrap(),
        BTreeMap::from([("k2".to_string(), "v2".to_string())])
    );
    // Remake again, mutate before reading, then read.
    let mut stash = f().await;
    stash
        .update_many(orders, [(("k3".into(), "v3".into()), 1, 1)])
        .await
        .unwrap();
    stash
        .seal(orders, Antichain::from_elem(2).borrow())
        .await
        .unwrap();

    assert_eq!(
        stash.peek_one(orders).await.unwrap(),
        BTreeMap::from([
            ("k1".to_string(), "v1".to_string()),
            ("k3".to_string(), "v3".to_string())
        ])
    );

    // Remake the stash, mutate, then read.
    let mut stash = f().await;
    let mut orders_batch = orders.make_batch(&mut stash).await.unwrap();
    orders.append_to_batch(&mut orders_batch, &"k4".to_string(), &"v4".to_string(), 1);
    stash.append(&[orders_batch]).await.unwrap();
    assert_eq!(
        stash.peek_one(orders).await.unwrap(),
        BTreeMap::from([
            ("k1".to_string(), "v1".to_string()),
            ("k3".to_string(), "v3".to_string()),
            ("k4".to_string(), "v4".to_string())
        ])
    );

    // Remake and read again.
    let mut stash = f().await;
    assert_eq!(
        stash.peek_one(orders).await.unwrap(),
        BTreeMap::from([
            ("k1".to_string(), "v1".to_string()),
            ("k3".to_string(), "v3".to_string()),
            ("k4".to_string(), "v4".to_string())
        ])
    );

    test_stash_table(&mut stash).await;

    stash
}

async fn test_stash<F, S, O>(f: F) -> S
where
    S: Stash,
    O: Future<Output = S>,
    F: Fn() -> O,
{
    let mut stash = f().await;
    // Create an arrangement, write some data into it, then read it back.
    let orders = stash.collection::<String, String>("orders").await.unwrap();
    stash
        .update(orders, ("widgets".into(), "1".into()), 1, 1)
        .await
        .unwrap();
    stash
        .update(orders, ("wombats".into(), "2".into()), 1, 2)
        .await
        .unwrap();
    // Move this before iter to better test the memory stash's iter_key.
    assert_eq!(
        stash
            .iter_key(orders, &"widgets".to_string())
            .await
            .unwrap(),
        &[("1".into(), 1, 1)]
    );
    assert_eq!(
        stash.iter(orders).await.unwrap(),
        &[
            (("widgets".into(), "1".into()), 1, 1),
            (("wombats".into(), "2".into()), 1, 2),
        ]
    );
    assert_eq!(
        stash
            .iter_key(orders, &"wombats".to_string())
            .await
            .unwrap(),
        &[("2".into(), 1, 2)]
    );

    // Write to another arrangement and ensure the data stays separate.
    let other = stash.collection::<String, String>("other").await.unwrap();
    stash
        .update(other, ("foo".into(), "bar".into()), 1, 1)
        .await
        .unwrap();
    assert_eq!(
        stash.iter(other).await.unwrap(),
        &[(("foo".into(), "bar".into()), 1, 1)],
    );
    assert_eq!(
        stash.iter(orders).await.unwrap(),
        &[
            (("widgets".into(), "1".into()), 1, 1),
            (("wombats".into(), "2".into()), 1, 2),
        ]
    );

    // Check that consolidation happens immediately...
    stash
        .update(orders, ("wombats".into(), "2".into()), 1, -1)
        .await
        .unwrap();
    assert_eq!(
        stash.iter(orders).await.unwrap(),
        &[
            (("widgets".into(), "1".into()), 1, 1),
            (("wombats".into(), "2".into()), 1, 1),
        ]
    );

    // ...even when it results in a entry's removal.
    stash
        .update(orders, ("wombats".into(), "2".into()), 1, -1)
        .await
        .unwrap();
    assert_eq!(
        stash.iter(orders).await.unwrap(),
        &[(("widgets".into(), "1".into()), 1, 1),]
    );

    // Check that logical compaction applies immediately.
    stash
        .update_many(
            orders,
            [
                (("widgets".into(), "1".into()), 2, 1),
                (("widgets".into(), "1".into()), 3, 1),
                (("widgets".into(), "1".into()), 4, 1),
            ],
        )
        .await
        .unwrap();
    stash
        .seal(orders, Antichain::from_elem(3).borrow())
        .await
        .unwrap();
    // Peek should not observe widgets from timestamps 3 or 4.
    assert_eq!(stash.peek_timestamp(orders).await.unwrap(), 2);
    assert_eq!(
        stash.peek(orders).await.unwrap(),
        vec![("widgets".into(), "1".into(), 2)]
    );
    assert_eq!(
        stash.peek_one(orders).await.unwrap_err().to_string(),
        "stash error: unexpected peek multiplicity"
    );
    stash
        .compact(orders, Antichain::from_elem(3).borrow())
        .await
        .unwrap();
    assert_eq!(
        stash.iter(orders).await.unwrap(),
        &[
            (("widgets".into(), "1".into()), 3, 3),
            (("widgets".into(), "1".into()), 4, 1),
        ]
    );

    // Check that physical compaction does not change the collection's contents.
    stash.consolidate(orders.id).await.unwrap();
    assert_eq!(
        stash.iter(orders).await.unwrap(),
        &[
            (("widgets".into(), "1".into()), 3, 3),
            (("widgets".into(), "1".into()), 4, 1),
        ]
    );

    // Test invalid seals, compactions, and updates.
    assert_eq!(
        stash
            .seal(orders, Antichain::from_elem(2).borrow())
            .await
            .unwrap_err()
            .to_string(),
        "stash error: seal request {2} is less than the current upper frontier {3}",
    );
    assert_eq!(
        stash
            .compact(orders, Antichain::from_elem(2).borrow())
            .await
            .unwrap_err()
            .to_string(),
        "stash error: compact request {2} is less than the current since frontier {3}",
    );
    assert_eq!(
        stash
            .compact(orders, Antichain::from_elem(4).borrow())
            .await
            .unwrap_err()
            .to_string(),
        "stash error: compact request {4} is greater than the current upper frontier {3}",
    );
    assert_eq!(
        stash
            .update(orders, ("wodgets".into(), "1".into()), 2, 1)
            .await
            .unwrap_err()
            .to_string(),
        "stash error: entry time 2 is less than the current upper frontier {3}",
    );

    // Test advancing since and upper to the empty frontier.
    stash.seal(orders, Antichain::new().borrow()).await.unwrap();
    stash
        .compact(orders, Antichain::new().borrow())
        .await
        .unwrap();
    assert_eq!(
        match stash.iter(orders).await {
            Ok(_) => panic!("call to iter unexpectedly succeeded"),
            Err(e) => e.to_string(),
        },
        "stash error: cannot iterate collection with empty since frontier",
    );
    assert_eq!(
        match stash.iter_key(orders, &"wombats".to_string()).await {
            Ok(_) => panic!("call to iter_key unexpectedly succeeded"),
            Err(e) => e.to_string(),
        },
        "stash error: cannot iterate collection with empty since frontier",
    );
    stash.consolidate(orders.id).await.unwrap();

    // Double check that the other collection is still untouched.
    assert_eq!(
        stash.iter(other).await.unwrap(),
        &[(("foo".into(), "bar".into()), 1, 1)],
    );
    assert_eq!(
        stash.since(other).await.unwrap(),
        Antichain::from_elem(Timestamp::MIN)
    );
    assert_eq!(
        stash.upper(other).await.unwrap(),
        Antichain::from_elem(Timestamp::MIN)
    );

    // Test peek_one.
    stash
        .seal(other, Antichain::from_elem(2).borrow())
        .await
        .unwrap();
    assert_eq!(
        stash.peek_one(other).await.unwrap(),
        BTreeMap::from([("foo".to_string(), "bar".to_string())])
    );
    assert_eq!(
        stash.peek_key_one(other, &"foo".to_string()).await.unwrap(),
        Some("bar".to_string())
    );

    stash
}

async fn test_stash_table(stash: &mut impl Append) {
    const TABLE: TypedCollection<Vec<u8>, String> = TypedCollection::new("table");
    fn uniqueness_violation(a: &String, b: &String) -> bool {
        a == b
    }
    let collection = TABLE.get(stash).await.unwrap();

    async fn commit(
        stash: &mut impl Append,
        collection: StashCollection<Vec<u8>, String>,
        pending: Vec<(Vec<u8>, String, i64)>,
    ) -> Result<(), StashError> {
        let mut batch = collection.make_batch(stash).await.unwrap();
        for (k, v, diff) in pending {
            collection.append_to_batch(&mut batch, &k, &v, diff);
        }
        stash.append(&[batch]).await.unwrap();
        Ok(())
    }

    TABLE
        .upsert_key(stash, &1i64.to_le_bytes().to_vec(), |_| {
            Ok::<_, Infallible>("v1".to_string())
        })
        .await
        .unwrap()
        .unwrap();
    TABLE
        .upsert(stash, vec![(2i64.to_le_bytes().to_vec(), "v2".to_string())])
        .await
        .unwrap();
    let mut table =
        TableTransaction::new(TABLE.peek_one(stash).await.unwrap(), uniqueness_violation);
    assert_eq!(
        table.items(),
        BTreeMap::from([
            (1i64.to_le_bytes().to_vec(), "v1".to_string()),
            (2i64.to_le_bytes().to_vec(), "v2".to_string())
        ])
    );
    assert_eq!(table.delete(|_k, _v| false).len(), 0);
    assert_eq!(table.delete(|_k, v| v == "v2").len(), 1);
    assert_eq!(
        table.items(),
        BTreeMap::from([(1i64.to_le_bytes().to_vec(), "v1".to_string())])
    );
    assert_eq!(table.update(|_k, _v| Some("v3".to_string())).unwrap(), 1);

    // Uniqueness violation.
    table
        .insert(3i64.to_le_bytes().to_vec(), "v3".to_string())
        .unwrap_err();

    table
        .insert(3i64.to_le_bytes().to_vec(), "v4".to_string())
        .unwrap();
    assert_eq!(
        table.items(),
        BTreeMap::from([
            (1i64.to_le_bytes().to_vec(), "v3".to_string()),
            (3i64.to_le_bytes().to_vec(), "v4".to_string()),
        ])
    );
    assert_eq!(
        table
            .update(|_k, _v| Some("v1".to_string()))
            .unwrap_err()
            .to_string(),
        "stash error: uniqueness violation"
    );
    let pending = table.pending();
    assert_eq!(
        pending,
        vec![
            (1i64.to_le_bytes().to_vec(), "v1".to_string(), -1),
            (1i64.to_le_bytes().to_vec(), "v3".to_string(), 1),
            (2i64.to_le_bytes().to_vec(), "v2".to_string(), -1),
            (3i64.to_le_bytes().to_vec(), "v4".to_string(), 1),
        ]
    );
    commit(stash, collection, pending).await.unwrap();
    let items = TABLE.peek_one(stash).await.unwrap();
    assert_eq!(
        items,
        BTreeMap::from([
            (1i64.to_le_bytes().to_vec(), "v3".to_string()),
            (3i64.to_le_bytes().to_vec(), "v4".to_string())
        ])
    );

    let mut table = TableTransaction::new(items, uniqueness_violation);
    // Deleting then creating an item that has a uniqueness violation should work.
    assert_eq!(table.delete(|k, _v| k == &1i64.to_le_bytes()).len(), 1);
    table
        .insert(1i64.to_le_bytes().to_vec(), "v3".to_string())
        .unwrap();
    // Uniqueness violation in value.
    table
        .insert(5i64.to_le_bytes().to_vec(), "v3".to_string())
        .unwrap_err();
    // Key already exists, expect error.
    table
        .insert(1i64.to_le_bytes().to_vec(), "v5".to_string())
        .unwrap_err();
    assert_eq!(table.delete(|k, _v| k == &1i64.to_le_bytes()).len(), 1);
    // Both the inserts work now because the key and uniqueness violation are gone.
    table
        .insert(5i64.to_le_bytes().to_vec(), "v3".to_string())
        .unwrap();
    table
        .insert(1i64.to_le_bytes().to_vec(), "v5".to_string())
        .unwrap();
    let pending = table.pending();
    assert_eq!(
        pending,
        vec![
            (1i64.to_le_bytes().to_vec(), "v3".to_string(), -1),
            (1i64.to_le_bytes().to_vec(), "v5".to_string(), 1),
            (5i64.to_le_bytes().to_vec(), "v3".to_string(), 1),
        ]
    );
    commit(stash, collection, pending).await.unwrap();
    let items = TABLE.peek_one(stash).await.unwrap();
    assert_eq!(
        items,
        BTreeMap::from([
            (1i64.to_le_bytes().to_vec(), "v5".to_string()),
            (3i64.to_le_bytes().to_vec(), "v4".to_string()),
            (5i64.to_le_bytes().to_vec(), "v3".to_string()),
        ])
    );

    let mut table = TableTransaction::new(items, uniqueness_violation);
    assert_eq!(table.delete(|_k, _v| true).len(), 3);
    table
        .insert(1i64.to_le_bytes().to_vec(), "v1".to_string())
        .unwrap();

    commit(stash, collection, table.pending()).await.unwrap();
    let items = TABLE.peek_one(stash).await.unwrap();
    assert_eq!(
        items,
        BTreeMap::from([(1i64.to_le_bytes().to_vec(), "v1".to_string()),])
    );

    let mut table = TableTransaction::new(items, uniqueness_violation);
    assert_eq!(table.delete(|_k, _v| true).len(), 1);
    table
        .insert(1i64.to_le_bytes().to_vec(), "v2".to_string())
        .unwrap();
    commit(stash, collection, table.pending()).await.unwrap();
    let items = TABLE.peek_one(stash).await.unwrap();
    assert_eq!(
        items,
        BTreeMap::from([(1i64.to_le_bytes().to_vec(), "v2".to_string()),])
    );

    // Verify we don't try to delete v3 or v4 during commit.
    let mut table = TableTransaction::new(items, uniqueness_violation);
    assert_eq!(table.delete(|_k, _v| true).len(), 1);
    table
        .insert(1i64.to_le_bytes().to_vec(), "v3".to_string())
        .unwrap();
    table
        .insert(1i64.to_le_bytes().to_vec(), "v4".to_string())
        .unwrap_err();
    assert_eq!(table.delete(|_k, _v| true).len(), 1);
    table
        .insert(1i64.to_le_bytes().to_vec(), "v5".to_string())
        .unwrap();
    commit(stash, collection, table.pending()).await.unwrap();
    let items = stash.peek(collection).await.unwrap();
    assert_eq!(
        items,
        vec![(1i64.to_le_bytes().to_vec(), "v5".to_string(), 1)]
    );

    // Test `set`.
    let items = TABLE.peek_one(stash).await.unwrap();
    let mut table = TableTransaction::new(items, uniqueness_violation);
    // Uniqueness violation.
    table
        .set(2i64.to_le_bytes().to_vec(), Some("v5".to_string()))
        .unwrap_err();
    table
        .set(3i64.to_le_bytes().to_vec(), Some("v6".to_string()))
        .unwrap();
    table.set(2i64.to_le_bytes().to_vec(), None).unwrap();
    table.set(1i64.to_le_bytes().to_vec(), None).unwrap();
    let pending = table.pending();
    assert_eq!(
        pending,
        vec![
            (1i64.to_le_bytes().to_vec(), "v5".to_string(), -1),
            (3i64.to_le_bytes().to_vec(), "v6".to_string(), 1),
        ]
    );
    commit(stash, collection, pending).await.unwrap();
    let items = TABLE.peek_one(stash).await.unwrap();
    assert_eq!(
        items,
        BTreeMap::from([(3i64.to_le_bytes().to_vec(), "v6".to_string())])
    );
}

#[test]
fn test_table() {
    fn uniqueness_violation(a: &String, b: &String) -> bool {
        a == b
    }
    let mut table = TableTransaction::new(
        BTreeMap::from([(1i64.to_le_bytes().to_vec(), "a".to_string())]),
        uniqueness_violation,
    );

    table
        .insert(2i64.to_le_bytes().to_vec(), "b".to_string())
        .unwrap();
    table
        .insert(3i64.to_le_bytes().to_vec(), "c".to_string())
        .unwrap();
}
