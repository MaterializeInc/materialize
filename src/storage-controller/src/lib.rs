// Copyright Materialize, Inc. and contributors. All rights reserved.
//
// Use of this software is governed by the Business Source License
// included in the LICENSE file.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0.

// BEGIN LINT CONFIG
// DO NOT EDIT. Automatically generated by bin/gen-lints.
// Have complaints about the noise? See the note in misc/python/materialize/cli/gen-lints.py first.
#![allow(unknown_lints)]
#![allow(clippy::style)]
#![allow(clippy::complexity)]
#![allow(clippy::large_enum_variant)]
#![allow(clippy::mutable_key_type)]
#![allow(clippy::stable_sort_primitive)]
#![allow(clippy::map_entry)]
#![allow(clippy::box_default)]
#![allow(clippy::drain_collect)]
#![warn(clippy::bool_comparison)]
#![warn(clippy::clone_on_ref_ptr)]
#![warn(clippy::no_effect)]
#![warn(clippy::unnecessary_unwrap)]
#![warn(clippy::dbg_macro)]
#![warn(clippy::todo)]
#![warn(clippy::wildcard_dependencies)]
#![warn(clippy::zero_prefixed_literal)]
#![warn(clippy::borrowed_box)]
#![warn(clippy::deref_addrof)]
#![warn(clippy::double_must_use)]
#![warn(clippy::double_parens)]
#![warn(clippy::extra_unused_lifetimes)]
#![warn(clippy::needless_borrow)]
#![warn(clippy::needless_question_mark)]
#![warn(clippy::needless_return)]
#![warn(clippy::redundant_pattern)]
#![warn(clippy::redundant_slicing)]
#![warn(clippy::redundant_static_lifetimes)]
#![warn(clippy::single_component_path_imports)]
#![warn(clippy::unnecessary_cast)]
#![warn(clippy::useless_asref)]
#![warn(clippy::useless_conversion)]
#![warn(clippy::builtin_type_shadow)]
#![warn(clippy::duplicate_underscore_argument)]
#![warn(clippy::double_neg)]
#![warn(clippy::unnecessary_mut_passed)]
#![warn(clippy::wildcard_in_or_patterns)]
#![warn(clippy::crosspointer_transmute)]
#![warn(clippy::excessive_precision)]
#![warn(clippy::overflow_check_conditional)]
#![warn(clippy::as_conversions)]
#![warn(clippy::match_overlapping_arm)]
#![warn(clippy::zero_divided_by_zero)]
#![warn(clippy::must_use_unit)]
#![warn(clippy::suspicious_assignment_formatting)]
#![warn(clippy::suspicious_else_formatting)]
#![warn(clippy::suspicious_unary_op_formatting)]
#![warn(clippy::mut_mutex_lock)]
#![warn(clippy::print_literal)]
#![warn(clippy::same_item_push)]
#![warn(clippy::useless_format)]
#![warn(clippy::write_literal)]
#![warn(clippy::redundant_closure)]
#![warn(clippy::redundant_closure_call)]
#![warn(clippy::unnecessary_lazy_evaluations)]
#![warn(clippy::partialeq_ne_impl)]
#![warn(clippy::redundant_field_names)]
#![warn(clippy::transmutes_expressible_as_ptr_casts)]
#![warn(clippy::unused_async)]
#![warn(clippy::disallowed_methods)]
#![warn(clippy::disallowed_macros)]
#![warn(clippy::disallowed_types)]
#![warn(clippy::from_over_into)]
// END LINT CONFIG

//! Implementation of the storage controller trait.

use std::any::Any;
use std::cmp::Reverse;
use std::collections::{BTreeMap, BTreeSet, BinaryHeap};
use std::fmt::Debug;
use std::num::NonZeroI64;
use std::str::FromStr;
use std::sync::Arc;
use std::time::Duration;

use async_trait::async_trait;
use bytes::BufMut;
use differential_dataflow::lattice::Lattice;
use futures::Stream;
use itertools::Itertools;
use mz_build_info::BuildInfo;
use mz_cluster_client::client::ClusterReplicaLocation;
use mz_cluster_client::ReplicaId;
use mz_ore::cast::CastFrom;
use mz_ore::collections::HashSet;
use mz_ore::metrics::MetricsRegistry;
use mz_ore::now::{to_datetime, EpochMillis, NowFn};
use mz_persist_client::cache::PersistClientCache;
use mz_persist_client::critical::SinceHandle;
use mz_persist_client::read::ReadHandle;
use mz_persist_client::stats::SnapshotStats;
use mz_persist_client::write::WriteHandle;
use mz_persist_client::{Diagnostics, PersistClient, PersistLocation, ShardId};
use mz_persist_txn::txn_read::TxnsCache;
use mz_persist_txn::txns::TxnsHandle;
use mz_persist_types::codec_impls::UnitSchema;
use mz_persist_types::{Codec64, Opaque};
use mz_proto::{IntoRustIfSome, ProtoType, RustType, TryFromProtoError};
use mz_repr::{ColumnName, Datum, Diff, GlobalId, RelationDesc, Row, TimestampManipulation};
use mz_stash::{self, AppendBatch, StashFactory, TypedCollection};
use mz_stash_types::metrics::Metrics as StashMetrics;
use mz_storage_client::client::{
    CreateSinkCommand, ProtoStorageCommand, ProtoStorageResponse, RunIngestionCommand,
    SinkStatisticsUpdate, SourceStatisticsUpdate, StorageCommand, StorageResponse,
    TimestamplessUpdate,
};
use mz_storage_client::controller::{
    CollectionDescription, CollectionState, DataSource, DataSourceOther, ExportDescription,
    ExportState, IntrospectionType, MonotonicAppender, ReadPolicy, SnapshotCursor,
    StorageController,
};
use mz_storage_client::healthcheck::{
    self, MZ_PREPARED_STATEMENT_HISTORY_DESC, MZ_SESSION_HISTORY_DESC,
    MZ_STATEMENT_EXECUTION_HISTORY_DESC,
};
use mz_storage_client::metrics::StorageControllerMetrics;
use mz_storage_types::collections as proto;
use mz_storage_types::controller::{
    CollectionMetadata, DurableCollectionMetadata, StorageError, TxnsCodecRow,
};
use mz_storage_types::instances::StorageInstanceId;
use mz_storage_types::parameters::StorageParameters;
use mz_storage_types::sinks::{ProtoDurableExportMetadata, SinkAsOf, StorageSinkDesc};
use mz_storage_types::sources::{IngestionDescription, SourceData, SourceExport};
use proptest::prelude::{any, Arbitrary, BoxedStrategy, Strategy};
use prost::Message;
use serde::{Deserialize, Serialize};
use timely::order::{PartialOrder, TotalOrder};
use timely::progress::{Antichain, ChangeBatch, Timestamp};
use tokio_stream::StreamMap;
use tracing::{debug, error, info, warn};

use crate::command_wals::ProtoShardId;
use crate::rehydration::RehydratingStorageClient;

mod collection_mgmt;
mod command_wals;
mod persist_handles;
mod rehydration;
mod statistics;

pub static METADATA_COLLECTION: TypedCollection<proto::GlobalId, proto::DurableCollectionMetadata> =
    TypedCollection::new("storage-collection-metadata");

pub static METADATA_EXPORT: TypedCollection<proto::GlobalId, proto::DurableExportMetadata> =
    TypedCollection::new("storage-export-metadata-u64");

pub static PERSIST_TXNS_SHARD: TypedCollection<(), String> =
    TypedCollection::new("persist-txns-shard");

pub static ALL_COLLECTIONS: &[&str] = &[
    METADATA_COLLECTION.name(),
    METADATA_EXPORT.name(),
    PERSIST_TXNS_SHARD.name(),
    command_wals::SHARD_FINALIZATION.name(),
];

// Do this dance so that we keep the storage controller expressed in terms of a generic timestamp `T`.
struct MetadataExportFetcher;
trait MetadataExport<T>
where
    // Associated type would be better but you can't express this relationship without unstable
    DurableExportMetadata<T>: RustType<proto::DurableExportMetadata>,
{
    fn get_stash_collection(
    ) -> &'static TypedCollection<proto::GlobalId, proto::DurableExportMetadata>;
}

impl MetadataExport<mz_repr::Timestamp> for MetadataExportFetcher {
    fn get_stash_collection(
    ) -> &'static TypedCollection<proto::GlobalId, proto::DurableExportMetadata> {
        &METADATA_EXPORT
    }
}

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct DurableExportMetadata<T> {
    pub initial_as_of: SinkAsOf<T>,
}

impl PartialOrd for DurableExportMetadata<mz_repr::Timestamp> {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl std::cmp::Ord for DurableExportMetadata<mz_repr::Timestamp> {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        let mut s = vec![];
        let mut o = vec![];
        self.encode(&mut s);
        other.encode(&mut o);
        s.cmp(&o)
    }
}

impl RustType<ProtoDurableExportMetadata> for DurableExportMetadata<mz_repr::Timestamp> {
    fn into_proto(&self) -> ProtoDurableExportMetadata {
        ProtoDurableExportMetadata {
            initial_as_of: Some(self.initial_as_of.into_proto()),
        }
    }

    fn from_proto(proto: ProtoDurableExportMetadata) -> Result<Self, TryFromProtoError> {
        Ok(DurableExportMetadata {
            initial_as_of: proto
                .initial_as_of
                .into_rust_if_some("ProtoDurableExportMetadata::initial_as_of")?,
        })
    }
}

impl RustType<mz_storage_types::collections::DurableExportMetadata>
    for DurableExportMetadata<mz_repr::Timestamp>
{
    fn into_proto(&self) -> mz_storage_types::collections::DurableExportMetadata {
        mz_storage_types::collections::DurableExportMetadata {
            initial_as_of: Some(self.initial_as_of.into_proto()),
        }
    }

    fn from_proto(
        proto: mz_storage_types::collections::DurableExportMetadata,
    ) -> Result<Self, TryFromProtoError> {
        Ok(DurableExportMetadata {
            initial_as_of: proto
                .initial_as_of
                .into_rust_if_some("DurableExportMetadata::initial_as_of")?,
        })
    }
}

impl DurableExportMetadata<mz_repr::Timestamp> {
    pub fn encode<B: BufMut>(&self, buf: &mut B) {
        let persisted: ProtoDurableExportMetadata = self.into_proto();
        persisted
            .encode(buf)
            .expect("no required fields means no initialization errors");
    }

    pub fn decode(buf: &[u8]) -> Result<Self, String> {
        let proto = ProtoDurableExportMetadata::decode(buf).map_err(|err| err.to_string())?;
        proto.into_rust().map_err(|err| err.to_string())
    }
}

impl Arbitrary for DurableExportMetadata<mz_repr::Timestamp> {
    type Strategy = BoxedStrategy<Self>;
    type Parameters = ();

    fn arbitrary_with(_: Self::Parameters) -> Self::Strategy {
        (any::<SinkAsOf<mz_repr::Timestamp>>(),)
            .prop_map(|(initial_as_of,)| Self { initial_as_of })
            .boxed()
    }
}

/// A storage controller for a storage instance.
#[derive(Debug)]
pub struct Controller<T: Timestamp + Lattice + Codec64 + From<EpochMillis> + TimestampManipulation>
{
    /// The build information for this process.
    build_info: &'static BuildInfo,
    /// A function that returns the current time.
    now: NowFn,
    /// The fencing token for this instance of the controller.
    envd_epoch: NonZeroI64,

    /// Collections maintained by the storage controller.
    ///
    /// This collection only grows, although individual collections may be rendered unusable.
    /// This is to prevent the re-binding of identifiers to other descriptions.
    pub(crate) collections: BTreeMap<GlobalId, CollectionState<T>>,
    pub(crate) exports: BTreeMap<GlobalId, ExportState<T>>,
    pub(crate) stash: mz_stash::Stash,
    /// Write handle for table shards.
    pub(crate) persist_table_worker: persist_handles::PersistTableWriteWorker<T>,
    /// Write handle for monotonic shards.
    pub(crate) persist_monotonic_worker: persist_handles::PersistMonotonicWriteWorker<T>,
    /// Read handles for all shards.
    ///
    /// These handles are on the other end of a Tokio task, so that work can be done asynchronously
    /// without blocking the storage controller.
    persist_read_handles: persist_handles::PersistReadWorker<T>,
    /// The shard id of the persist-txn txns shard or None if persist-txn is not
    /// enabled.
    txns_id: Option<ShardId>,
    /// A PersistClient usable for opening txns_id.
    txns_client: PersistClient,
    stashed_response: Option<StorageResponse<T>>,
    /// Compaction commands to send during the next call to
    /// `StorageController::process`.
    pending_compaction_commands: Vec<(GlobalId, Antichain<T>, Option<StorageInstanceId>)>,

    /// Interface for managed collections
    pub(crate) collection_manager: collection_mgmt::CollectionManager<T>,
    /// Tracks which collection is responsible for which [`IntrospectionType`].
    pub(crate) introspection_ids: BTreeMap<IntrospectionType, GlobalId>,
    /// Tokens for tasks that drive updating introspection collections. Dropping
    /// this will make sure that any tasks (or other resources) will stop when
    /// needed.
    // TODO(aljoscha): Should these live somewhere else?
    introspection_tokens: BTreeMap<GlobalId, Box<dyn Any + Send + Sync>>,

    /// Consolidated metrics updates to periodically write. We do not eagerly initialize this,
    /// and its contents are entirely driven by `StorageResponse::StatisticsUpdates`'s.
    source_statistics: Arc<
        std::sync::Mutex<BTreeMap<GlobalId, statistics::StatsInitState<SourceStatisticsUpdate>>>,
    >,
    /// Consolidated metrics updates to periodically write. We do not eagerly initialize this,
    /// and its contents are entirely driven by `StorageResponse::StatisticsUpdates`'s.
    sink_statistics:
        Arc<std::sync::Mutex<BTreeMap<GlobalId, statistics::StatsInitState<SinkStatisticsUpdate>>>>,

    /// Clients for all known storage instances.
    clients: BTreeMap<StorageInstanceId, RehydratingStorageClient<T>>,
    /// For each storage instance the ID of its replica, if any.
    replicas: BTreeMap<StorageInstanceId, ReplicaId>,
    /// Set to `true` once `initialization_complete` has been called.
    initialized: bool,
    /// Storage configuration to apply to newly provisioned instances.
    config: StorageParameters,
    /// Mechanism for returning frontier advancement for tables.
    internal_response_queue: tokio::sync::mpsc::UnboundedReceiver<StorageResponse<T>>,
    /// The persist location where all storage collections are being written to
    persist_location: PersistLocation,
    /// A persist client used to write to storage collections
    persist: Arc<PersistClientCache>,
    /// Metrics of the Storage controller
    metrics: StorageControllerMetrics,
    /// Mechanism for the storage controller to send itself feedback, potentially emulating the
    /// responses we expect from clusters.
    ///
    /// Note: This is used for finalizing shards of webhook sources, once webhook sources are
    /// installed on a `clusterd` this can likely be refactored away.
    internal_response_sender: tokio::sync::mpsc::UnboundedSender<StorageResponse<T>>,

    /// `(read, write)` frontiers that have been recorded in the `Frontiers` collection, kept to be
    /// able to retract old rows.
    recorded_frontiers: BTreeMap<GlobalId, (Antichain<T>, Antichain<T>)>,
    /// Write frontiers that have been recorded in the `ReplicaFrontiers` collection, kept to be
    /// able to retract old rows.
    recorded_replica_frontiers: BTreeMap<(GlobalId, ReplicaId), Antichain<T>>,
}

#[async_trait(?Send)]
impl<T> StorageController for Controller<T>
where
    T: Timestamp
        + Lattice
        + TotalOrder
        + Codec64
        + From<EpochMillis>
        + TimestampManipulation
        + Into<mz_repr::Timestamp>,
    StorageCommand<T>: RustType<ProtoStorageCommand>,
    StorageResponse<T>: RustType<ProtoStorageResponse>,
    MetadataExportFetcher: MetadataExport<T>,
    DurableExportMetadata<T>: RustType<proto::DurableExportMetadata>,
{
    type Timestamp = T;

    fn initialization_complete(&mut self) {
        self.initialized = true;
        for client in self.clients.values_mut() {
            client.send(StorageCommand::InitializationComplete);
        }
    }

    fn update_configuration(&mut self, config_params: StorageParameters) {
        config_params.persist.apply(self.persist.cfg());

        for client in self.clients.values_mut() {
            client.send(StorageCommand::UpdateConfiguration(config_params.clone()));
        }
        self.config.update(config_params);
    }

    fn collection(&self, id: GlobalId) -> Result<&CollectionState<Self::Timestamp>, StorageError> {
        self.collections
            .get(&id)
            .ok_or(StorageError::IdentifierMissing(id))
    }

    fn collection_mut(
        &mut self,
        id: GlobalId,
    ) -> Result<&mut CollectionState<Self::Timestamp>, StorageError> {
        self.collections
            .get_mut(&id)
            .ok_or(StorageError::IdentifierMissing(id))
    }

    fn collections(
        &self,
    ) -> Box<dyn Iterator<Item = (&GlobalId, &CollectionState<Self::Timestamp>)> + '_> {
        Box::new(self.collections.iter())
    }

    fn create_instance(&mut self, id: StorageInstanceId) {
        let mut client = RehydratingStorageClient::new(
            self.build_info,
            self.metrics.for_instance(id),
            self.envd_epoch,
            self.config.grpc_client.clone(),
        );
        if self.initialized {
            client.send(StorageCommand::InitializationComplete);
        }
        client.send(StorageCommand::UpdateConfiguration(self.config.clone()));
        let old_client = self.clients.insert(id, client);
        assert!(old_client.is_none(), "storage instance {id} already exists");
    }

    fn drop_instance(&mut self, id: StorageInstanceId) {
        let client = self.clients.remove(&id);
        assert!(client.is_some(), "storage instance {id} does not exist");
    }

    fn connect_replica(
        &mut self,
        instance_id: StorageInstanceId,
        replica_id: ReplicaId,
        location: ClusterReplicaLocation,
    ) {
        let client = self
            .clients
            .get_mut(&instance_id)
            .unwrap_or_else(|| panic!("instance {instance_id} does not exist"));
        client.connect(location);

        self.replicas.insert(instance_id, replica_id);
    }

    fn drop_replica(&mut self, instance_id: StorageInstanceId, _replica_id: ReplicaId) {
        let client = self
            .clients
            .get_mut(&instance_id)
            .unwrap_or_else(|| panic!("instance {instance_id} does not exist"));
        client.reset();

        self.replicas.remove(&instance_id);
    }

    // Add new migrations below and precede them with a short summary of the
    // migration's purpose and optional additional commentary about safety or
    // approach.
    //
    // Note that:
    // - The sum of all migrations must be idempotent because all migrations run
    //   every time the catalog opens, unless migrations are explicitly
    //   disabled. This might mean changing code outside the migration itself,
    //   or only executing some migrations when encountering certain versions.
    // - Migrations must preserve backwards compatibility with all past releases
    //   of Materialize.
    #[tracing::instrument(level = "debug", skip_all)]
    async fn migrate_collections(
        &mut self,
        _collections: Vec<(GlobalId, CollectionDescription<Self::Timestamp>)>,
    ) -> Result<(), StorageError> {
        // Collection migrations look something like this:
        // let mut durable_metadata = METADATA_COLLECTION.peek_one(&mut self.stash).await?;
        // do_migration(&mut durable_metadata)?;
        // self.upsert_collection_metadata(&mut durable_metadata, remap_shard_migration_delta)
        //     .await;
        Ok(())
    }

    // TODO(aljoscha): It would be swell if we could refactor this Leviathan of
    // a method/move individual parts to their own methods.
    #[tracing::instrument(level = "debug", skip_all)]
    async fn create_collections(
        &mut self,
        register_ts: Option<Self::Timestamp>,
        mut collections: Vec<(GlobalId, CollectionDescription<Self::Timestamp>)>,
    ) -> Result<(), StorageError> {
        // Validate first, to avoid corrupting state.
        // 1. create a dropped identifier, or
        // 2. create an existing identifier with a new description.
        // Make sure to check for errors within `ingestions` as well.
        collections.sort_by_key(|(id, _)| *id);
        collections.dedup();
        for pos in 1..collections.len() {
            if collections[pos - 1].0 == collections[pos].0 {
                return Err(StorageError::SourceIdReused(collections[pos].0));
            }
        }
        for (id, description) in collections.iter() {
            if let Ok(collection) = self.collection(*id) {
                if &collection.description != description {
                    return Err(StorageError::SourceIdReused(*id));
                }
            }
        }

        // Install collection state for each bound description. Note that this
        // method implementation attempts to do AS MUCH work concurrently as
        // possible. There are inline comments explaining the motivation behind
        // each section.
        let mut entries = Vec::with_capacity(collections.len());

        for (id, _desc) in &collections {
            entries.push((
                *id,
                DurableCollectionMetadata {
                    data_shard: ShardId::new(),
                },
            ))
        }

        // Perform all stash writes in a single transaction, to minimize transaction overhead and
        // the time spent waiting for stash.
        METADATA_COLLECTION
            .insert_without_overwrite(
                &mut self.stash,
                entries
                    .into_iter()
                    .map(|(key, val)| (key.into_proto(), val.into_proto())),
            )
            .await?;

        let durable_metadata: BTreeMap<GlobalId, DurableCollectionMetadata> = METADATA_COLLECTION
            .peek_one(&mut self.stash)
            .await?
            .into_iter()
            .map(RustType::from_proto)
            .collect::<Result<_, _>>()
            .map_err(|e| StorageError::IOError(e.into()))?;

        // We first enrich each collection description with some additional metadata...
        use futures::stream::{StreamExt, TryStreamExt};
        let enriched_with_metadata = collections
            .into_iter()
            .map(|(id, description)| {
                let collection_shards = durable_metadata.get(&id).expect("inserted above");

                let status_shard =
                    if let Some(status_collection_id) = description.status_collection_id {
                        Some(
                            durable_metadata
                                .get(&status_collection_id)
                                .ok_or(StorageError::IdentifierMissing(status_collection_id))?
                                .data_shard,
                        )
                    } else {
                        None
                    };

                let remap_shard = match &description.data_source {
                    // Only ingestions can have remap shards.
                    DataSource::Ingestion(IngestionDescription {
                        remap_collection_id,
                        ..
                    }) => {
                        // Iff ingestion has a remap collection, its metadata must
                        // exist (and be correct) by this point.
                        Some(
                            durable_metadata
                                .get(remap_collection_id)
                                .ok_or(StorageError::IdentifierMissing(*remap_collection_id))?
                                .data_shard,
                        )
                    }
                    _ => None,
                };

                // If the shard is being managed by persist-txn (initially, tables), then we need to
                // pass along the shard id for the txns shard to dataflow rendering.
                let txns_shard = match description.data_source {
                    DataSource::Other(DataSourceOther::TableWrites) => {
                        // `self.txns_id` is None if persist-txn is not enabled, which makes this
                        // do the right thing.
                        self.txns_id.clone()
                    }
                    DataSource::Ingestion(_)
                    | DataSource::Introspection(_)
                    | DataSource::Progress
                    | DataSource::Webhook
                    | DataSource::Other(DataSourceOther::Compute)
                    | DataSource::Other(DataSourceOther::Source) => None,
                };

                let metadata = CollectionMetadata {
                    persist_location: self.persist_location.clone(),
                    remap_shard,
                    data_shard: collection_shards.data_shard,
                    status_shard,
                    relation_desc: description.desc.clone(),
                    txns_shard,
                };

                Ok((id, description, metadata))
            })
            .collect_vec();

        // So that we can open `SinceHandle`s for each collections concurrently.
        let persist_client = self
            .persist
            .open(self.persist_location.clone())
            .await
            .unwrap();
        let persist_client = &persist_client;
        // Reborrow the `&mut self` as immutable, as all the concurrent work to be processed in
        // this stream cannot all have exclusive access.
        let this = &*self;
        let to_register: Vec<_> = futures::stream::iter(enriched_with_metadata)
            .map(|data: Result<_, StorageError>| {
                let register_ts = register_ts.clone();
                async move {
                let (id, description, metadata) = data?;

                // should be replaced with real introspection (https://github.com/MaterializeInc/materialize/issues/14266)
                // but for now, it's helpful to have this mapping written down somewhere
                debug!(
                    "mapping GlobalId={} to remap shard ({:?}), data shard ({}), status shard ({:?})",
                    id, metadata.remap_shard, metadata.data_shard, metadata.status_shard
                );

                let (write, mut since_handle) = this
                    .open_data_handles(
                        &id,
                        metadata.data_shard,
                        description.since.as_ref(),
                        metadata.relation_desc.clone(),
                        persist_client,
                    )
                    .await;

                // Present tables as springing into existence at the register_ts by advancing
                // the since. Otherwise, we could end up in a situation where a table with a
                // long compaction window appears to exist before the environment (and this the
                // table) existed.
                //
                // We could potentially also do the same thing for other sources, in particular
                // storage's internal sources and perhaps others, but leave them for now.
                match description.data_source {
                    DataSource::Introspection(_)
                    | DataSource::Webhook
                    | DataSource::Ingestion(_)
                    | DataSource::Progress
                    | DataSource::Other(DataSourceOther::Compute)
                    | DataSource::Other(DataSourceOther::Source) => {},
                    DataSource::Other(DataSourceOther::TableWrites) => {
                        let register_ts = register_ts.expect("caller should have provided a register_ts when creating a table");
                        if since_handle.since().elements() == &[T::minimum()] {
                            debug!("advancing {} to initial since of {:?}", id, register_ts);
                            let token = since_handle.opaque().clone();
                            let _ = since_handle.compare_and_downgrade_since(&token, (&token, &Antichain::from_elem(register_ts.clone()))).await;
                        }
                    }
                }

                Ok::<_, StorageError>((id, description, write, since_handle, metadata))
            }})
            // Poll each future for each collection concurrently, maximum of 50 at a time.
            .buffer_unordered(50)
            // HERE BE DRAGONS:
            //
            // There are at least 2 subtleties in using `FuturesUnordered` (which
            // `buffer_unordered` uses underneath:
            // - One is captured here <https://github.com/rust-lang/futures-rs/issues/2387>
            // - And the other is deadlocking if processing an OUTPUT of a `FuturesUnordered`
            // stream attempts to obtain an async mutex that is also obtained in the futures
            // being polled.
            //
            // Both of these could potentially be issues in all usages of `buffer_unordered` in
            // this method, so we stick the standard advice: only use `try_collect` or
            // `collect`!
            .try_collect()
            .await?;

        let mut to_create = Vec::with_capacity(to_register.len());
        let mut table_registers = Vec::with_capacity(to_register.len());
        // This work mutates the controller state, so must be done serially. Because there
        // is no io-bound work, its very fast.
        {
            // We hold this lock for a very short amount of time, just doing some hashmap inserts
            // and unbounded channel sends.
            let mut source_statistics = self.source_statistics.lock().expect("poisoned");
            for (id, description, write, since_handle, metadata) in to_register {
                let data_shard_since = since_handle.since().clone();

                let collection_state = CollectionState::new(
                    description.clone(),
                    data_shard_since,
                    write.upper().clone(),
                    vec![],
                    metadata.clone(),
                );

                match description.data_source {
                    DataSource::Introspection(_) | DataSource::Webhook => {
                        debug!(desc = ?description, meta = ?metadata, "registering {} with persist monotonic worker", id);
                        self.persist_monotonic_worker.register(id, write);
                        self.collections.insert(id, collection_state);
                    }
                    DataSource::Other(DataSourceOther::TableWrites) => {
                        debug!(desc = ?description, meta = ?metadata, "registering {} with persist table worker", id);
                        table_registers.push((id, write, collection_state));
                    }
                    DataSource::Ingestion(_)
                    | DataSource::Progress
                    | DataSource::Other(DataSourceOther::Compute)
                    | DataSource::Other(DataSourceOther::Source) => {
                        debug!(desc = ?description, meta = ?metadata, "not registering {} with a controller persist worker", id);
                        self.collections.insert(id, collection_state);
                    }
                }
                self.persist_read_handles.register(id, since_handle);

                if let DataSource::Ingestion(i) = &description.data_source {
                    source_statistics.insert(id, statistics::StatsInitState(BTreeMap::new()));
                    // Note that `source_exports` contains the subsources as well.
                    for (id, _) in i.source_exports.iter() {
                        source_statistics.insert(*id, statistics::StatsInitState(BTreeMap::new()));
                    }
                }

                to_create.push((id, description));
            }
        }

        // Register the tables all in one batch.
        if !table_registers.is_empty() {
            let register_ts = register_ts
                .expect("caller should have provided a register_ts when creating a table");
            let mut collection_states = Vec::with_capacity(table_registers.len());
            let table_registers = table_registers
                .into_iter()
                .map(|(id, write, collection_state)| {
                    collection_states.push((id, collection_state));
                    (id, write)
                })
                .collect();
            self.persist_table_worker
                .register(register_ts, table_registers);
            for (id, collection_state) in collection_states {
                self.collections.insert(id, collection_state);
            }
        }

        // Patch up the since of all subsources (which includes the "main"
        // collection) and install read holds from the subsources on the since
        // of the remap collection. We need to do this here because a) the since
        // of the remap collection might be in advance of the since of the data
        // collections because we lazily forward commands to downgrade the since
        // to persist, and b) at the time the subsources are created we know
        // close to nothing about them, not even that they are subsources.
        //
        // N.B. Patching up the since based on the since of the remap collection
        // is correct because the since of the remap collection can advance iff
        // the storage controller allowed it to, which it only does when it
        // would also allow the since of the data collections to advance. It's
        // just that we need to reconcile outselves to the outside world
        // (persist) here.
        //
        // TODO(aljoscha): We should find a way to put this information and the
        // read holds in place when we create the subsource collections. OR, we
        // could create the subsource collections only as part of creating the
        // main source/ingestion.
        for (_id, description) in to_create.iter() {
            match &description.data_source {
                DataSource::Ingestion(ingestion) => {
                    let storage_dependencies = description.get_storage_dependencies();

                    self.install_dependency_read_holds(
                        // N.B. The "main" collection of the source is included in
                        // `source_exports`.
                        ingestion.source_exports.keys().cloned(),
                        &storage_dependencies,
                    )?;
                }
                DataSource::Webhook
                | DataSource::Introspection(_)
                | DataSource::Progress
                | DataSource::Other(_) => {
                    // No since to patch up and no read holds to install on
                    // dependencies!
                }
            }
        }

        // Reborrow `&mut self` immutably, same reasoning as above.
        let this = &*self;

        this.append_shard_mappings(to_create.iter().map(|(id, _)| *id), 1)
            .await;

        let mut statement_logging_sources_seen = 0;
        // TODO(guswynn): perform the io in this final section concurrently.
        for (id, description) in to_create {
            match description.data_source {
                DataSource::Ingestion(ingestion) => {
                    let description = self.enrich_ingestion(id, ingestion)?;

                    // Fetch the client for this ingestion's instance.
                    let client =
                        self.clients
                            .get_mut(&description.instance_id)
                            .ok_or_else(|| StorageError::IngestionInstanceMissing {
                                storage_instance_id: description.instance_id,
                                ingestion_id: id,
                            })?;
                    let augmented_ingestion = RunIngestionCommand {
                        id,
                        description,
                        update: false,
                    };

                    client.send(StorageCommand::RunIngestions(vec![augmented_ingestion]));
                }
                DataSource::Introspection(i) => {
                    let prev = self.introspection_ids.insert(i, id);
                    assert!(
                        prev.is_none(),
                        "cannot have multiple IDs for introspection type"
                    );

                    self.collection_manager.register_collection(id);

                    match i {
                        IntrospectionType::ShardMapping => {
                            self.initialize_shard_mapping().await;
                        }
                        IntrospectionType::Frontiers | IntrospectionType::ReplicaFrontiers => {
                            // Set the collection to empty.
                            self.reconcile_managed_collection(id, vec![]).await;
                        }
                        IntrospectionType::StorageSourceStatistics => {
                            // Set the collection to empty.
                            self.reconcile_managed_collection(id, vec![]).await;

                            let scraper_token = statistics::spawn_statistics_scraper(
                                id.clone(),
                                // These do a shallow copy.
                                self.collection_manager.clone(),
                                Arc::clone(&self.source_statistics),
                            );

                            // Make sure this is dropped when the controller is
                            // dropped, so that the internal task will stop.
                            self.introspection_tokens.insert(id, scraper_token);
                        }
                        IntrospectionType::StorageSinkStatistics => {
                            // Set the collection to empty.
                            self.reconcile_managed_collection(id, vec![]).await;

                            let scraper_token = statistics::spawn_statistics_scraper(
                                id.clone(),
                                // These do a shallow copy.
                                self.collection_manager.clone(),
                                Arc::clone(&self.sink_statistics),
                            );

                            // Make sure this is dropped when the controller is
                            // dropped, so that the internal task will stop.
                            self.introspection_tokens.insert(id, scraper_token);
                        }
                        IntrospectionType::SourceStatusHistory => {
                            self.partially_truncate_status_history(
                                IntrospectionType::SourceStatusHistory,
                            )
                            .await;
                        }
                        IntrospectionType::SinkStatusHistory => {
                            self.partially_truncate_status_history(
                                IntrospectionType::SinkStatusHistory,
                            )
                            .await;
                        }

                        IntrospectionType::StatementExecutionHistory
                        | IntrospectionType::SessionHistory
                        | IntrospectionType::PreparedStatementHistory => {
                            statement_logging_sources_seen += 1;
                            if statement_logging_sources_seen == 3 {
                                self.partially_truncate_statement_log().await;
                            }
                        }

                        // Truncate compute-maintained collections.
                        IntrospectionType::ComputeDependencies
                        | IntrospectionType::ComputeReplicaHeartbeats => {
                            self.reconcile_managed_collection(id, vec![]).await;
                        }
                    }
                }
                DataSource::Webhook => {
                    // Register the collection so our manager knows about it.
                    self.collection_manager.register_collection(id);
                }
                DataSource::Progress | DataSource::Other(_) => {}
            }
        }

        Ok(())
    }

    fn check_alter_collection(
        &mut self,
        collections: &BTreeMap<GlobalId, IngestionDescription>,
    ) -> Result<(), StorageError> {
        for (id, ingestion) in collections {
            self.check_alter_collection_inner(*id, ingestion.clone())?;
        }
        Ok(())
    }

    async fn alter_collection(
        &mut self,
        collections: BTreeMap<GlobalId, IngestionDescription>,
    ) -> Result<(), StorageError> {
        self.check_alter_collection(&collections)
            .expect("error avoided by calling check_alter_collection first");

        for (id, ingestion) in collections {
            // Describe the ingestion in terms of collection metadata.
            let description = self
                .enrich_ingestion(id, ingestion.clone())
                .expect("verified valid in check_alter_collection_inner");

            let collection = self.collection_mut(id).expect("validated exists");
            let new_source_exports = match &mut collection.description.data_source {
                DataSource::Ingestion(active_ingestion) => {
                    // Determine which IDs we're adding.
                    let new_source_exports: Vec<_> = description
                        .source_exports
                        .keys()
                        .filter(|id| !active_ingestion.source_exports.contains_key(id))
                        .cloned()
                        .collect();
                    *active_ingestion = ingestion;

                    new_source_exports
                }
                _ => unreachable!("verified collection refers to ingestion"),
            };

            // Assess dependency since, which we have to fast-forward this
            // collection's since to.
            let storage_dependencies = collection.description.get_storage_dependencies();

            // Ensure this new collection's since is aligned with the dependencies.
            // This will likely place its since beyond its upper which is OK because
            // its snapshot will catch it up with the rest of the source, i.e. we
            // will never see its upper at a state beyond 0 and less than its since.
            self.install_dependency_read_holds(
                new_source_exports.into_iter(),
                &storage_dependencies,
            )?;

            // Fetch the client for this ingestion's instance.
            let client = self
                .clients
                .get_mut(&description.instance_id)
                .expect("verified exists");

            client.send(StorageCommand::RunIngestions(vec![RunIngestionCommand {
                id,
                description,
                update: true,
            }]));
        }

        Ok(())
    }

    fn export(&self, id: GlobalId) -> Result<&ExportState<Self::Timestamp>, StorageError> {
        self.exports
            .get(&id)
            .ok_or(StorageError::IdentifierMissing(id))
    }

    fn export_mut(
        &mut self,
        id: GlobalId,
    ) -> Result<&mut ExportState<Self::Timestamp>, StorageError> {
        self.exports
            .get_mut(&id)
            .ok_or(StorageError::IdentifierMissing(id))
    }

    async fn create_exports(
        &mut self,
        exports: Vec<(GlobalId, ExportDescription<Self::Timestamp>)>,
    ) -> Result<(), StorageError> {
        // Validate first, to avoid corrupting state.
        let mut dedup = BTreeMap::new();
        for (id, desc) in exports.iter() {
            if dedup.insert(id, desc).is_some() {
                return Err(StorageError::SinkIdReused(*id));
            }
            if let Ok(export) = self.export(*id) {
                if &export.description != desc {
                    return Err(StorageError::SinkIdReused(*id));
                }
            }
        }

        for (id, description) in exports {
            let from_id = description.sink.from;

            let dependency_since = self.determine_collection_since_joins(&[from_id])?;
            self.install_read_capabilities(id, &[from_id], dependency_since.clone())?;

            info!(
                sink_id = id.to_string(),
                from_id = from_id.to_string(),
                acquired_since = ?dependency_since,
                "prepare_export: sink acquired read holds"
            );

            // It's worth adding a quick note on write frontiers here.
            //
            // The write frontier that sinks communicate back to the controller
            // indicates that all further writes will happen at a time `t` such
            // that `!timely::ParitalOrder::less_than(&t, &write_frontier)` is
            // true.  On restart, the sink will receive an SinkAsOf from this
            // controller indicating that it should ignore everything at or
            // before the `since` of the from collection. This will not miss any
            // records because, if there were records not yet written out that
            // have an uncompacted time of `since`, the write frontier
            // previously reported from the sink must be less than `since` so we
            // would not have compacted up to `since`! This is tested by the
            // kafka persistence tests.
            //
            // TODO: Remove upper frontier manipulation from sinks, the read
            // policy ensures that we can always resume and discern the updates
            // that happened at upper. The comment above is slightly wrong:
            // sinks report `F-1` as the upper when they are at upper `F`
            // (speaking in terms of a timely frontier). We should change sinks
            // to divorce what they write out to the progress topic and what
            // they report back as the write upper. To make sure that the
            // reported write upper conforms with what other parts of the system
            // think how uppers work.
            //
            // Note: This is where the sink code (kafka) calculates the write
            // frontier that it reports back:
            // https://github.com/MaterializeInc/materialize/blob/ec8560a532eb5e7282041757d6c1d650f0ffaa77/src/storage/src/sink/kafka.rs#L857
            let read_policy = ReadPolicy::step_back();

            let from_collection = self.collection(from_id)?;
            let from_storage_metadata = from_collection.collection_metadata.clone();

            let storage_dependencies = vec![from_id];

            let value = MetadataExportFetcher::get_stash_collection()
                .insert_key_without_overwrite(
                    &mut self.stash,
                    id.into_proto(),
                    DurableExportMetadata {
                        initial_as_of: description.sink.as_of.clone(),
                    }
                    .into_proto(),
                )
                .await?;
            let mut durable_export_data = DurableExportMetadata::from_proto(value)
                .map_err(|e| StorageError::IOError(e.into()))?;

            durable_export_data
                .initial_as_of
                .downgrade(&dependency_since);

            info!(
                sink_id = id.to_string(),
                from_id = from_id.to_string(),
                initial_as_of = ?durable_export_data.initial_as_of,
                "create_exports: creating sink"
            );

            self.exports.insert(
                id,
                ExportState::new(
                    description.clone(),
                    dependency_since,
                    read_policy,
                    storage_dependencies,
                ),
            );

            let status_id = if let Some(status_collection_id) = description.sink.status_id {
                Some(
                    self.collection(status_collection_id)?
                        .collection_metadata
                        .data_shard,
                )
            } else {
                None
            };

            let cmd = CreateSinkCommand {
                id,
                description: StorageSinkDesc {
                    from: from_id,
                    from_desc: description.sink.from_desc,
                    connection: description.sink.connection,
                    envelope: description.sink.envelope,
                    as_of: durable_export_data.initial_as_of,
                    status_id,
                    from_storage_metadata,
                },
            };

            // Fetch the client for this exports's cluster.
            let client = self
                .clients
                .get_mut(&description.instance_id)
                .ok_or_else(|| StorageError::ExportInstanceMissing {
                    storage_instance_id: description.instance_id,
                    export_id: id,
                })?;

            self.sink_statistics
                .lock()
                .expect("poisoned")
                .insert(id, statistics::StatsInitState(BTreeMap::new()));

            client.send(StorageCommand::CreateSinks(vec![cmd]));
        }
        Ok(())
    }

    fn drop_sources(&mut self, identifiers: Vec<GlobalId>) -> Result<(), StorageError> {
        self.validate_collection_ids(identifiers.iter().cloned())?;
        self.drop_sources_unvalidated(identifiers);
        Ok(())
    }

    fn drop_sources_unvalidated(&mut self, identifiers: Vec<GlobalId>) {
        // We don't explicitly remove read capabilities! Downgrading the
        // frontier of the source to `[]` (the empty Antichain), will propagate
        // to the storage dependencies.
        let policies = identifiers
            .into_iter()
            .filter(|id| self.collection(*id).is_ok())
            .map(|id| (id, ReadPolicy::ValidFrom(Antichain::new())))
            .collect();
        self.set_read_policy(policies);
    }

    /// Drops the read capability for the sinks and allows their resources to be reclaimed.
    fn drop_sinks(&mut self, identifiers: Vec<GlobalId>) -> Result<(), StorageError> {
        self.validate_export_ids(identifiers.iter().cloned())?;
        self.drop_sinks_unvalidated(identifiers);
        Ok(())
    }

    fn drop_sinks_unvalidated(&mut self, identifiers: Vec<GlobalId>) {
        for id in identifiers {
            // Already removed.
            if self.export(id).is_err() {
                continue;
            }

            // We don't explicitly remove read capabilities! Downgrading the
            // frontier of the sink to `[]` (the empty Antichain), will
            // propagate to the storage dependencies.

            // Remove sink by removing its write frontier and arranging for deprovisioning.
            self.update_write_frontiers(&[(id, Antichain::new())]);
        }
    }

    #[tracing::instrument(level = "debug", skip_all)]
    fn append_table(
        &mut self,
        write_ts: Self::Timestamp,
        advance_to: Self::Timestamp,
        commands: Vec<(GlobalId, Vec<TimestamplessUpdate>)>,
    ) -> Result<tokio::sync::oneshot::Receiver<Result<(), StorageError>>, StorageError> {
        // TODO(petrosagg): validate appends against the expected RelationDesc of the collection
        for (id, updates) in commands.iter() {
            if !updates.is_empty() {
                if !write_ts.less_than(&advance_to) {
                    return Err(StorageError::UpdateBeyondUpper(*id));
                }
            }
        }

        Ok(self
            .persist_table_worker
            .append(write_ts, advance_to, commands))
    }

    fn monotonic_appender(&self, id: GlobalId) -> Result<MonotonicAppender, StorageError> {
        self.collection_manager.monotonic_appender(id)
    }

    // TODO(petrosagg): This signature is not very useful in the context of partially ordered times
    // where the as_of frontier might have multiple elements. In the current form the mutually
    // incomparable updates will be accumulated together to a state of the collection that never
    // actually existed. We should include the original time in the updates advanced by the as_of
    // frontier in the result and let the caller decide what to do with the information.
    async fn snapshot(
        &mut self,
        id: GlobalId,
        as_of: Self::Timestamp,
    ) -> Result<Vec<(Row, Diff)>, StorageError> {
        let data_shard = self.collection(id)?.collection_metadata.data_shard;
        let contents = match self.txns_id.as_mut() {
            None => {
                // We're not using persist-txn for tables, so we can take a snapshot directly.
                let mut read_handle = self.read_handle_for_snapshot(id).await?;
                read_handle
                    .snapshot_and_fetch(Antichain::from_elem(as_of))
                    .await
            }
            Some(txns_id) => {
                // We _are_ using persist-txn for tables. It advances the physical upper of the
                // shard lazily, so we need to ask it for the snapshot to ensure the read is
                // unblocked.
                //
                // Consider the following scenario:
                // - Table A is written to via txns at time 5
                // - Tables other than A are written to via txns consuming timestamps up to 10
                // - We'd like to read A at 7
                // - The application process of A's txn has advanced the upper to 5+1, but we need
                //   it to be past 7, but the txns shard knows that (5,10) is empty of writes to A
                // - This branch allows it to handle that advancing the physical upper of Table A to
                //   10 (NB but only once we see it get past the write at 5!)
                // - Then we can read it normally.
                //
                // TODO(txn): We do a series of snapshots at boot and then never again. It's
                // wasteful to create this TxnsCache and then throw it away for each of them, but
                // it's better than the alternative of keeping it alive for snapshot calls that will
                // never come (worse, it's tricky to keep it making progress, which results in a
                // stuck since). Replace this with the shared TxnsCache thing we'll have to do
                // anyway for the dataflow operators.
                let mut txns_cache = TxnsCache::<Self::Timestamp, TxnsCodecRow>::open(
                    &self.txns_client,
                    *txns_id,
                    Some(data_shard),
                )
                .await;
                txns_cache.update_gt(&as_of).await;
                let data_snapshot = txns_cache.data_snapshot(data_shard, as_of.clone());
                let mut read_handle = self.read_handle_for_snapshot(id).await?;
                data_snapshot.snapshot_and_fetch(&mut read_handle).await
            }
        };
        match contents {
            Ok(contents) => {
                let mut snapshot = Vec::with_capacity(contents.len());
                for ((data, _), _, diff) in contents {
                    // TODO(petrosagg): We should accumulate the errors too and let the user
                    // interprret the result
                    let row = data.expect("invalid protobuf data").0?;
                    snapshot.push((row, diff));
                }
                Ok(snapshot)
            }
            Err(_) => Err(StorageError::ReadBeforeSince(id)),
        }
    }

    async fn snapshot_cursor(
        &mut self,
        id: GlobalId,
        as_of: Self::Timestamp,
    ) -> Result<SnapshotCursor<Self::Timestamp>, StorageError>
    where
        Self::Timestamp: Timestamp + Lattice + Codec64,
    {
        let data_shard = self.collection(id)?.collection_metadata.data_shard;
        // See the comments in Self::snapshot for what's going on here.
        let cursor = match self.txns_id.as_mut() {
            None => {
                let mut handle = self.read_handle_for_snapshot(id).await?;
                let cursor = handle
                    .snapshot_cursor(Antichain::from_elem(as_of))
                    .await
                    .map_err(|_| StorageError::ReadBeforeSince(id))?;
                SnapshotCursor {
                    _read_handle: handle,
                    cursor,
                }
            }
            Some(txns_id) => {
                // TODO(txn): Replace this with the shared TxnsCache thing
                // we'll have to do anyway for the dataflow operators.
                let mut txns_cache = TxnsCache::<Self::Timestamp, TxnsCodecRow>::open(
                    &self.txns_client,
                    *txns_id,
                    Some(data_shard),
                )
                .await;
                txns_cache.update_gt(&as_of).await;
                let data_snapshot = txns_cache.data_snapshot(data_shard, as_of.clone());
                let mut handle = self.read_handle_for_snapshot(id).await?;
                let cursor = data_snapshot
                    .snapshot_cursor(&mut handle)
                    .await
                    .map_err(|_| StorageError::ReadBeforeSince(id))?;
                SnapshotCursor {
                    _read_handle: handle,
                    cursor,
                }
            }
        };

        Ok(cursor)
    }

    async fn snapshot_stats(
        &self,
        id: GlobalId,
        as_of: Antichain<Self::Timestamp>,
    ) -> Result<SnapshotStats<Self::Timestamp>, StorageError> {
        // TODO(txn): Fix stats for persist-txn shards.
        self.persist_read_handles.snapshot_stats(id, as_of).await
    }

    #[tracing::instrument(level = "debug", skip(self))]
    fn set_read_policy(&mut self, policies: Vec<(GlobalId, ReadPolicy<Self::Timestamp>)>) {
        let mut read_capability_changes = BTreeMap::default();

        for (id, policy) in policies.into_iter() {
            let collection = self
                .collection_mut(id)
                .expect("Reference to absent collection");

            let mut new_read_capability = policy.frontier(collection.write_frontier.borrow());

            if PartialOrder::less_equal(&collection.implied_capability, &new_read_capability) {
                let mut update = ChangeBatch::new();
                update.extend(new_read_capability.iter().map(|time| (time.clone(), 1)));
                std::mem::swap(&mut collection.implied_capability, &mut new_read_capability);
                update.extend(new_read_capability.iter().map(|time| (time.clone(), -1)));
                if !update.is_empty() {
                    read_capability_changes.insert(id, update);
                }
            }

            collection.read_policy = policy;
        }

        if !read_capability_changes.is_empty() {
            self.update_read_capabilities(&mut read_capability_changes);
        }
    }

    #[tracing::instrument(level = "debug", skip(self))]
    fn update_write_frontiers(&mut self, updates: &[(GlobalId, Antichain<Self::Timestamp>)]) {
        let mut read_capability_changes = BTreeMap::default();

        for (id, new_upper) in updates.iter() {
            if let Ok(collection) = self.collection_mut(*id) {
                if PartialOrder::less_than(&collection.write_frontier, new_upper) {
                    collection.write_frontier = new_upper.clone();
                }

                let mut new_read_capability = collection
                    .read_policy
                    .frontier(collection.write_frontier.borrow());

                if PartialOrder::less_equal(&collection.implied_capability, &new_read_capability) {
                    let mut update = ChangeBatch::new();
                    update.extend(new_read_capability.iter().map(|time| (time.clone(), 1)));
                    std::mem::swap(&mut collection.implied_capability, &mut new_read_capability);
                    update.extend(new_read_capability.iter().map(|time| (time.clone(), -1)));

                    if !update.is_empty() {
                        read_capability_changes.insert(*id, update);
                    }
                }
            } else if let Ok(export) = self.export_mut(*id) {
                if PartialOrder::less_than(&export.write_frontier, new_upper) {
                    export.write_frontier = new_upper.clone();
                }

                // Ignore read policy for sinks whose write frontiers are closed, which identifies
                // the sink is being dropped; we need to advance the read frontier to the empty
                // chain to signal to the dataflow machinery that they should deprovision this
                // object.
                let mut new_read_capability = if export.write_frontier.is_empty() {
                    export.write_frontier.clone()
                } else {
                    export.read_policy.frontier(export.write_frontier.borrow())
                };

                if PartialOrder::less_equal(&export.read_capability, &new_read_capability) {
                    let mut update = ChangeBatch::new();
                    update.extend(new_read_capability.iter().map(|time| (time.clone(), 1)));
                    std::mem::swap(&mut export.read_capability, &mut new_read_capability);
                    update.extend(new_read_capability.iter().map(|time| (time.clone(), -1)));

                    if !update.is_empty() {
                        read_capability_changes.insert(*id, update);
                    }
                }
            } else {
                panic!("Reference to absent collection {id}");
            }
        }

        if !read_capability_changes.is_empty() {
            self.update_read_capabilities(&mut read_capability_changes);
        }
    }

    #[tracing::instrument(level = "debug", skip(self))]
    fn update_read_capabilities(
        &mut self,
        updates: &mut BTreeMap<GlobalId, ChangeBatch<Self::Timestamp>>,
    ) {
        // Location to record consequences that we need to act on.
        let mut collections_net = BTreeMap::new();
        let mut exports_net = BTreeMap::new();

        // Repeatedly extract the maximum id, and updates for it.
        while let Some(key) = updates.keys().rev().next().cloned() {
            let mut update = updates.remove(&key).unwrap();
            if let Ok(collection) = self.collection_mut(key) {
                let current_read_capabilities = collection.read_capabilities.frontier().to_owned();
                for (time, diff) in update.iter() {
                    assert!(
                        collection.read_capabilities.count_for(time) + diff >= 0,
                        "update {:?} for collection {key} would lead to negative \
                        read capabilities, read capabilities before applying: {:?}",
                        update,
                        collection.read_capabilities
                    );

                    if collection.read_capabilities.count_for(time) + diff > 0 {
                        assert!(
                            current_read_capabilities.less_equal(time),
                            "update {:?} for collection {key} is trying to \
                            install read capabilities before the current \
                            frontier of read capabilities, read capabilities before applying: {:?}",
                            update,
                            collection.read_capabilities
                        );
                    }
                }

                let changes = collection.read_capabilities.update_iter(update.drain());
                update.extend(changes);

                for id in collection.storage_dependencies.iter() {
                    updates
                        .entry(*id)
                        .or_insert_with(ChangeBatch::new)
                        .extend(update.iter().cloned());
                }

                let (changes, frontier, _cluster_id) =
                    collections_net.entry(key).or_insert_with(|| {
                        (
                            ChangeBatch::new(),
                            Antichain::new(),
                            collection.cluster_id(),
                        )
                    });

                changes.extend(update.drain());
                *frontier = collection.read_capabilities.frontier().to_owned();
            } else if let Ok(export) = self.export_mut(key) {
                // Exports are not depended upon by other storage objects. We
                // only need to report changes in our own read_capability to our
                // dependencies.
                for id in export.storage_dependencies.iter() {
                    updates
                        .entry(*id)
                        .or_insert_with(ChangeBatch::new)
                        .extend(update.iter().cloned());
                }

                // Make sure we also send `AllowCompaction` commands for sinks,
                // which drives updating the sink's `as_of`, among other things.
                let (changes, frontier, _cluster_id) =
                    exports_net.entry(key).or_insert_with(|| {
                        (
                            ChangeBatch::new(),
                            Antichain::new(),
                            Some(export.cluster_id()),
                        )
                    });

                changes.extend(update.drain());
                *frontier = export.read_capability.clone();
            } else {
                // This is confusing and we should probably error.
                panic!("Unknown collection identifier {}", key);
            }
        }

        // Translate our net compute actions into `AllowCompaction` commands and
        // downgrade persist sinces. The actual downgrades are performed by a Tokio
        // task asynchorously.
        //
        // N.B. We only downgrade persist sinces for collections because
        // exports/sinks don't have an associated collection. We still _do_ want
        // to sent `AllowCompaction` commands to workers for them, though.
        let mut worker_compaction_commands = BTreeMap::default();
        let mut persist_compaction_commands = BTreeMap::default();
        for (key, (mut changes, frontier, cluster_id)) in collections_net {
            if !changes.is_empty() {
                worker_compaction_commands.insert(key, (frontier.clone(), cluster_id));
                persist_compaction_commands.insert(key, frontier);
            }
        }
        for (key, (mut changes, frontier, cluster_id)) in exports_net {
            if !changes.is_empty() {
                worker_compaction_commands.insert(key, (frontier, cluster_id));
            }
        }

        self.persist_read_handles
            .downgrade(persist_compaction_commands);

        for (id, (frontier, cluster_id)) in worker_compaction_commands {
            // Acquiring a client for a storage instance requires await, so we
            // instead stash these for later and process when we can.
            self.pending_compaction_commands
                .push((id, frontier, cluster_id));
        }
    }

    async fn ready(&mut self) {
        let mut clients = self
            .clients
            .values_mut()
            .map(|client| client.response_stream())
            .enumerate()
            .collect::<StreamMap<_, _>>();

        use tokio_stream::StreamExt;
        let msg = tokio::select! {
            // Order matters here. We want to process internal commands
            // before processing external commands.
            biased;

            Some(m) = self.internal_response_queue.recv() => m,
            Some((_id, m)) = clients.next() => m,
        };

        self.stashed_response = Some(msg);
    }

    #[tracing::instrument(level = "debug", skip(self))]
    async fn process(&mut self) -> Result<(), anyhow::Error> {
        match self.stashed_response.take() {
            None => (),
            Some(StorageResponse::FrontierUppers(updates)) => {
                self.update_write_frontiers(&updates);
            }
            Some(StorageResponse::DroppedIds(ids)) => {
                let shards_to_finalize: Vec<_> = ids
                    .iter()
                    .filter_map(|id| {
                        // Drop all write handles. This is safe to do because
                        // there will be no more data passed to the write
                        // handle. n.b. we do not need to drop the read handle
                        // because this code is only ever executed in response
                        // to dropping a collection, which downgrades the write
                        // handle to the empty anitchain, which in turn drops
                        // the read handle.
                        //
                        // At most one of these workers will have the handle,
                        // but it's safe to drop from both.
                        self.persist_table_worker.drop_handle(*id);
                        self.persist_monotonic_worker.drop_handle(*id);

                        self.collections.remove(id).map(
                            |CollectionState {
                                 collection_metadata: CollectionMetadata { data_shard, .. },
                                 ..
                             }| data_shard,
                        )
                    })
                    .collect();

                // Ensure we don't leak any shards by tracking all of them we intend to
                // finalize.
                self.register_shards_for_finalization(shards_to_finalize)
                    .await;

                METADATA_COLLECTION
                    .delete_keys(
                        &mut self.stash,
                        ids.into_iter()
                            .map(|id| RustType::into_proto(&id))
                            .collect(),
                    )
                    .await
                    .expect("stash operation must succeed");

                if self.config.finalize_shards {
                    info!("triggering shard finalization due to dropped storage object");
                    self.finalize_shards().await;
                } else {
                    info!("not triggering shard finalization due to dropped storage object because enable_storage_shard_finalization parameter is false")
                }
            }
            Some(StorageResponse::StatisticsUpdates(source_stats, sink_stats)) => {
                // Note we only hold the locks while moving some plain-old-data around here.
                //
                // We just write the whole object, as the update from storage represents the
                // current values.
                //
                // We don't overwrite removed objects, as we may have received a late
                // `StatisticsUpdates` while we were shutting down the storage object.
                {
                    let mut shared_stats = self.source_statistics.lock().expect("poisoned");
                    for stat in source_stats {
                        statistics::StatsInitState::set_if_not_removed(
                            shared_stats.get_mut(&stat.id),
                            stat.worker_id,
                            stat,
                        )
                    }
                }

                {
                    let mut shared_stats = self.sink_statistics.lock().expect("poisoned");
                    for stat in sink_stats {
                        statistics::StatsInitState::set_if_not_removed(
                            shared_stats.get_mut(&stat.id),
                            stat.worker_id,
                            stat,
                        )
                    }
                }
            }
        }

        // IDs of sources that were dropped whose statuses should be updated.
        let mut pending_source_drops = vec![];

        // IDs of sinks that were dropped whose statuses should be updated (and statistics
        // cleared).
        let mut pending_sink_drops = vec![];

        // IDs of sources (and subsources) whose statistics should be cleared.
        let mut source_statistics_to_drop = vec![];

        // TODO(aljoscha): We could consolidate these before sending to
        // instances, but this seems fine for now.
        for (id, frontier, cluster_id) in self.pending_compaction_commands.drain(..) {
            // TODO(petrosagg): make this a strict check
            // TODO(aljoscha): What's up with this TODO?
            // Note that while collections are dropped, the `client` may already
            // be cleared out, before we do this post-processing!
            let client = cluster_id.and_then(|cluster_id| self.clients.get_mut(&cluster_id));

            if cluster_id.is_some() && frontier.is_empty() {
                if self.collections.get(&id).is_some() {
                    pending_source_drops.push(id);
                } else if self.exports.get(&id).is_some() {
                    pending_sink_drops.push(id);
                } else {
                    panic!("Reference to absent collection {id}");
                }
            }

            // Check if the collection is for a Webhook source, unregister if so.
            let collection = self.collections.get(&id);
            if let Some(CollectionState { description, .. }) = collection {
                if description.data_source == DataSource::Webhook && frontier.is_empty() {
                    // Unregister our collection from the manager so writes should no longer occur.
                    self.collection_manager.unregsiter_collection(id).await;

                    pending_source_drops.push(id);
                    // Normally `clusterd` will emit this StorageResponse when it knows we can
                    // drop an ID, but since Webhook sources don't run on a cluster, we manually
                    // emit this event here.
                    let _ = self
                        .internal_response_sender
                        .send(StorageResponse::DroppedIds([id].into()));
                }
            }

            // Sources can have subsources, which don't have associated clusters, which
            // is why this operates differently than sinks.
            if frontier.is_empty() {
                if self.collections.get(&id).is_some() {
                    source_statistics_to_drop.push(id);
                }
            }

            // Note that while collections are dropped, the `client` may already
            // be cleared out, before we do this post-processing!
            if let Some(client) = client {
                client.send(StorageCommand::AllowCompaction(vec![(
                    id,
                    frontier.clone(),
                )]));
            }
        }

        // Delete all source->shard mappings
        self.append_shard_mappings(pending_source_drops.iter().cloned(), -1)
            .await;

        // Record the drop status for all pending source and sink drops.
        //
        // We also delete the items' statistics objects.
        //
        // The locks are held for a short time, only while we do some hash map removals.

        let source_status_history_id =
            self.introspection_ids[&IntrospectionType::SourceStatusHistory];
        let mut updates = vec![];
        for id in pending_source_drops.drain(..) {
            let status_row = healthcheck::pack_status_row(
                id,
                "dropped",
                None,
                &Default::default(),
                &Default::default(),
                (self.now)(),
            );
            updates.push((status_row, 1));
        }

        self.append_to_managed_collection(source_status_history_id, updates)
            .await;

        {
            let mut source_statistics = self.source_statistics.lock().expect("poisoned");
            for id in source_statistics_to_drop {
                source_statistics.remove(&id);
            }
        }

        // Record the drop status for all pending sink drops.
        let sink_status_history_id = self.introspection_ids[&IntrospectionType::SinkStatusHistory];
        let mut updates = vec![];
        {
            let mut sink_statistics = self.sink_statistics.lock().expect("poisoned");
            for id in pending_sink_drops.drain(..) {
                let status_row = healthcheck::pack_status_row(
                    id,
                    "dropped",
                    None,
                    &Default::default(),
                    &Default::default(),
                    (self.now)(),
                );
                updates.push((status_row, 1));

                sink_statistics.remove(&id);
            }
        }
        self.append_to_managed_collection(sink_status_history_id, updates)
            .await;

        Ok(())
    }

    async fn reconcile_state(&mut self) {
        self.reconcile_state_inner().await
    }

    async fn inspect_persist_state(
        &self,
        id: GlobalId,
    ) -> Result<serde_json::Value, anyhow::Error> {
        let collection = &self.collection(id)?.collection_metadata;
        let client = self
            .persist
            .open(collection.persist_location.clone())
            .await?;
        let shard_state = client
            .inspect_shard::<Self::Timestamp>(&collection.data_shard)
            .await?;
        let json_state = serde_json::to_value(shard_state)?;
        Ok(json_state)
    }

    async fn record_frontiers(
        &mut self,
        external_frontiers: BTreeMap<
            GlobalId,
            (Antichain<Self::Timestamp>, Antichain<Self::Timestamp>),
        >,
    ) {
        let mut frontiers = external_frontiers;

        // Enrich `frontiers` with storage frontiers.
        for (object_id, collection) in self.active_collections() {
            let since = collection.read_capabilities.frontier().to_owned();
            let upper = collection.write_frontier.clone();
            frontiers.insert(object_id, (since, upper));
        }
        for (object_id, export) in self.active_exports() {
            // Exports cannot be read from, so their `since` is always the empty frontier.
            let since = Antichain::new();
            let upper = export.write_frontier.clone();
            frontiers.insert(object_id, (since, upper));
        }

        let mut updates = Vec::new();
        let mut push_update =
            |object_id: GlobalId,
             (since, upper): (Antichain<Self::Timestamp>, Antichain<Self::Timestamp>),
             diff: Diff| {
                let read_frontier = since
                    .into_option()
                    .map_or(Datum::Null, |ts| Datum::MzTimestamp(ts.into()));
                let write_frontier = upper
                    .into_option()
                    .map_or(Datum::Null, |ts| Datum::MzTimestamp(ts.into()));
                let row = Row::pack_slice(&[
                    Datum::String(&object_id.to_string()),
                    read_frontier,
                    write_frontier,
                ]);
                updates.push((row, diff));
            };

        let mut old_frontiers = std::mem::replace(&mut self.recorded_frontiers, frontiers);
        for (&id, new) in &self.recorded_frontiers {
            match old_frontiers.remove(&id) {
                Some(old) if &old != new => {
                    push_update(id, new.clone(), 1);
                    push_update(id, old, -1);
                }
                Some(_) => (),
                None => push_update(id, new.clone(), 1),
            }
        }
        for (id, old) in old_frontiers {
            push_update(id, old, -1);
        }

        self.append_to_managed_collection(
            self.introspection_ids[&IntrospectionType::Frontiers],
            updates,
        )
        .await;
    }

    async fn record_replica_frontiers(
        &mut self,
        external_frontiers: BTreeMap<(GlobalId, ReplicaId), Antichain<Self::Timestamp>>,
    ) {
        let mut frontiers = external_frontiers;

        // Enrich `frontiers` with storage frontiers.
        for (object_id, collection) in self.active_collections() {
            let replica_id = collection
                .cluster_id()
                .and_then(|c| self.replicas.get(&c))
                .copied();
            if let Some(replica_id) = replica_id {
                let upper = collection.write_frontier.clone();
                frontiers.insert((object_id, replica_id), upper);
            }
        }
        for (object_id, export) in self.active_exports() {
            let cluster_id = export.cluster_id();
            let replica_id = self.replicas.get(&cluster_id).copied();
            if let Some(replica_id) = replica_id {
                let upper = export.write_frontier.clone();
                frontiers.insert((object_id, replica_id), upper);
            }
        }

        let mut updates = Vec::new();
        let mut push_update = |(object_id, replica_id): (GlobalId, ReplicaId),
                               upper: Antichain<Self::Timestamp>,
                               diff: Diff| {
            let write_frontier = upper
                .into_option()
                .map_or(Datum::Null, |ts| Datum::MzTimestamp(ts.into()));
            let row = Row::pack_slice(&[
                Datum::String(&object_id.to_string()),
                Datum::String(&replica_id.to_string()),
                write_frontier,
            ]);
            updates.push((row, diff));
        };

        let mut old_frontiers = std::mem::replace(&mut self.recorded_replica_frontiers, frontiers);
        for (&key, new) in &self.recorded_replica_frontiers {
            match old_frontiers.remove(&key) {
                Some(old) if &old != new => {
                    push_update(key, new.clone(), 1);
                    push_update(key, old, -1);
                }
                Some(_) => (),
                None => push_update(key, new.clone(), 1),
            }
        }
        for (key, old) in old_frontiers {
            push_update(key, old, -1);
        }

        self.append_to_managed_collection(
            self.introspection_ids[&IntrospectionType::ReplicaFrontiers],
            updates,
        )
        .await;
    }

    async fn record_introspection_updates(
        &mut self,
        type_: IntrospectionType,
        updates: Vec<(Row, Diff)>,
    ) {
        let id = self.introspection_ids[&type_];
        self.append_to_managed_collection(id, updates).await;
    }
}

/// A wrapper struct that presents the adapter token to a format that is understandable by persist
/// and also allows us to differentiate between a token being present versus being set for the
/// first time.
// TODO(aljoscha): Make this crate-public again once the remap operator doesn't
// hold a critical handle anymore.
#[derive(PartialEq, Clone, Debug)]
pub struct PersistEpoch(Option<NonZeroI64>);

impl Opaque for PersistEpoch {
    fn initial() -> Self {
        PersistEpoch(None)
    }
}

impl Codec64 for PersistEpoch {
    fn codec_name() -> String {
        "PersistEpoch".to_owned()
    }

    fn encode(&self) -> [u8; 8] {
        self.0.map(NonZeroI64::get).unwrap_or(0).to_le_bytes()
    }

    fn decode(buf: [u8; 8]) -> Self {
        Self(NonZeroI64::new(i64::from_le_bytes(buf)))
    }
}

impl From<NonZeroI64> for PersistEpoch {
    fn from(epoch: NonZeroI64) -> Self {
        Self(Some(epoch))
    }
}

impl<T> Controller<T>
where
    T: Timestamp + Lattice + TotalOrder + Codec64 + From<EpochMillis> + TimestampManipulation,
    StorageCommand<T>: RustType<ProtoStorageCommand>,
    StorageResponse<T>: RustType<ProtoStorageResponse>,

    Self: StorageController<Timestamp = T>,
{
    /// Create a new storage controller from a client it should wrap.
    ///
    /// Note that when creating a new storage controller, you must also
    /// reconcile it with the previous state.
    pub async fn new(
        build_info: &'static BuildInfo,
        postgres_url: String,
        persist_location: PersistLocation,
        persist_clients: Arc<PersistClientCache>,
        now: NowFn,
        stash_metrics: Arc<StashMetrics>,
        envd_epoch: NonZeroI64,
        metrics_registry: MetricsRegistry,
        enable_persist_txn_tables: bool,
    ) -> Self {
        let (tx, rx) = tokio::sync::mpsc::unbounded_channel();

        let tls = mz_tls_util::make_tls(
            &tokio_postgres::config::Config::from_str(&postgres_url)
                .expect("invalid postgres url for storage stash"),
        )
        .expect("could not make storage TLS connection");
        let mut stash = StashFactory::from_metrics(stash_metrics)
            .open(postgres_url, None, tls)
            .await
            .expect("could not connect to postgres storage stash");

        // Ensure all collections are initialized, otherwise they cannot
        // be read.
        async fn maybe_get_init_batch<'tx, K, V>(
            tx: &'tx mz_stash::Transaction<'tx>,
            typed: &TypedCollection<K, V>,
        ) -> Option<AppendBatch>
        where
            K: mz_stash::Data,
            V: mz_stash::Data,
        {
            let collection = tx
                .collection::<K, V>(typed.name())
                .await
                .expect("named collection must exist");
            if !collection
                .is_initialized(tx)
                .await
                .expect("collection known to exist")
            {
                Some(
                    collection
                        .make_batch_tx(tx)
                        .await
                        .expect("stash operation must succeed"),
                )
            } else {
                None
            }
        }

        stash
            .with_transaction(move |tx| {
                Box::pin(async move {
                    // Query all collections in parallel. Makes for triplicated
                    // names, but runs quick.
                    let (metadata_collection, metadata_export, shard_finalization) = futures::join!(
                        maybe_get_init_batch(&tx, &METADATA_COLLECTION),
                        maybe_get_init_batch(&tx, &METADATA_EXPORT),
                        maybe_get_init_batch(&tx, &command_wals::SHARD_FINALIZATION),
                    );
                    let batches: Vec<AppendBatch> =
                        [metadata_collection, metadata_export, shard_finalization]
                            .into_iter()
                            .filter_map(|b| b)
                            .collect();

                    tx.append(batches).await
                })
            })
            .await
            .expect("stash operation must succeed");

        let txns_client = persist_clients
            .open(persist_location.clone())
            .await
            .expect("location should be valid");
        let (persist_table_worker, txns_id) = if enable_persist_txn_tables {
            let txns_id = PERSIST_TXNS_SHARD
                .insert_key_without_overwrite(&mut stash, (), ShardId::new().into_proto())
                .await
                .expect("could not get txns shard id")
                .parse::<ShardId>()
                .expect("should be valid shard id");
            let txns = TxnsHandle::open(
                T::minimum(),
                txns_client.clone(),
                txns_id,
                Arc::new(RelationDesc::empty()),
                Arc::new(UnitSchema),
            )
            .await;
            let worker = persist_handles::PersistTableWriteWorker::new_txns(tx.clone(), txns);
            (worker, Some(txns_id))
        } else {
            let worker = persist_handles::PersistTableWriteWorker::new_legacy(tx.clone());
            (worker, None)
        };
        let persist_monotonic_worker =
            persist_handles::PersistMonotonicWriteWorker::new(tx.clone());
        let collection_manager_write_handle = persist_monotonic_worker.clone();

        let collection_manager =
            collection_mgmt::CollectionManager::new(collection_manager_write_handle, now.clone());

        Self {
            build_info,
            collections: BTreeMap::default(),
            exports: BTreeMap::default(),
            stash,
            persist_table_worker,
            persist_monotonic_worker,
            persist_read_handles: persist_handles::PersistReadWorker::new(),
            txns_id,
            txns_client,
            stashed_response: None,
            pending_compaction_commands: vec![],
            collection_manager,
            introspection_ids: BTreeMap::new(),
            introspection_tokens: BTreeMap::new(),
            now,
            envd_epoch,
            source_statistics: Arc::new(std::sync::Mutex::new(BTreeMap::new())),
            sink_statistics: Arc::new(std::sync::Mutex::new(BTreeMap::new())),
            clients: BTreeMap::new(),
            replicas: BTreeMap::new(),
            initialized: false,
            config: StorageParameters::default(),
            internal_response_sender: tx,
            internal_response_queue: rx,
            persist_location,
            persist: persist_clients,
            metrics: StorageControllerMetrics::new(metrics_registry),
            recorded_frontiers: BTreeMap::new(),
            recorded_replica_frontiers: BTreeMap::new(),
        }
    }

    /// Validate that a collection exists for all identifiers, and error if any do not.
    fn validate_collection_ids(
        &self,
        ids: impl Iterator<Item = GlobalId>,
    ) -> Result<(), StorageError> {
        for id in ids {
            self.collection(id)?;
        }
        Ok(())
    }

    /// Validate that a collection exists for all identifiers, and error if any do not.
    fn validate_export_ids(&self, ids: impl Iterator<Item = GlobalId>) -> Result<(), StorageError> {
        for id in ids {
            self.export(id)?;
        }
        Ok(())
    }

    /// Iterate over collections that have not been dropped.
    fn active_collections(&self) -> impl Iterator<Item = (GlobalId, &CollectionState<T>)> {
        self.collections
            .iter()
            .filter(|(_id, c)| !c.is_dropped())
            .map(|(id, c)| (*id, c))
    }

    /// Iterate over exports that have not been dropped.
    fn active_exports(&self) -> impl Iterator<Item = (GlobalId, &ExportState<T>)> {
        self.exports
            .iter()
            .filter(|(_id, e)| !e.is_dropped())
            .map(|(id, e)| (*id, e))
    }

    /// Return the since frontier at which we can read from all the given
    /// collections.
    ///
    /// The outer error is a potentially recoverable internal error, while the
    /// inner error is appropriate to return to the adapter.
    fn determine_collection_since_joins(
        &self,
        collections: &[GlobalId],
    ) -> Result<Antichain<T>, StorageError> {
        let mut joined_since = Antichain::from_elem(T::minimum());
        for id in collections {
            let collection = self.collection(*id)?;

            let since = collection.implied_capability.clone();
            joined_since.join_assign(&since);
        }

        Ok(joined_since)
    }

    /// Install read capabilities on the given `storage_dependencies`.
    #[tracing::instrument(level = "info", skip(self))]
    fn install_read_capabilities(
        &mut self,
        from_id: GlobalId,
        storage_dependencies: &[GlobalId],
        read_capability: Antichain<T>,
    ) -> Result<(), StorageError> {
        let mut changes = ChangeBatch::new();
        for time in read_capability.iter() {
            changes.update(time.clone(), 1);
        }

        let mut storage_read_updates = storage_dependencies
            .iter()
            .map(|id| (*id, changes.clone()))
            .collect();

        self.update_read_capabilities(&mut storage_read_updates);

        Ok(())
    }

    /// Opens a write and critical since handles for the given `shard`.
    ///
    /// `since` is an optional `since` that the read handle will be forwarded to if it is less than
    /// its current since.
    ///
    /// This will `halt!` the process if we cannot successfully acquire a critical handle with our
    /// current epoch.
    async fn open_data_handles(
        &self,
        id: &GlobalId,
        shard: ShardId,
        since: Option<&Antichain<T>>,
        relation_desc: RelationDesc,
        persist_client: &PersistClient,
    ) -> (
        WriteHandle<SourceData, (), T, Diff>,
        SinceHandle<SourceData, (), T, Diff, PersistEpoch>,
    ) {
        let diagnostics = Diagnostics {
            shard_name: id.to_string(),
            handle_purpose: format!("controller data for {}", id),
        };

        // Construct the handle in a separate block to ensure all error paths are diverging
        let since_handle = {
            // This block's aim is to ensure the handle is in terms of our epoch
            // by the time we return it.
            let mut handle: SinceHandle<_, _, _, _, PersistEpoch> = persist_client
                .open_critical_since(
                    shard,
                    PersistClient::CONTROLLER_CRITICAL_SINCE,
                    diagnostics.clone(),
                )
                .await
                .expect("invalid persist usage");

            // Take the join of the handle's since and the provided `since`; this lets materialized
            // views express the since at which their read handles "start."
            let since = handle
                .since()
                .join(since.unwrap_or(&Antichain::from_elem(T::minimum())));

            let our_epoch = self.envd_epoch;

            loop {
                let current_epoch: PersistEpoch = handle.opaque().clone();

                // Ensure the current epoch is <= our epoch.
                let unchecked_success = current_epoch.0.map(|e| e <= our_epoch).unwrap_or(true);

                if unchecked_success {
                    // Update the handle's state so that it is in terms of our epoch.
                    let checked_success = handle
                        .compare_and_downgrade_since(
                            &current_epoch,
                            (&PersistEpoch::from(our_epoch), &since),
                        )
                        .await
                        .is_ok();
                    if checked_success {
                        break handle;
                    }
                } else {
                    mz_ore::halt!("fenced by envd @ {current_epoch:?}. ours = {our_epoch}");
                }
            }
        };

        let mut write = persist_client
            .open_writer(
                shard,
                Arc::new(relation_desc),
                Arc::new(UnitSchema),
                diagnostics.clone(),
            )
            .await
            .expect("invalid persist usage");

        // N.B.
        // Fetch the most recent upper for the write handle. Otherwise, this may be behind
        // the since of the since handle. Its vital this happens AFTER we create
        // the since handle as it needs to be linearized with that operation. It may be true
        // that creating the write handle after the since handle already ensures this, but we
        // do this out of an abundance of caution.
        //
        // Note that this returns the upper, but also sets it on the handle to be fetched later.
        write.fetch_recent_upper().await;

        (write, since_handle)
    }

    /// Effectively truncates the `data_shard` associated with `global_id`
    /// effective as of the system time.
    ///
    /// # Panics
    /// - If `id` does not belong to a collection or is not registered as a
    ///   managed collection.
    async fn reconcile_managed_collection(&mut self, id: GlobalId, updates: Vec<(Row, Diff)>) {
        let mut reconciled_updates = BTreeMap::<Row, Diff>::new();

        for (row, diff) in updates.into_iter() {
            *reconciled_updates.entry(row).or_default() += diff;
        }

        match self.collections[&id].write_frontier.as_option() {
            Some(f) if f > &T::minimum() => {
                let as_of = f.step_back().unwrap();

                let negate = self.snapshot(id, as_of).await.unwrap();

                for (row, diff) in negate.into_iter() {
                    *reconciled_updates.entry(row).or_default() -= diff;
                }
            }
            // If collection is closed or the frontier is the minimum, we cannot
            // or don't need to truncate (respectively).
            _ => {}
        }

        let updates: Vec<_> = reconciled_updates
            .into_iter()
            .filter(|(_, diff)| *diff != 0)
            .collect();

        if !updates.is_empty() {
            self.append_to_managed_collection(id, updates).await;
        }
    }

    /// Append `updates` to the `data_shard` associated with `global_id`
    /// effective as of the system time.
    ///
    /// # Panics
    /// - If `id` is not registered as a managed collection.
    #[tracing::instrument(level = "debug", skip(self, updates))]
    async fn append_to_managed_collection(&self, id: GlobalId, updates: Vec<(Row, Diff)>) {
        self.collection_manager
            .append_to_collection(id, updates)
            .await;
    }

    /// Initializes the data expressing which global IDs correspond to which
    /// shards. Necessary because we cannot write any of these mappings that we
    /// discover before the shard mapping collection exists.
    ///
    /// # Panics
    /// - If `IntrospectionType::ShardMapping` is not associated with a
    /// `GlobalId` in `self.introspection_ids`.
    /// - If `IntrospectionType::ShardMapping`'s `GlobalId` is not registered as
    ///   a managed collection.
    async fn initialize_shard_mapping(&mut self) {
        let id = self.introspection_ids[&IntrospectionType::ShardMapping];

        let mut row_buf = Row::default();
        let mut updates = Vec::with_capacity(self.collections.len());
        for (
            global_id,
            CollectionState {
                collection_metadata: CollectionMetadata { data_shard, .. },
                ..
            },
        ) in self.collections.iter()
        {
            let mut packer = row_buf.packer();
            packer.push(Datum::from(global_id.to_string().as_str()));
            packer.push(Datum::from(data_shard.to_string().as_str()));
            updates.push((row_buf.clone(), 1));
        }

        self.reconcile_managed_collection(id, updates).await;
    }

    /// Partially truncate the statement log tables.
    /// The logic is as follows:
    /// For any statement execution whose begin date is younger than
    /// `statement_logging_retention_time_seconds`, retain both it, and any
    /// prepared statement and session it references.
    ///
    /// Note - this can use unbounded memory. We don't need to ingest
    /// the whole collection on startup, but we _do_ need to buffer
    /// all the updates/retractions before sending them. This will be
    /// fine with our current volume, but in the near future we should switch to a more incremental approach.
    /// Persist will soon give us the ability to do that easily; see
    /// [here](https://materializeinc.slack.com/archives/C01CFKM1QRF/p1693592123322009) for details.
    ///
    /// The other reason this might technically use unbounded memory
    /// is because we have to store the UUID of every prepared
    /// statement we plan to keep -- this will cost about 40 MB * the
    /// average QPS, assuming 30-day retention. This shouldn't cause problems for any of the
    /// existing usage patterns, but we will need to think harder
    /// about how to avoid it if we start supporting customers with a
    /// huge QPS (probably we will need to just make their statement
    /// logs non-persistent or have a low sampling rate).
    ///
    /// If for any reason this function starts causing problems in the
    /// real world, we can disable it by turning off the
    /// `TRUNCATE_STATEMENT_LOG` variable.
    async fn partially_truncate_statement_log(&mut self) {
        if !self.config.truncate_statement_log {
            tracing::info!("Not garbage-collecting statement log, due to config parameter.");
            return;
        }
        let now = (self.now)();
        let cutoff = to_datetime(now)
            - chrono::Duration::seconds(
                self.config
                    .statement_logging_retention_time_seconds
                    .try_into()
                    .expect("sane config value"),
            );
        let mseh_id = self.introspection_ids[&IntrospectionType::StatementExecutionHistory];
        let mpsh_id = self.introspection_ids[&IntrospectionType::PreparedStatementHistory];
        let msh_id = self.introspection_ids[&IntrospectionType::SessionHistory];
        let mseh_ts = match self.collections[&mseh_id]
            .write_frontier
            .elements()
            .iter()
            .next()
        {
            Some(ts) if ts > &T::minimum() => ts.step_back().unwrap(),
            // If collection is closed or the frontier is the minimum, we cannot
            // or don't need to truncate (respectively).
            _ => return,
        };
        let mpsh_ts = match self.collections[&mpsh_id]
            .write_frontier
            .elements()
            .iter()
            .next()
        {
            Some(ts) if ts > &T::minimum() => ts.step_back().unwrap(),
            // If collection is closed or the frontier is the minimum, we cannot
            // or don't need to truncate (respectively).
            _ => return,
        };
        let msh_ts = match self.collections[&msh_id]
            .write_frontier
            .elements()
            .iter()
            .next()
        {
            Some(ts) if ts > &T::minimum() => ts.step_back().unwrap(),
            // If collection is closed or the frontier is the minimum, we cannot
            // or don't need to truncate (respectively).
            _ => return,
        };

        let (mseh_began_at, _) = MZ_STATEMENT_EXECUTION_HISTORY_DESC
            .get_by_name(&ColumnName::from("began_at"))
            .expect("schema has not changed");
        let (mseh_prepared_statement_id, _) = MZ_STATEMENT_EXECUTION_HISTORY_DESC
            .get_by_name(&ColumnName::from("prepared_statement_id"))
            .expect("schema has not changed");
        let (mseh_finished_at, _) = MZ_STATEMENT_EXECUTION_HISTORY_DESC
            .get_by_name(&ColumnName::from("finished_at"))
            .expect("schema has not changed");
        let (mseh_finished_status, _) = MZ_STATEMENT_EXECUTION_HISTORY_DESC
            .get_by_name(&ColumnName::from("finished_status"))
            .expect("schema has not changed");

        let mut mseh_rows = Box::pin(
            self.snapshot_and_stream(mseh_id, mseh_ts)
                .await
                .expect("snapshot_succeeds"),
        );

        let mut mseh_updates = vec![];
        let mut ps_to_keep = HashSet::new();
        use futures::stream::StreamExt;
        while let Some((source_data, _ts, diff)) = mseh_rows.next().await {
            assert!(diff != 0);
            let row = source_data.0.expect("valid data");

            let unpacked = row.unpack();
            let began_at = unpacked[mseh_began_at].unwrap_timestamptz();

            if *began_at < cutoff {
                mseh_updates.push((row, diff * -1));
            } else {
                let ps_id = unpacked[mseh_prepared_statement_id].unwrap_uuid();
                // The following `ps_to_keep.insert` invocation is imprecise -- technically, we only
                // need to keep the corresponding prepared statement if the diffs of all the
                // statement execution rows that reference it sum to a positive value.
                // However, it's exceedingly likely that this is true if there are _any_ diffs in the
                // window, so we don't really need to bother keeping track of a multiplicity here.
                //
                // In the event where due to some uncompacted data in mseh we keep around a row in mpsh
                // that we shouldn't, no problems will be caused other than a tiny increase in storage until the
                // next time we run this truncation process.
                ps_to_keep.insert(ps_id);
                let ended_at = unpacked[mseh_finished_at];
                if matches!(ended_at, Datum::Null) {
                    // We refer to a statement that began, but didn't finish (or whose finish was never recorded)
                    // as "aborted".
                    // We need to fill in "finished_at" and "finished_status" for such statements here.
                    let aborted_row = Row::pack(unpacked.iter().enumerate().map(|(i, datum)| {
                        if i == mseh_finished_at {
                            Datum::TimestampTz(
                                to_datetime(now).try_into().expect("sane system time"),
                            )
                        } else if i == mseh_finished_status {
                            Datum::String("aborted")
                        } else {
                            *datum
                        }
                    }));
                    mseh_updates.push((row, diff * -1));
                    mseh_updates.push((aborted_row, diff));
                }
            }
        }

        let mut mpsh_updates = vec![];
        let mut sessions_to_keep = HashSet::new();

        let mut mpsh_rows = Box::pin(
            self.snapshot_and_stream(mpsh_id, mpsh_ts)
                .await
                .expect("snapshot_succeeds"),
        );

        let (mpsh_id_col, _) = MZ_PREPARED_STATEMENT_HISTORY_DESC
            .get_by_name(&ColumnName::from("id"))
            .expect("schema has not changed");
        let (mpsh_session_id, _) = MZ_PREPARED_STATEMENT_HISTORY_DESC
            .get_by_name(&ColumnName::from("session_id"))
            .expect("schema has not changed");
        while let Some((source_data, _ts, diff)) = mpsh_rows.next().await {
            let row = source_data.0.expect("valid data");
            let unpacked = row.unpack();
            let id = unpacked[mpsh_id_col].unwrap_uuid();
            if ps_to_keep.get(&id).is_some() {
                let session_id = unpacked[mpsh_session_id].unwrap_uuid();
                sessions_to_keep.insert(session_id);
            } else {
                mpsh_updates.push((row, diff * -1));
            }
        }
        let ps_kept = ps_to_keep.len();
        std::mem::drop(ps_to_keep);

        let mut msh_rows = Box::pin(
            self.snapshot_and_stream(msh_id, msh_ts)
                .await
                .expect("snapshot_succeeds"),
        );

        let (msh_id_col, _) = MZ_SESSION_HISTORY_DESC
            .get_by_name(&ColumnName::from("id"))
            .expect("schema has not changed");

        let mut msh_updates = vec![];
        while let Some((source_data, _ts, diff)) = msh_rows.next().await {
            let row = source_data.0.expect("valid data");
            let id = row.iter().nth(msh_id_col).unwrap().unwrap_uuid();
            if !sessions_to_keep.contains(&id) {
                msh_updates.push((row, diff * -1));
            }
        }

        self.append_to_managed_collection(mseh_id, mseh_updates)
            .await;
        self.append_to_managed_collection(mpsh_id, mpsh_updates)
            .await;
        self.append_to_managed_collection(msh_id, msh_updates).await;
        // self.metrics
        //     .set_startup_prepared_statement_bytes(u64::cast_from(mpsh_bytes));
        self.metrics
            .set_startup_prepared_statements_kept(u64::cast_from(ps_kept));
    }

    /// Effectively truncates the source status history shard except for the most recent updates
    /// from each ID.
    async fn partially_truncate_status_history(&mut self, collection: IntrospectionType) {
        let (keep_n, occurred_at_col, id_col) = match collection {
            IntrospectionType::SourceStatusHistory => (
                self.config.keep_n_source_status_history_entries,
                healthcheck::MZ_SOURCE_STATUS_HISTORY_DESC
                    .get_by_name(&ColumnName::from("occurred_at"))
                    .expect("schema has not changed")
                    .0,
                healthcheck::MZ_SOURCE_STATUS_HISTORY_DESC
                    .get_by_name(&ColumnName::from("source_id"))
                    .expect("schema has not changed")
                    .0,
            ),
            IntrospectionType::SinkStatusHistory => (
                self.config.keep_n_sink_status_history_entries,
                healthcheck::MZ_SINK_STATUS_HISTORY_DESC
                    .get_by_name(&ColumnName::from("occurred_at"))
                    .expect("schema has not changed")
                    .0,
                healthcheck::MZ_SINK_STATUS_HISTORY_DESC
                    .get_by_name(&ColumnName::from("sink_id"))
                    .expect("schema has not changed")
                    .0,
            ),
            _ => unreachable!(),
        };

        let id = self.introspection_ids[&collection];

        let mut rows = match self.collections[&id].write_frontier.as_option() {
            Some(f) if f > &T::minimum() => {
                let as_of = f.step_back().unwrap();

                self.snapshot(id, as_of).await.expect("snapshot succeeds")
            }
            // If collection is closed or the frontier is the minimum, we cannot
            // or don't need to truncate (respectively).
            _ => return,
        };

        // BTreeMap<Id, MinHeap<(OccurredAt, Row)>>, to track the
        // earliest events for each id.
        let mut last_n_entries_per_id: BTreeMap<Datum, BinaryHeap<Reverse<(Datum, Vec<Datum>)>>> =
            BTreeMap::new();

        // Consolidate the snapshot, so we can process it correctly below.
        differential_dataflow::consolidation::consolidate(&mut rows);

        let mut deletions = vec![];

        for (row, diff) in rows.iter() {
            let status_row = row.unpack();
            let id = status_row[id_col];
            let occurred_at = status_row[occurred_at_col];

            // Duplicate rows ARE possible if many status changes happen in VERY quick succession,
            // so we go ahead and handle them.
            assert!(
                *diff > 0,
                "only know how to operate over consolidated data with diffs > 0, \
                found diff {} for object {} in {:?}",
                diff,
                id,
                collection
            );

            // Consider duplicated rows separately.
            for _ in 0..*diff {
                let entries = last_n_entries_per_id.entry(id).or_default();

                // We CAN have multiple statuses (most likely Starting and Running) at the exact same
                // millisecond, depending on how the `health_operator` is scheduled.
                //
                // Note that these will be arbitrarily ordered, so a Starting event might
                // survive and a Running one won't. The next restart will remove the other,
                // so we don't bother being careful about it.
                //
                // TODO(guswynn): unpack these into health-status objects and use
                // their `Ord1 impl.
                entries.push(Reverse((occurred_at, status_row.clone())));

                // Retain some number of entries, using pop to mark the oldest entries for
                // deletion.
                while entries.len() > keep_n {
                    if let Some(Reverse((_, r))) = entries.pop() {
                        deletions.push(r);
                    }
                }
            }
        }

        let mut row_buf = Row::default();
        // Updates are only deletes because everything else is already in the shard.
        let updates = deletions
            .into_iter()
            .map(|unpacked_row| {
                // Re-pack all rows
                let mut packer = row_buf.packer();
                packer.extend(unpacked_row.into_iter());
                (row_buf.clone(), -1)
            })
            .collect();

        self.append_to_managed_collection(id, updates).await;
    }

    /// Appends a new global ID, shard ID pair to the appropriate collection.
    /// Use a `diff` of 1 to append a new entry; -1 to retract an existing
    /// entry.
    ///
    /// However, data is written iff we know of the `GlobalId` of the
    /// `IntrospectionType::ShardMapping` collection; in other cases, data is
    /// dropped on the floor. In these cases, the data is later written by
    /// [`Self::initialize_shard_mapping`].
    ///
    /// # Panics
    /// - If `self.collections` does not have an entry for `global_id`.
    /// - If `IntrospectionType::ShardMapping`'s `GlobalId` is not registered as
    ///   a managed collection.
    /// - If diff is any value other than `1` or `-1`.
    #[tracing::instrument(level = "debug", skip_all)]
    async fn append_shard_mappings<I>(&self, global_ids: I, diff: i64)
    where
        I: Iterator<Item = GlobalId>,
    {
        mz_ore::soft_assert!(diff == -1 || diff == 1, "use 1 for insert or -1 for delete");

        let id = match self.introspection_ids.get(&IntrospectionType::ShardMapping) {
            Some(id) => *id,
            _ => return,
        };

        let mut updates = vec![];
        // Pack updates into rows
        let mut row_buf = Row::default();

        for global_id in global_ids {
            let shard_id = self.collections[&global_id].collection_metadata.data_shard;

            let mut packer = row_buf.packer();
            packer.push(Datum::from(global_id.to_string().as_str()));
            packer.push(Datum::from(shard_id.to_string().as_str()));
            updates.push((row_buf.clone(), diff));
        }

        self.append_to_managed_collection(id, updates).await;
    }

    /// Updates the on-disk and in-memory representation of `DurableCollectionMetadata` (i.e. KV
    /// pairs in `METADATA_COLLECTION` on-disk and `all_current_metadata` as its in-memory
    /// representation) to include that of `upsert_state`, i.e. upserting the KV pairs in
    /// `upsert_state` into in `all_current_metadata`, as well as `METADATA_COLLECTION`.
    ///
    /// Any shards no longer referenced after the upsert will be finalized.
    ///
    /// Note that this function expects to be called:
    /// - While no source is currently using the shards identified in the current metadata.
    /// - Before any sources begins using the shards identified in `new_metadata`.
    ///
    /// We allow this being kept around as dead code because we might want to perform similar
    /// migration in the future.
    #[allow(dead_code)]
    async fn upsert_collection_metadata(
        &mut self,
        all_current_metadata: &mut BTreeMap<GlobalId, DurableCollectionMetadata>,
        upsert_state: BTreeMap<GlobalId, DurableCollectionMetadata>,
    ) {
        // If nothing changed, don't do any work, which might include async
        // calls into stash.
        if upsert_state.is_empty() {
            return;
        }

        let mut new_shards = BTreeSet::new();
        let mut dropped_shards = BTreeSet::new();
        let mut data_shards_to_replace = BTreeSet::new();
        for (id, new_metadata) in upsert_state.iter() {
            match all_current_metadata.get(id) {
                Some(metadata) => {
                    let old = metadata.data_shard;
                    let new = new_metadata.data_shard;
                    if old != new {
                        info!("replacing {}'s data shard {:?} with {:?}", id, old, new);
                        new_shards.insert(new);
                        dropped_shards.insert(old);
                        data_shards_to_replace.insert(*id);
                    }
                }
                // New collections, which might use an another collection's
                // dropped shard.
                None => {
                    new_shards.insert(new_metadata.data_shard);
                    continue;
                }
            };

            // Update the in-memory representation.
            all_current_metadata.insert(*id, new_metadata.clone());
        }

        // Reconcile dropped shards reference with shards that moved into a new
        // collection.
        dropped_shards.retain(|shard| !new_shards.contains(shard));

        // Ensure we don't leak any shards by tracking all of them we intend to
        // finalize.
        self.register_shards_for_finalization(dropped_shards.iter().cloned())
            .await;

        // Update the on-disk representation.
        METADATA_COLLECTION
            .upsert(
                &mut self.stash,
                upsert_state.into_iter().map(|s| RustType::into_proto(&s)),
            )
            .await
            .expect("connect to stash");

        // Avoid taking lock if unnecessary
        if data_shards_to_replace.is_empty() {
            return;
        }

        let persist_client = self
            .persist
            .open(self.persist_location.clone())
            .await
            .unwrap();

        // Update the in-memory state for data shards
        for id in data_shards_to_replace {
            let c = match self.collection_mut(id) {
                Ok(c) => c,
                Err(_) => continue,
            };

            assert_ne!(
                c.description.data_source,
                DataSource::Progress,
                "we do not have the logic in place to update a progress collection's shard \
                to do this, you'll also need to update the in-memory state of the collection \
                that uses this shard as its progress collection or determine this is set \
                before that collection is created"
            );

            let data_shard = all_current_metadata[&id].data_shard;
            c.collection_metadata.data_shard = data_shard;

            let collection_desc = c.description.clone();
            let relation_desc = c.collection_metadata.relation_desc.clone();

            // This will halt! if any of the handles cannot be acquired
            // because we're not the leader anymore. But that's fine, we
            // already updated all the persistent state (in stash).
            let (write, since_handle) = self
                .open_data_handles(
                    &id,
                    data_shard,
                    collection_desc.since.as_ref(),
                    relation_desc,
                    &persist_client,
                )
                .await;

            match collection_desc.data_source {
                DataSource::Introspection(_) | DataSource::Webhook => {
                    self.persist_monotonic_worker.update(id, write);
                }
                DataSource::Other(DataSourceOther::TableWrites) => {
                    self.persist_table_worker.update(id, write);
                }
                DataSource::Ingestion(_)
                | DataSource::Progress
                | DataSource::Other(DataSourceOther::Compute)
                | DataSource::Other(DataSourceOther::Source) => {
                    // No-op.
                }
            }
            self.persist_read_handles.update(id, since_handle);
        }
    }

    /// Attempts to close all shards marked for finalization.
    #[allow(dead_code)]
    #[tracing::instrument(level = "debug", skip(self))]
    async fn finalize_shards(&mut self) {
        let shards = self
            .stash
            .with_transaction(move |tx| {
                Box::pin(async move {
                    let collection = tx
                        .collection::<ProtoShardId, ()>(command_wals::SHARD_FINALIZATION.name())
                        .await
                        .expect("named collection must exist");
                    tx.peek_one(collection).await
                })
            })
            .await
            .expect("stash operation succeeds")
            .into_iter()
            .map(|(shard, _)| ShardId::from_proto(shard).expect("invalid ShardId"));

        // Open a persist client to delete unused shards.
        let persist_client = self
            .persist
            .open(self.persist_location.clone())
            .await
            .unwrap();

        let persist_client = &persist_client;

        use futures::stream::StreamExt;
        let finalized_shards: BTreeSet<ShardId> = futures::stream::iter(shards)
            .map(|shard_id| async move {
                // Open read handle, whose since is the global since.
                let read_handle: ReadHandle<SourceData, (), T, Diff> = persist_client
                    .open_leased_reader(
                        shard_id,
                        Arc::new(RelationDesc::empty()),
                        Arc::new(UnitSchema),
                        // TODO: thread the global ID into the shard finalization WAL
                        Diagnostics::from_purpose("finalizing shards"),
                    )
                    .await
                    .expect("invalid persist usage");

                // If global since is empty, we can close shard because no one has an outstanding
                // read hold.
                if read_handle.since().is_empty() {
                    let mut write_handle: WriteHandle<SourceData, (), T, Diff> = persist_client
                        .open_writer(
                            shard_id,
                            Arc::new(RelationDesc::empty()),
                            Arc::new(UnitSchema),
                            // TODO: thread the global ID into the shard finalization WAL
                            Diagnostics::from_purpose("finalizing shards"),
                        )
                        .await
                        .expect("invalid persist usage");

                    if write_handle.upper().is_empty() {
                        Some(shard_id)
                    } else {
                        // Finalizing a shard can take a long time cleaning up existing data.
                        // Spawning a task means that we can't proactively remove this shard
                        // from the finalization register, unfortunately... but the next run
                        // of `finalize_shards` should notice the upper has advanced and tidy
                        // up.
                        mz_ore::task::spawn(|| format!("finalize_shard({shard_id})"), async move {
                            let result =
                                tokio::time::timeout(
                                    Duration::from_secs(15 * 60),

                                    write_handle.append(
                                        Vec::<(
                                            (mz_storage_types::sources::SourceData, ()),
                                            T,
                                            Diff,
                                        )>::new(),
                                        write_handle.upper().clone(),
                                        Antichain::new(),
                                    )
                                ).await;

                            // Rather than error, just leave this shard as one to finalize later.
                            match result {
                                Err(_) => {
                                    warn!("timed out while trying to finalize shard {shard_id}");
                                }
                                Ok(Err(usage)) => {
                                    error!("invalid usage while finalizing shard {shard_id}: {usage:?}")
                                }
                                Ok(Ok(Err(mismatch))) => {
                                    warn!("unable to advance the upper of shard {shard_id} to the empty antichain: {mismatch:?}")
                                }
                                Ok(Ok(Ok(()))) => {}
                            };
                        });
                        None
                    }
                } else {
                    None
                }
            })
            // Poll each future for each collection concurrently, maximum of 10 at a time.
            .buffer_unordered(10)
            // HERE BE DRAGONS: see warning on other uses of buffer_unordered
            // before any changes to `collect`
            .collect::<BTreeSet<Option<ShardId>>>()
            .await
            .into_iter()
            .filter_map(|shard| shard)
            .collect();

        if !finalized_shards.is_empty() {
            self.clear_from_shard_finalization_register(finalized_shards)
                .await;
        }
    }

    /// Determines if an `ALTER` is valid.
    fn check_alter_collection_inner(
        &self,
        id: GlobalId,
        mut ingestion: IngestionDescription,
    ) -> Result<(), StorageError> {
        // Check that the client exists.
        self.clients
            .get(&ingestion.instance_id)
            .ok_or(StorageError::IngestionInstanceMissing {
                storage_instance_id: ingestion.instance_id,
                ingestion_id: id,
            })?;

        // Take a cloned copy of the description because we are going to treat it as a "scratch
        // space".
        let mut collection_description = self.collection(id)?.description.clone();

        // Get the previous storage dependencies; we need these to understand if something has
        // changed in what we depend upon.
        let prev_storage_dependencies = collection_description.get_storage_dependencies();

        // We cannot know the metadata of exports yet to be created, so we have
        // to remove them. However, we know that adding source exports is
        // compatible, so still OK to proceed.
        ingestion
            .source_exports
            .retain(|id, _| self.collection(*id).is_ok());

        // Describe the ingestion in terms of collection metadata.
        let described_ingestion = self.enrich_ingestion(id, ingestion.clone())?;

        // Check compatibility between current and new ingestions and install new ingestion in
        // collection description.
        match &mut collection_description.data_source {
            DataSource::Ingestion(cur_ingestion) => {
                let prev_ingestion = self.enrich_ingestion(id, cur_ingestion.clone())?;
                prev_ingestion.alter_compatible(id, &described_ingestion)?;

                *cur_ingestion = ingestion;
            }
            o => {
                tracing::info!(
                    "{id:?} inalterable because its data source is {:?} and not an ingestion",
                    o
                );
                return Err(StorageError::InvalidAlterSource { id });
            }
        };

        let new_storage_dependencies = collection_description.get_storage_dependencies();

        if prev_storage_dependencies != new_storage_dependencies {
            tracing::info!(
                    "{id:?} inalterable because its storage dependencies have changed: were {:?} but are now {:?}",
                    prev_storage_dependencies,
                    new_storage_dependencies
                );
            return Err(StorageError::InvalidAlterSource { id });
        }

        Ok(())
    }

    /// For each element of `collections`, install a read hold on all of the
    /// `storage_dependencies`.
    ///
    /// Note that this adjustment is only guaranteed to be reflected in memory;
    /// downgrades to persist shards are not guaranteed to occur unless they
    /// close the shard.
    ///
    /// # Panics
    ///
    /// - If any identified collection's since is less than the dependency since
    ///   and:
    ///     - Its read policy is not `ReadPolicy::NoPolicy`
    ///     - Its read policy is `ReadPolicy::NoPolicy(f)` and the dependency
    ///       since is <= `f`.
    ///
    ///     - Its write frontier is neither `T::minimum` nor beyond the
    ///       dependency since.
    /// - If any identified collection's data source is not
    ///   [`DataSource::Ingestion] (primary source) or [`DataSource::Other`]
    ///   (subsources).
    fn install_dependency_read_holds<I: Iterator<Item = GlobalId>>(
        &mut self,
        collections: I,
        storage_dependencies: &[GlobalId],
    ) -> Result<(), StorageError> {
        let dependency_since = self.determine_collection_since_joins(storage_dependencies)?;

        for id in collections {
            let collection = self.collection(id).expect("known to exist");
            assert!(
                matches!(collection.description.data_source, DataSource::Other(_) | DataSource::Ingestion(_)),
                "only primary sources w/ subsources and subsources can have dependency read holds installed"
            );

            // Because of the "backward" dependency structure (primary sources
            // depend on subsources, rather than the other way around, which one
            // might expect), we do not know what the initial since of the
            // collection should be. We only find out that information once its
            // primary sources comes along and correlates the subsource to its
            // dependency sinces (e.g. remap shards).
            //
            // Once we find that out, we need ensure that the controller's
            // version of the since is sufficiently advanced so that we may
            // install the read hold.
            //
            // TODO: remove this if statement once we fix the inverse dependency
            // of subsources
            if PartialOrder::less_than(&collection.implied_capability, &dependency_since) {
                assert!(
                    match &collection.read_policy {
                        ReadPolicy::NoPolicy { initial_since } =>
                            PartialOrder::less_than(initial_since, &dependency_since),
                        _ => false,
                    },
                    "subsources should not have external read holds installed until \
                                    their ingestion is created, but {:?} has read policy {:?}",
                    id,
                    collection.read_policy
                );

                // Patch up the implied capability + maybe the persist shard's
                // since.
                self.set_read_policy(vec![(
                    id,
                    ReadPolicy::NoPolicy {
                        initial_since: dependency_since.clone(),
                    },
                )]);

                // We have to re-borrow.
                let collection = self.collection(id).expect("known to exist");
                assert!(
                    collection.implied_capability == dependency_since,
                    "monkey patching the implied_capability to {:?} did not work, is still {:?}",
                    dependency_since,
                    collection.implied_capability,
                );
            }

            // Fill in the storage dependencies.
            let collection = self.collection_mut(id).expect("known to exist");

            assert!(
                PartialOrder::less_than(&collection.implied_capability, &collection.write_frontier)
                    // Whenever a collection is being initialized, this state is
                    // acceptable.
                    || *collection.write_frontier == [T::minimum()],
                "{id}:  the implied capability {:?} should be less than the write_frontier {:?}. Collection state dump: {:#?}",
                collection.implied_capability,
                collection.write_frontier,
                collection
            );

            collection
                .storage_dependencies
                .extend(storage_dependencies.iter().cloned());

            assert!(
                !PartialOrder::less_than(
                    &collection.read_capabilities.frontier(),
                    &collection.implied_capability.borrow()
                ),
                "{id}: at this point, there can be no read holds for any time that is not \
                    beyond the implied capability  but we have implied_capability {:?}, \
                    read_capabilities {:?}",
                collection.implied_capability,
                collection.read_capabilities,
            );

            let read_hold = collection.implied_capability.clone();
            self.install_read_capabilities(id, storage_dependencies, read_hold)?;
        }

        Ok(())
    }

    /// Converts an `IngestionDescription<()>` into `IngestionDescription<CollectionMetadata>`.
    fn enrich_ingestion(
        &self,
        id: GlobalId,
        ingestion: IngestionDescription,
    ) -> Result<IngestionDescription<CollectionMetadata>, StorageError> {
        // Each ingestion is augmented with the collection metadata.
        let mut source_imports = BTreeMap::new();
        for (id, _) in ingestion.source_imports {
            // This _requires_ that the sub-source collection (with
            // `DataSource::Other`) was registered BEFORE we process this, the
            // top-level collection.
            let metadata = self.collection(id)?.collection_metadata.clone();
            source_imports.insert(id, metadata);
        }

        // The ingestion metadata is simply the collection metadata of the collection with
        // the associated ingestion
        let ingestion_metadata = self.collection(id)?.collection_metadata.clone();

        let mut source_exports = BTreeMap::new();
        for (id, export) in ingestion.source_exports {
            // Note that these metadata's have been previously enriched with the
            // required `RelationDesc` for each sub-source above!
            let storage_metadata = self.collection(id)?.collection_metadata.clone();
            source_exports.insert(
                id,
                SourceExport {
                    storage_metadata,
                    output_index: export.output_index,
                },
            );
        }

        Ok(IngestionDescription {
            source_imports,
            source_exports,
            ingestion_metadata,
            // The rest of the fields are identical
            desc: ingestion.desc,
            instance_id: ingestion.instance_id,
            remap_collection_id: ingestion.remap_collection_id,
        })
    }

    async fn read_handle_for_snapshot(
        &self,
        id: GlobalId,
    ) -> Result<ReadHandle<SourceData, (), T, Diff>, StorageError> {
        let metadata = &self.collection(id)?.collection_metadata;

        let persist_client = self
            .persist
            .open(metadata.persist_location.clone())
            .await
            .unwrap();

        // We create a new read handle every time someone requests a snapshot and then immediately
        // expire it instead of keeping a read handle permanently in our state to avoid having it
        // heartbeat continously. The assumption is that calls to snapshot are rare and therefore
        // worth it to always create a new handle.
        let read_handle = persist_client
            .open_leased_reader::<SourceData, (), _, _>(
                metadata.data_shard,
                Arc::new(metadata.relation_desc.clone()),
                Arc::new(UnitSchema),
                Diagnostics {
                    shard_name: id.to_string(),
                    handle_purpose: format!("snapshot {}", id),
                },
            )
            .await
            .expect("invalid persist usage");
        Ok(read_handle)
    }

    async fn snapshot_and_stream(
        &self,
        id: GlobalId,
        as_of: T,
    ) -> Result<impl Stream<Item = (SourceData, T, Diff)>, StorageError> {
        let as_of = Antichain::from_elem(as_of);
        let mut read_handle = self.read_handle_for_snapshot(id).await?;
        use futures::stream::StreamExt;
        match read_handle.snapshot_and_stream(as_of).await {
            Ok(contents) => Ok(contents.map(|((result_k, result_v), t, diff)| {
                let () = result_v.expect("invalid empty value");
                let data = result_k.expect("invalid key data");
                (data, t, diff)
            })),
            Err(_) => Err(StorageError::ReadBeforeSince(id)),
        }
    }
}
