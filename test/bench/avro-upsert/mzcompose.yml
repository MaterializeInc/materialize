# Copyright Materialize, Inc. All rights reserved.
#
# Use of this software is governed by the Business Source License
# included in the LICENSE file at the root of this repository.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0.


# Map from host-port:internal port
#
# This mostly just shows all the ports that are available to the host system, if you want
# to change these you must restart the docker-compose cluster.
x-port-mappings:
  - &kafka-internal ${KAFKA_PORT:-9092}
  - &kafka-external 9093:9093
  - &schema-registry ${SR_PORT:-8081:8081}
  - &materialized ${MZ_PORT:-6875}
  - &grafana 3000:3000
  - &prometheus 9090
  - &perf-metrics ${PERF_METRICS_PORT:-8675}
  - &perf-dash-web ${PERF_DASH_PORT:-8875:8875}

version: '3.7'
services:
  create-views:
    mzbuild: avro-upsert-create-views
  perf-dash-metrics:
    mzbuild: materialized
    ports:
      - *perf-metrics
    command:
      - --disable-telemetry
      - --listen-addr=0.0.0.0:${PERF_METRICS_PORT:-8675}
      - --logical-compaction-window=1ms
    environment:
      - MZ_DEV=1
  perf-dash-scraper:
    mzbuild: perf-dash-scraper
    command: scrape
  perf-dash-create-views:
    mzbuild: perf-dash-create-views
  perf-dash-web:
    mzbuild: perf-dash-web
    ports:
      - *perf-dash-web
  materialized:
    mzbuild: materialized
    ports:
      - *materialized
    command:
      - --workers=${MZ_WORKERS:-16}
      - --logical-compaction-window=1ms
      # We want this to eventually count up to the size of the largest batch in
      # an arrangement. This number represents a tradeoff between proactive
      # merging (which takes time) and low latency.
      #
      # 1000 was chosen by fair dice roll.
      - --differential-idle-merge-effort=1000
      - --timely-progress-mode=${MZ_TIMELY_PROGRESS_MODE:-demand}
      - --disable-telemetry
    environment:
      # You can, for example, add `pgwire=trace` or change `info` to `debug` to
      # get more verbose logs.
      - MZ_LOG=pgwire=debug,info
      - MZ_DEV=1
  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
  kafka:
    image: confluentinc/cp-enterprise-kafka:5.5.3
    ports:
      - *kafka-internal
      - *kafka-external
    depends_on: [zookeeper]
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://${KAFKA_HOST:-kafka}:9093
      KAFKA_METRIC_REPORTERS: "io.confluent.metrics.reporter.ConfluentMetricsReporter"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG_RETENTION_HOURS: -1
      KAFKA_NUM_PARTITIONS: 30
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_LOG_CLEANUP_POLICY: "compact"
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: "kafka:9092"
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      # To avoid race condition with control-center
      CONFLUENT_METRICS_REPORTER_TOPIC_CREATE: "false"
      KAFKA_JMX_PORT: 9991
  schema-registry:
    image: confluentinc/cp-schema-registry:5.5.3
    ports:
      - *schema-registry
    environment:
     - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
     - SCHEMA_REGISTRY_HOST_NAME=schema-registry
     - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8081,http://localhost:8081
    depends_on: [zookeeper, kafka]
  avro-upsert-generator:
    mzbuild: avro-upsert-generator
  metric-verifier:
    mzbuild: metric-verifier
    environment:
      MZ_WORKERS: ${MZ_WORKERS:-0}
      MZBENCH_GIT_REF: ${MZBENCH_GIT_REF:-None}
      MZBENCH_ID: ${MZBENCH_ID:-0}
  # All monitoring
  dashboard:
    mzbuild: dashboard
    propagate-uid-gid: true
    environment:
      - 'MATERIALIZED_URL=materialized:6875'
    ports:
      - *grafana
      - *prometheus
    volumes:
      # ensure that data doesn't get lost across restarts
      # data will be lost if you remove docker volumes (using nuke, for example)
      - prometheus:/prometheus
      - grafana:/var/lib/grafana
      # specialized configurations
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./grafana/conf/load-test.json:/etc/grafana/provisioning/dashboards/chbench-load-test.json

volumes:
  grafana:
  prometheus:

mzworkflows:

  start-services:
    steps:
    - step: start-services
      services: [dashboard]
    - step: start-services
      services: [kafka, schema-registry, perf-dash-metrics]
    - step: wait-for-tcp
      host: kafka
      port: 9092
    - step: wait-for-tcp
      host: schema-registry
      port: 8081
    - step: run
      service: perf-dash-scraper
      command: >-
        create-topics
    - step: run
      service: metric-verifier
      command: >-
        create-topics
    - step: run
      service: perf-dash-create-views
    - step: start-services
      services: [perf-dash-web]

  setup-benchmark:
    env:
      UPSERT_GENERATOR_DISTRIBUTION: ${UPSERT_GENERATOR_DISTRIBUTION:-benchmark}
      UPSERT_GENERATOR_NUM_RECORDS: ${UPSERT_GENERATOR_NUM_RECORDS:-400000000}
      UPSERT_GENERATOR_PARALLELISM: ${UPSERT_GENERATOR_PARALLELISM:-40}
    steps:
    - step: workflow
      workflow: start-services
    - step: run
      service: avro-upsert-generator
      command: >-
        --parallelism=${UPSERT_GENERATOR_PARALLELISM}
        --num-records=${UPSERT_GENERATOR_NUM_RECORDS}
        --distribution=${UPSERT_GENERATOR_DISTRIBUTION}

  run-benchmark:
    env:
      MZ_WORKERS: ${MZ_WORKERS:-16}
      METRIC_VERIFIER_TIMEOUT: ${METRIC_VERIFIER_TIMEOUT:-3600}
      UPSERT_GENERATOR_NUM_RECORDS: ${UPSERT_GENERATOR_NUM_RECORDS:-400000000}
    steps:
    - step: remove-services
      services: [materialized, perf-dash-scraper]
      destroy_volumes: true
    - step: start-services
      services: [materialized, perf-dash-scraper]
    - step: run
      service: metric-verifier
      daemon: true
      command: >-
        scrape
        --timeout-seconds=${METRIC_VERIFIER_TIMEOUT}
        "sum(mz_messages_ingested)"
        ${UPSERT_GENERATOR_NUM_RECORDS}
    - step: run
      service: create-views
    - step: wait
      service: metric-verifier
      expected_return_code: 0
      print_logs: true

  # The benchmark that we run in the cloud
  benchmark-large:
    steps:
    - step: workflow
      workflow: setup-benchmark-large
    - step: workflow
      workflow: run-benchmark-large

  setup-benchmark-large:
    env:
      UPSERT_GENERATOR_DISTRIBUTION: benchmark
      UPSERT_GENERATOR_NUM_RECORDS: 400000000
    steps:
    - step: workflow
      workflow: setup-benchmark

  run-benchmark-large:
    env:
      MZ_WORKERS: ${MZ_WORKERS:-16}
      UPSERT_GENERATOR_NUM_RECORDS: 400000000
    steps:
    - step: workflow
      workflow: run-benchmark

  # The benchmark that developers can run on their laptop
  benchmark-medium:
    steps:
    - step: workflow
      workflow: setup-benchmark-medium
    - step: workflow
      workflow: run-benchmark-medium

  setup-benchmark-medium:
    env:
      UPSERT_GENERATOR_DISTRIBUTION: medium
      UPSERT_GENERATOR_NUM_RECORDS: 20000000
      UPSERT_GENERATOR_PARALLELISM: 8
    steps:
    - step: workflow
      workflow: setup-benchmark

  run-benchmark-medium:
    env:
      MZ_WORKERS: ${MZ_WORKERS:-8}
      METRIC_VERIFIER_TIMEOUT: 900
      UPSERT_GENERATOR_NUM_RECORDS: 20000000
    steps:
    - step: workflow
      workflow: run-benchmark

  # The smoketest benchmark that we run in CI
  ci:
    steps:
    - step: workflow
      workflow: setup-benchmark-ci
    - step: workflow
      workflow: run-benchmark-ci

  benchmark-ci:
    steps:
      - step: worfklow
        workflow: ci

  setup-benchmark-ci:
    env:
      UPSERT_GENERATOR_DISTRIBUTION: small
      UPSERT_GENERATOR_NUM_RECORDS: 100000
      UPSERT_GENERATOR_PARALLELISM: 4
    steps:
    - step: workflow
      workflow: setup-benchmark

  run-benchmark-ci:
    env:
      MZ_WORKERS: ${MZ_WORKERS:-8}
      METRIC_VERIFIER_TIMEOUT: 30
      UPSERT_GENERATOR_NUM_RECORDS: 100000
    steps:
    - step: workflow
      workflow: run-benchmark

  benchmark-insert-with-filter:
    steps:
    - step: workflow
      workflow: setup-benchmark-insert-with-filter
    - step: workflow
      workflow: run-benchmark-insert-with-filter

  setup-benchmark-insert-with-filter:
    steps:
    - step: workflow
      workflow: start-services
    - step: run
      service: avro-upsert-generator
      command: >-
        --parallelism=40

  run-benchmark-insert-with-filter:
    env:
      MZ_WORKERS: ${MZ_WORKERS:-16}
    steps:
    - step: remove-services
      services: [materialized, perf-dash-scraper]
      destroy_volumes: true
    - step: start-services
      services: [materialized, perf-dash-scraper]
    - step: run
      service: metric-verifier
      daemon: true
      command: >-
        scrape
        --timeout-seconds=900
        "sum(mz_messages_ingested)"
        "400000000"
    - step: run
      service: create-views
      command: >-
        insert_views.sql
    - step: wait
      service: metric-verifier
      expected_return_code: 0
      print_logs: true

  run-generator:
    steps:
    - step: run
      service: avro-upsert-generator

  rerun-benchmark:
    steps:
    - step: remove-services
      services: [materialized, perf-dash-scraper]
      destroy_volumes: true
    - step: start-services
      services: [materialized, perf-dash-scraper]
    - step: run
      service: create-views
