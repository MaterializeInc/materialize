#!/usr/bin/env python3

# Copyright Materialize, Inc. and contributors. All rights reserved.
#
# Use of this software is governed by the Business Source License
# included in the LICENSE file at the root of this repository.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0.

import argparse
import multiprocessing
import pathlib
import subprocess
import sys

DISTRIBUTIONS = "/usr/share/generator/distributions"

def run(args: argparse.Namespace) -> int:
    """Run the generator, inserting args.num_records number of messages."""

    records_per_process = int(args.num_records / args.parallelism)

    bootstrap_broker = args.bootstrap_broker
    schema_registry_url = args.schema_registry_url

    topic= args.topic

    distribution_dir = pathlib.Path(DISTRIBUTIONS, args.distribution)
    key_schema = pathlib.Path(distribution_dir, "key-schema.json").read_text().strip()
    value_schema = pathlib.Path(distribution_dir, "value-schema.json").read_text().strip()

    key_distribution = (
        pathlib.Path(distribution_dir, "key-distribution.json").read_text().strip()
    )
    value_distribution = (
        pathlib.Path(distribution_dir, "value-distribution.json").read_text().strip()
    )

    kafka_gen = [
        "/usr/local/bin/kgen",
        "--quiet",
        "--bootstrap-server",
        bootstrap_broker,
        "--schema-registry-url",
        schema_registry_url,
        "--num-records",
        str(records_per_process),
        "--topic",
        topic,
        "--keys",
        "avro",
        "--values",
        "avro",
        "--avro-schema",
        value_schema,
        "--avro-distribution",
        value_distribution,
        "--avro-key-schema",
        key_schema,
        "--avro-key-distribution",
        key_distribution,
    ]

    print(
        f"Spawning {args.parallelism} generator processes, writing {records_per_process} messages each"
    )
    procs = [subprocess.Popen(kafka_gen) for _ in range(0, args.parallelism)]

    exit_code = 0
    for (i, p) in enumerate(procs):
        p.wait()
        print(
            f"{i}/{args.parallelism} processes finished: pid={p.pid} returncode={p.returncode}"
        )

        # If a process exited with an error, exit with the return code of the first such process
        if p.returncode != 0 and exit_code == 0:
            exit_code = p.returncode

    return exit_code


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "-d",
        "--distribution",
        type=str,
        default="benchmark",
        help="Name of the distribution to use for generating random records",
        choices=[p.name for p in pathlib.Path(DISTRIBUTIONS).iterdir()],
    )

    parser.add_argument(
        "-n",
        "--num-records",
        type=int,
        default=400000000,
        help="Total number of messages to generate",
    )
    parser.add_argument(
        "-p",
        "--parallelism",
        type=int,
        default=multiprocessing.cpu_count(),
        help="Number of processes to spawn",
    )

    parser.add_argument(
        "-b",
        "--bootstrap-broker",
        type=str,
        default="kafka:9092",
        help="Kafka bootstrap server",
    )

    parser.add_argument(
        "-r",
        "--schema-registry-url",
        type=str,
        default="http://schema-registry:8081",
        help="Schema Registry url",
    )

    parser.add_argument(
        "-t",
        "--topic",
        type=str,
        help="Kafka topic",
    )

    args = parser.parse_args()
    if args.num_records % args.parallelism != 0:
        print("ERROR: Number of records must divide evenly by number of processes")
        sys.exit(1)

    sys.exit(run(args))
