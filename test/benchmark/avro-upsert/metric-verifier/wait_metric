#!/usr/bin/env python3

# Copyright Materialize, Inc. All rights reserved.
#
# Use of this software is governed by the Business Source License
# included in the LICENSE file at the root of this repository.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0.

import argparse
import dateparser
import datetime
import sys
import time
import urllib

import kafka  # type: ignore
import prometheus_api_client
import prometheus_api_client.utils

SCHEMAS_DIRECTORY = "/usr/share/benchmarks/schemas"

def run(args: argparse.Namespace) -> int:
    """Wait for the query to settle or timeout and then dump ingest metrics."""

    start = dateparser.parse('now')
    dashboard_start = dateparser.parse('30 seconds ago')

    # Parse topic name from the schema files ("namespace")
    topic = None
    for schema_file in pathlib.Path(SCHEMAS_DIRECTORY).glob('*.avsc'):
        topic_name = set_schema(args, schema_file)
        if topic:
            assert topic_name == topic
        topic = topic_name

    try:
        return wait_metric(args)
    finally:
        record_results(args, topic_name, start, dashboard_start)


def record_results(args: argparse.Namespace, start: datetime.datetime, dashboard_start: datetime.datetime):
    """Write the results of this benchmark to the Kafka topic"""

    # Create parameters to see a dashboard with the metrics from this benchmark run
    # Add padding to make the charts nicer to read
    # Grafana expects timestamps with milliseconds
    path = '/d/materialize-overview/materialize-overview'
    query = urllib.parse.urlencode( {
              "from": round(dashboard_start.timestamp()) * 1000,
                "to": round(dateparser.parse('in 30 seconds').timestamp()) * 1000,
                "tz": "UTC"
             })
    dashboard_url = urllib.parse.urlunparse(('http', args.grafana_location, path, '', query, ''))

    key = encode_key(args.benchmark_id)
    value = encode_value({"start_ms": start.timestamp() * 1000,
               "end_ms": dateparser.parse('now').timestamp() *  1000,
               "dashboard_url": dashboard_url
              })


    producer.send(kafka_topic, key=key, value=value)
    producer.flush()
    print(f'Grafana URL: {dashboard_url}')


def set_schema(args: argparse.Namespace, schema_file: pathlib.Path) -> None:
    """Write our JSON schema definition to schema registry."""

    url = f"http://{args.schema_registry}:{args.schema_registry_port/subjects/{schema_name}/versions"
    headers = {"Content-Type": "application/vnd.schemaregistry.v1+json"}
    schema = schema_file.read_text().strip()
    response = requests.post(
        url,
        json={"schema": schema},
        headers=headers,
    )

    response.raise_for_status()
    if not response.json()["id"] == subject_id:
        print(f"FATAL: failed to write schema to schema registry: {url}")
        sys.exit(1)

    return json.loads(schema)["namespace"]


def wait_metric(args: argparse.Namespace) -> int:
    """Wait for the given metric, returning desired exit code (0 is success)."""
    prom = prometheus_api_client.PrometheusConnect(f'http://{args.host}:{args.port}')
    time_so_far = 0
    start = int(time.monotonic())
    while time_so_far < args.timeout_seconds:
        current_values = prom.custom_query(args.prom_query)
        if args.verbose:
            print(current_values)

        if len(current_values) > 1:
            print('ERROR: Prometheus query must only return a zero or one results!')
            prometheus_api_client.utils.pretty_print_metric(current_values)
            return 1

        # We aren't running query_range, so there should only be a single timestamp and point in the reponse
        if current_values:
            (ts, point) = [float(i) for i in current_values[0]['value']]
            if point == args.expected_value:
                rate = round(point / max(time_so_far, 1))
                print(f"SUCCESS! seconds_taken={time_so_far} rows_per_sec={rate}")
                return 0

        time.sleep(1)
        time_so_far = int(time.monotonic()) - start

    # Check this last because it's okay to have a 1-2 second grace period and we want the
    # ability to print the most recent result
    print(f"FAILED! Query response is '{point}' after {time_so_far} seconds")
    return 1


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="Enable verbose logging to print the results of each prometheus query",
    )

    parser.add_argument(
        "--benchmark-id",
        type=int,
        help="Unique identifier that identifies this benchmark",
    )

    parser.add_argument(
        "--grafana-location",
        type=str,
        default='localhost:3000',
        help="Default URL net location (host and port) for Grafana",
    )

    parser.add_argument(
        "--kafkahost",
        help="Name of the kafka broker",
        type=str,
        default="kafka",
    )
    parser.add_argument(
        "--kafka-port", help="Port the connect to the broker over", type=int, default=9092
    )

    parser.add_argument(
        "--schema-registry", help="Hostname of the Kafka schema registry", type=str,
        default="schema-registry"
    )
    parser.add_argument(
        "--schema-registry-port", help="Port that schema registry is listening on", type=int,
        default=8081
    )


    parser.add_argument(
        "--prometheus-host",
        type=str,
        default='dashboard',
        help="Hostname of the prometheus instance to query",
    )

    parser.add_argument(
        "--prometheus-port",
        type=int,
        default=9090,
        help="Port on which the prometheus instance is running",
    )

    parser.add_argument(
        "-t",
        "--timeout-seconds",
        type=int,
        default=900,
        help="Length of time to wait until the metric reaches the specified value",
    )

    parser.add_argument(
        "prom_query",
        type=str,
        help="Prometheus query to run",
    )

    parser.add_argument(
        "expected_value",
        type=float,
        help="Expected value of the metric queried",
    )

    args = parser.parse_args()
    sys.exit(run(args))
