# Copyright Materialize, Inc. and contributors. All rights reserved.
#
# Use of this software is governed by the Business Source License
# included in the LICENSE file at the root of this repository.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0.

version: '3.7'

mzworkflows:
  debezium-avro:
    steps:
      - step: workflow
        workflow: start-deps

      - step: run
        service: testdrive-svc
        command: debezium-postgres.td.initialize

      - step: run
        service: testdrive-svc
        command: ${TD_TEST:-*.td}

  start-deps:
    steps:
      - step: start-services
        services: [postgres, kafka, schema-registry, materialized, debezium]
      - step: wait-for-tcp
        host: kafka
        port: 9092
        timeout_secs: 120
      - step: wait-for-tcp
        host: schema-registry
        port: 8081
      - step: wait-for-tcp
        host: debezium
        port: 8083
      - step: wait-for-mz
      - step: wait-for-postgres
        dbname: postgres

services:
  testdrive-svc:
    mzbuild: testdrive
    entrypoint:
      - bash
      - -c
      - >-
        testdrive
        --kafka-addr=kafka:9092
        --schema-registry-url=http://schema-registry:8081
        --materialized-url=postgres://materialize@materialized:6875
        --validate-catalog=/share/mzdata/catalog
        --no-reset
        --default-timeout 300
        $$*
      - bash
    environment:
    - TMPDIR=/share/tmp
    - MZ_LOG_FILTER
    - AWS_ACCESS_KEY_ID
    - AWS_SECRET_ACCESS_KEY
    - AWS_SESSION_TOKEN
    volumes:
    - .:/workdir
    - mzdata:/share/mzdata
    - tmp:/share/tmp
    propagate-uid-gid: true
    init: true
    depends_on: [kafka, zookeeper, schema-registry, materialized, debezium]
  materialized:
    mzbuild: materialized
    command: >-
      --data-directory=/share/mzdata
      --workers 1
      --experimental
      --timestamp-frequency 100ms
      --disable-telemetry
      --retain-prometheus-metrics 1s
    ports:
      - 6875
    environment:
    - MZ_DEV=1
    - MZ_LOG_FILTER
    - AWS_ACCESS_KEY_ID
    - AWS_SECRET_ACCESS_KEY
    - AWS_SESSION_TOKEN
    - ALL_PROXY
    volumes:
    - mzdata:/share/mzdata
    - tmp:/share/tmp
  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.4
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
  kafka:
    image: confluentinc/cp-kafka:5.5.4
    environment:
    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
    - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
    - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
  schema-registry:
    image: confluentinc/cp-schema-registry:5.5.4
    environment:
    - SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=PLAINTEXT://kafka:9092
    - SCHEMA_REGISTRY_HOST_NAME=localhost
    depends_on: [kafka, zookeeper]
  postgres:
    image: postgres:11.4
    ports:
      - 5432
    command: postgres -c wal_level=logical -c max_wal_senders=20 -c max_replication_slots=20
  debezium:
    image: debezium/connect:1.6
    hostname: debezium
    ports:
      - 8083
    environment:
    - BOOTSTRAP_SERVERS=kafka:9092
    - CONFIG_STORAGE_TOPIC=connect_configs
    - OFFSET_STORAGE_TOPIC=connect_offsets
    - STATUS_STORAGE_TOPIC=connect_statuses
    # We don't support JSON, so ensure that connect uses AVRO to encode messages and CSR to
    # record the schema
    - KEY_CONVERTER=io.confluent.connect.avro.AvroConverter
    - VALUE_CONVERTER=io.confluent.connect.avro.AvroConverter
    - CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL=http://schema-registry:8081
    - CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=http://schema-registry:8081
    depends_on: [kafka, schema-registry]

volumes:
  mzdata:
  tmp:
