# Copyright Materialize, Inc. and contributors. All rights reserved.
#
# Use of this software is governed by the Business Source License
# included in the LICENSE file at the root of this repository.
#
# As of the Change Date specified in that file, in accordance with
# the Business Source License, use of this software will be governed
# by the Apache License, Version 2.0.
#
# Test that large transactions are properly replicated

$ postgres-execute connection=postgres://postgres:postgres@postgres
DROP TABLE IF EXISTS ten;
CREATE TABLE ten (f1 INTEGER);
INSERT INTO ten VALUES (1), (2), (3), (4), (5), (6), (7), (8), (9), (10);
CREATE TABLE large_distinct_rows (f1 INTEGER, PRIMARY KEY (f1));
ALTER TABLE large_distinct_rows REPLICA IDENTITY FULL;
CREATE TABLE large_same_rows (f1 INTEGER);
ALTER TABLE large_same_rows REPLICA IDENTITY FULL;
CREATE SEQUENCE large_transaction_sequence;
BEGIN;
INSERT INTO large_distinct_rows SELECT nextval('large_transaction_sequence') FROM ten AS a1, ten AS a2, ten AS a3, ten AS a4, ten AS a5, ten AS a6;
INSERT INTO large_same_rows SELECT 1 FROM ten AS a1, ten AS a2, ten AS a3, ten AS a4, ten AS a5, ten AS a6;
COMMIT;

> CREATE MATERIALIZED SOURCE large_distinct_rows
  FROM KAFKA BROKER '${testdrive.kafka-addr}' TOPIC 'postgres.public.large_distinct_rows'
  WITH (consistency_topic = 'postgres.transaction')
  FORMAT AVRO USING CONFLUENT SCHEMA REGISTRY '${testdrive.schema-registry-url}'
  ENVELOPE DEBEZIUM;

> CREATE MATERIALIZED SOURCE large_same_rows
  FROM KAFKA BROKER '${testdrive.kafka-addr}' TOPIC 'postgres.public.large_same_rows'
  WITH (consistency_topic = 'postgres.transaction')
  FORMAT AVRO USING CONFLUENT SCHEMA REGISTRY '${testdrive.schema-registry-url}'
  ENVELOPE DEBEZIUM;

> SELECT COUNT(*), COUNT(DISTINCT f1), MIN(f1), MAX(f1) FROM large_distinct_rows
1000000 1000000 1 1000000

> SELECT COUNT(*), COUNT(DISTINCT f1), MIN(f1), MAX(f1) FROM large_same_rows;
1000000 1 1 1

$ postgres-execute connection=postgres://postgres:postgres@postgres
UPDATE large_distinct_rows SET f1 = f1 + 1000000;
UPDATE large_same_rows SET f1 = 2;

> SELECT COUNT(*), COUNT(DISTINCT f1), MIN(f1), MAX(f1) FROM large_distinct_rows
1000000 1000000 1000001 2000000

> SELECT COUNT(*), COUNT(DISTINCT f1), MIN(f1), MAX(f1) FROM large_same_rows
1000000 1 2 2
