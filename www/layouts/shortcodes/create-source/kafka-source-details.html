### Kafka source details

- Materialize expects each source to use one Kafka topic, which is&mdash;in
  turn&mdash;generated by a single table in an upstream database.
- {{ if eq ($.Get "format") "avro" }}By default, Materialize only ingests message
  payloads, not their keys. Avro-formatted sources, though, can work with message
  keys using the [Upsert envelope](#upsert-envelope-details).
- {{ end }}Materialize supports connecting to
  [SSL-encrypted](#ssl-encrypted-kafka-details) or
  [Kerberized Kafka clusters](#kerberized-kafka-details).

#### SSL-encrypted Kafka details

Enable connections to SSL-encrypted Kafka clusters using the appropriate
[`WITH` options](#ssl-with-options).

- To encrypt data coming from the Kafka broker, authenticate its identity by
  providing a copy of the CA certificate that signed the broker's certificate
  (`ssl_ca_location`).
- To connect Materialize to a Kafka cluster that requires SSL authentication,
  create a client key pair for Materialize, and then provide the certificate,
  key, and optional key password (`ssl_certificate_location`, `ssl_key_location`,
  `ssl_key_password`, respectively). Note that this also requires authenticating
  the server.
- Materialize can also connect to a Confluent Schema Registry if it uses the same
  CA as the Kafka broker.

#### Kerberized Kafka details

Enable connections to Kerberized Kafka clusters using the appropriate [`WITH`
options](#kerberos-with-options).

- Materialize currently only supports:
  - `GSSAPI` as the `sasl_mechanisms`
  - `SASL_PLAINTEXT` as the `security_protocol`
- Materialize does _not_ support Kerberos authentication for Confluent Schema
  Registries.
